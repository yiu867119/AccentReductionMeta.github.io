{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d528aa4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Foreign Accent Reduction META-ANALYSIS\n",
      "================================================================================ \n",
      "Initiated: 2025-11-30 14:48:37 | R version 4.5.1 (2025-06-13 ucrt)\n",
      "================================================================================\n",
      "\n",
      "================================================================================ \n",
      "STEP 0: ENVIRONMENT SETUP & DATA VALIDATION\n",
      "================================================================================ \n",
      "\n",
      "0.1: Loading required packages...\n",
      "--------------------------------------------------------------------------------\n",
      "  ✅ metafor v4.8.0\n",
      "  ✅ robumeta v2.1\n",
      "\n",
      "0.2: Setting up output directories...\n",
      "--------------------------------------------------------------------------------\n",
      "  ✅ Created output structure:\n",
      "     - Meta_Analysis_Results/\n",
      "       ├── Step1_Overall_Model/\n",
      "       ├── Step2_Moderator_Analysis/\n",
      "       ├── Step3_Robustness_Checks/\n",
      "       └── Step4_Publication_Bias/\n",
      "\n",
      "0.3: Defining helper functions...\n",
      "--------------------------------------------------------------------------------\n",
      "  ✅ Safe CSV writer configured\n",
      "\n",
      "0.4: Configuring R environment...\n",
      "--------------------------------------------------------------------------------\n",
      "  ✅ Precision: 4 decimals | No scientific notation | 80-char width\n",
      "\n",
      "0.5: Loading meta-analysis dataset...\n",
      "--------------------------------------------------------------------------------\n",
      "  ✅ Loaded: Meta_ready_cleaned.csv | Effects: 29 | Studies: 24 | Columns: 30\n",
      "\n",
      "0.6: Validating dataset structure...\n",
      "--------------------------------------------------------------------------------\n",
      "  ✅ Variance source: Standard Error (SE)\n",
      "  ✅ Variance (vi) calculated from SE: vi = SE²\n",
      "  ✅ Dataset validated successfully\n",
      "\n",
      "0.7: Setting reference levels for categorical moderators...\n",
      "--------------------------------------------------------------------------------\n",
      "  ✅ Age_Group: reference = Adolescent\n",
      "  ✅ Proficiency_Level: reference = Beginner\n",
      "  ✅ English_Major: reference = No\n",
      "  ✅ Education_Stage: reference = SecondarySchool\n",
      "  ✅ Learning_Context: reference = English\n",
      "  ✅ Training_Context: reference = Laboratory\n",
      "  ✅ Focus_Type: reference = Production\n",
      "  ✅ Target_Feature: reference = Suprasegmental\n",
      "  ✅ Feedback_Type: reference = Implicit\n",
      "  ✅ Instructor_Type: reference = Human\n",
      "  ✅ Peer_Interaction: reference = No\n",
      "  ✅ Visual_Cue: reference = No\n",
      "  ✅ Treatment_Duration: reference = Long\n",
      "  ✅ Comparator_Type: reference = Passive\n",
      "  ✅ Design_Type: reference = Quasi_Experiment\n",
      "  ✅ Outcome_Domain: reference = Pronunciation_Accuracy\n",
      "  ✅ Rater_Type: reference = Human\n",
      "  ✅ L1: reference = Arabic (most common, auto-detected)\n",
      "\n",
      "  ✅ Reference levels set for all categorical moderators\n",
      "  ✅ Baseline levels stored in BASELINE_LEVELS list\n",
      "\n",
      "================================================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# META-ANALYSIS: Foreign Accent Reduction EFFECTIVENESS\n",
    "# ============================================================================\n",
    "# PURPOSE: Quantify training effectiveness and isolate moderators via \n",
    "#          random-effects models, robustness checks, and bias assessment\n",
    "#\n",
    "# WORKFLOW:\n",
    "#   STEP 0: Environment setup & data validation\n",
    "#   STEP 1: Overall random-effects model (REML, Q/I²/τ², prediction interval)\n",
    "#   STEP 2: Moderator analyses (univariate & multivariate meta-regression)\n",
    "#   STEP 3: Robustness checks (leave-one-out, influence, RVE)\n",
    "#   STEP 4: Publication bias (Egger, trim-and-fill, fail-safe N)\n",
    "#\n",
    "# DEPENDENCIES:\n",
    "#   metafor  ≥ 3.0.0    REML meta-analysis (Viechtbauer, 2010)\n",
    "#   robumeta ≥ 2.0      Robust variance estimation (Hedges et al., 2010)\n",
    "#\n",
    "# ============================================================================\n",
    "# DATA STRUCTURE\n",
    "# ============================================================================\n",
    "#\n",
    "# INPUT:  Meta_ready_cleaned.csv\n",
    "#\n",
    "# OUTPUTS (14 files total, organized by analysis step)\n",
    "# \n",
    "# Meta_Analysis_Results/\n",
    "# ├── Step1_Overall_Model/\n",
    "# │   ├── overall_meta_analysis_results.csv       Pooled effect & heterogeneity\n",
    "# │   └── forest_overall.png                      Forest plot for overall effect\n",
    "# ├── Step2_Moderator_Analysis/\n",
    "# │   ├── univariate_moderator_summary.csv        Omnibus tests per moderator (1 row/mod)\n",
    "# │   ├── univariate_moderator_results.csv        Level-by-level results (β, CI, p)\n",
    "# │   ├── multivariate_model_coefficients.csv     Adjusted moderator effects\n",
    "# │   └── multivariate_model_fit.csv              Model R² & fit indices\n",
    "# ├── Step3_Robustness_Checks/\n",
    "# │   ├── leave_one_out_analysis.csv              Sensitivity metrics\n",
    "# │   ├── influence_diagnostics.csv               Cook's D, DFBETAS, leverage\n",
    "# │   ├── rve_overall_effect.csv                  RVE-adjusted pooled effect\n",
    "# │   └── rve_moderator_results.csv               RVE-adjusted moderator tests\n",
    "# └── Step4_Publication_Bias/\n",
    "#     ├── funnel_plot.png                         Visual asymmetry assessment\n",
    "#     ├── publication_bias_tests.csv              Egger, trim-and-fill, fsN\n",
    "#     └── publication_bias_trim_and_fill.csv      Imputed studies (only if k_imputed > 0)\n",
    "#\n",
    "# ============================================================================\n",
    "\n",
    "# Clear workspace & initialize\n",
    "rm(list = ls())\n",
    "analysis_start_time <- Sys.time()\n",
    "\n",
    "cat(\"\\n\", paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"Foreign Accent Reduction META-ANALYSIS\\n\")\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\")\n",
    "cat(\"Initiated: \", format(analysis_start_time, \"%Y-%m-%d %H:%M:%S\"), \" | \",\n",
    "    R.version.string, \"\\n\", sep = \"\")\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\\n\", sep = \"\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 0: ENVIRONMENT SETUP & DATA VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\")\n",
    "cat(\"STEP 0: ENVIRONMENT SETUP & DATA VALIDATION\\n\")\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 0.1: Package Installation & Loading\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"0.1: Loading required packages...\\n\", paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "required_packages <- c(\"metafor\", \"robumeta\")\n",
    "for (pkg in required_packages) {\n",
    "  if (!require(pkg, character.only = TRUE, quietly = TRUE)) {\n",
    "    install.packages(pkg, repos = \"https://cloud.r-project.org/\", quiet = TRUE)\n",
    "  }\n",
    "  library(pkg, character.only = TRUE)\n",
    "  cat(\"  ✅ \", pkg, \" v\", as.character(packageVersion(pkg)), \"\\n\", sep = \"\")\n",
    "}\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 0.2: Create Output Directory Structure\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"0.2: Setting up output directories...\\n\", paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "# Define main results directory\n",
    "results_dir <- file.path(getwd(), \"Meta_Analysis_Results\")\n",
    "\n",
    "# Create subdirectories for each analysis step\n",
    "step1_dir <- file.path(results_dir, \"Step1_Overall_Model\")\n",
    "step2_dir <- file.path(results_dir, \"Step2_Moderator_Analysis\")\n",
    "step3_dir <- file.path(results_dir, \"Step3_Robustness_Checks\")\n",
    "step4_dir <- file.path(results_dir, \"Step4_Publication_Bias\")\n",
    "\n",
    "# Create all directories\n",
    "for (dir_path in c(step1_dir, step2_dir, step3_dir, step4_dir)) {\n",
    "  if (!dir.exists(dir_path)) {\n",
    "    dir.create(dir_path, recursive = TRUE)\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"  ✅ Created output structure:\\n\")\n",
    "cat(\"     - Meta_Analysis_Results/\\n\")\n",
    "cat(\"       ├── Step1_Overall_Model/\\n\")\n",
    "cat(\"       ├── Step2_Moderator_Analysis/\\n\")\n",
    "cat(\"       ├── Step3_Robustness_Checks/\\n\")\n",
    "cat(\"       └── Step4_Publication_Bias/\\n\\n\")\n",
    "\n",
    "# Store paths in global environment for use by helper functions\n",
    "assign(\"step1_dir\", step1_dir, envir = .GlobalEnv)\n",
    "assign(\"step2_dir\", step2_dir, envir = .GlobalEnv)\n",
    "assign(\"step3_dir\", step3_dir, envir = .GlobalEnv)\n",
    "assign(\"step4_dir\", step4_dir, envir = .GlobalEnv)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 0.3: Define Helper Function (Safe CSV Export with Error Handling)\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"0.3: Defining helper functions...\\n\", paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "safe_write_csv <- function(data, filename, output_dir = NULL, show_message = TRUE) {\n",
    "  # Use provided directory or fall back to working directory\n",
    "  if (is.null(output_dir)) {\n",
    "    if (exists(\"output_path\", envir = .GlobalEnv)) {\n",
    "      output_dir <- get(\"output_path\", envir = .GlobalEnv)\n",
    "    } else {\n",
    "      output_dir <- getwd()\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  tryCatch({\n",
    "    write.csv(data, file.path(output_dir, filename), row.names = FALSE, fileEncoding = \"UTF-8\")\n",
    "    if (show_message) cat(\"  ✅ Saved: \", filename, \"\\n\", sep = \"\")\n",
    "    return(TRUE)\n",
    "  }, error = function(e) {\n",
    "    timestamp <- format(Sys.time(), \"%Y%m%d_%H%M%S\")\n",
    "    alt_filename <- paste0(sub(\"\\\\.csv$\", \"\", filename), \"_\", timestamp, \".csv\")\n",
    "    write.csv(data, file.path(output_dir, alt_filename), row.names = FALSE, fileEncoding = \"UTF-8\")\n",
    "    if (show_message) cat(\"  ⚠️  File locked. Saved as: \", alt_filename, \"\\n\", sep = \"\")\n",
    "    return(FALSE)\n",
    "  })\n",
    "}\n",
    "\n",
    "cat(\"  ✅ Safe CSV writer configured\\n\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 0.4: Configure R Environment\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"0.4: Configuring R environment...\\n\", paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "options(digits = 4, scipen = 999, width = 80, stringsAsFactors = FALSE, warn = 1)\n",
    "cat(\"  ✅ Precision: 4 decimals | No scientific notation | 80-char width\\n\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 0.5: Load & Validate Dataset\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"0.5: Loading meta-analysis dataset...\\n\", paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "data_file <- \"Meta_ready_cleaned.csv\"\n",
    "if (!file.exists(data_file)) {\n",
    "  stop(\"Data file missing: \", data_file, \" | Check working directory: \", getwd())\n",
    "}\n",
    "\n",
    "df <- read.csv(data_file, stringsAsFactors = FALSE, fileEncoding = \"UTF-8\")\n",
    "cat(\"  ✅ Loaded: \", data_file, \" | Effects: \", nrow(df), \" | Studies: \", \n",
    "    length(unique(df$Study_ID)), \" | Columns: \", ncol(df), \"\\n\\n\", sep = \"\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 0.6: Validate Essential Columns\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"0.6: Validating dataset structure...\\n\", paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "essential_cols <- c(\"Study_ID\", \"Effect_ID\", \"Hedges_g\")\n",
    "missing_cols <- setdiff(essential_cols, names(df))\n",
    "if (length(missing_cols) > 0) stop(\"Missing columns: \", paste(missing_cols, collapse = \", \"))\n",
    "\n",
    "if (\"SE\" %in% names(df)) {\n",
    "  variance_source <- \"SE\"\n",
    "  df$vi <- df$SE^2  # Create variance from standard error\n",
    "  cat(\"  ✅ Variance source: Standard Error (SE)\\n\")\n",
    "  cat(\"  ✅ Variance (vi) calculated from SE: vi = SE²\\n\")\n",
    "} else if (\"Variance\" %in% names(df)) {\n",
    "  variance_source <- \"Variance\"\n",
    "  df$vi <- df$Variance  # Use existing variance\n",
    "  cat(\"  ✅ Variance source: Variance\\n\")\n",
    "  cat(\"  ✅ Variance (vi) assigned from Variance column\\n\")\n",
    "} else {\n",
    "  stop(\"Missing variance metric: Dataset must include 'SE' or 'Variance' column\")\n",
    "}\n",
    "\n",
    "cat(\"  ✅ Dataset validated successfully\\n\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 0.7: Set Reference Levels for Categorical Moderators\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"0.7: Setting reference levels for categorical moderators...\\n\", paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "# Initialize baseline storage list\n",
    "BASELINE_LEVELS <- list()\n",
    "\n",
    "# LEARNER CHARACTERISTICS\n",
    "# Adolescent as reference (youngest age group baseline)\n",
    "if (\"Age_Group\" %in% names(df)) {\n",
    "  BASELINE_Age_Group <- \"Adolescent\"\n",
    "  BASELINE_LEVELS$Age_Group <- BASELINE_Age_Group\n",
    "  df$Age_Group <- relevel(factor(df$Age_Group), ref = BASELINE_Age_Group)\n",
    "  cat(\"  ✅ Age_Group: reference = \", BASELINE_Age_Group, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# Advanced as reference (highest proficiency baseline)\n",
    "if (\"Proficiency_Level\" %in% names(df)) {\n",
    "  BASELINE_Proficiency_Level <- \"Beginner\"\n",
    "  BASELINE_LEVELS$Proficiency_Level <- BASELINE_Proficiency_Level\n",
    "  df$Proficiency_Level <- relevel(factor(df$Proficiency_Level), ref = BASELINE_Proficiency_Level)\n",
    "  cat(\"  ✅ Proficiency_Level: reference = \", BASELINE_Proficiency_Level, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# Non-English major as reference (typical baseline)\n",
    "if (\"English_Major\" %in% names(df)) {\n",
    "  BASELINE_English_Major <- \"No\"\n",
    "  BASELINE_LEVELS$English_Major <- BASELINE_English_Major\n",
    "  df$English_Major <- relevel(factor(df$English_Major), ref = BASELINE_English_Major)\n",
    "  cat(\"  ✅ English_Major: reference = \", BASELINE_English_Major, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# Secondary school as reference (lower education level baseline)\n",
    "if (\"Education_Stage\" %in% names(df)) {\n",
    "  BASELINE_Education_Stage <- \"SecondarySchool\"\n",
    "  BASELINE_LEVELS$Education_Stage <- BASELINE_Education_Stage\n",
    "  df$Education_Stage <- relevel(factor(df$Education_Stage), ref = BASELINE_Education_Stage)\n",
    "  cat(\"  ✅ Education_Stage: reference = \", BASELINE_Education_Stage, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# LEARNING ENVIRONMENT\n",
    "# Foreign language context as reference (more common than L2)\n",
    "if (\"Learning_Context\" %in% names(df)) {\n",
    "  BASELINE_Learning_Context <- \"English\"\n",
    "  BASELINE_LEVELS$Learning_Context <- BASELINE_Learning_Context\n",
    "  df$Learning_Context <- relevel(factor(df$Learning_Context), ref = BASELINE_Learning_Context)\n",
    "  cat(\"  ✅ Learning_Context: reference = \", BASELINE_Learning_Context, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# Laboratory as reference (controlled setting baseline)\n",
    "if (\"Training_Context\" %in% names(df)) {\n",
    "  BASELINE_Training_Context <- \"Laboratory\"\n",
    "  BASELINE_LEVELS$Training_Context <- BASELINE_Training_Context\n",
    "  df$Training_Context <- relevel(factor(df$Training_Context), ref = BASELINE_Training_Context)\n",
    "  cat(\"  ✅ Training_Context: reference = \", BASELINE_Training_Context, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# INSTRUCTIONAL FEATURES\n",
    "# Perception as reference (receptive skill baseline)\n",
    "if (\"Focus_Type\" %in% names(df)) {\n",
    "  BASELINE_Focus_Type <- \"Production\"\n",
    "  BASELINE_LEVELS$Focus_Type <- BASELINE_Focus_Type\n",
    "  df$Focus_Type <- relevel(factor(df$Focus_Type), ref = BASELINE_Focus_Type)\n",
    "  cat(\"  ✅ Focus_Type: reference = \", BASELINE_Focus_Type, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# Segmental as reference (traditional pronunciation target)\n",
    "if (\"Target_Feature\" %in% names(df)) {\n",
    "  BASELINE_Target_Feature <- \"Suprasegmental\"\n",
    "  BASELINE_LEVELS$Target_Feature <- BASELINE_Target_Feature\n",
    "  df$Target_Feature <- relevel(factor(df$Target_Feature), ref = BASELINE_Target_Feature)\n",
    "  cat(\"  ✅ Target_Feature: reference = \", BASELINE_Target_Feature, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# Implicit feedback as reference (less explicit baseline)\n",
    "if (\"Feedback_Type\" %in% names(df)) {\n",
    "  BASELINE_Feedback_Type <- \"Implicit\"\n",
    "  BASELINE_LEVELS$Feedback_Type <- BASELINE_Feedback_Type\n",
    "  df$Feedback_Type <- relevel(factor(df$Feedback_Type), ref = BASELINE_Feedback_Type)\n",
    "  cat(\"  ✅ Feedback_Type: reference = \", BASELINE_Feedback_Type, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# Human instructor as reference (traditional instruction mode)\n",
    "if (\"Instructor_Type\" %in% names(df)) {\n",
    "  BASELINE_Instructor_Type <- \"Human\"\n",
    "  BASELINE_LEVELS$Instructor_Type <- BASELINE_Instructor_Type\n",
    "  df$Instructor_Type <- relevel(factor(df$Instructor_Type), ref = BASELINE_Instructor_Type)\n",
    "  cat(\"  ✅ Instructor_Type: reference = \", BASELINE_Instructor_Type, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# No peer interaction as reference (typical baseline)\n",
    "if (\"Peer_Interaction\" %in% names(df)) {\n",
    "  BASELINE_Peer_Interaction <- \"No\"\n",
    "  BASELINE_LEVELS$Peer_Interaction <- BASELINE_Peer_Interaction\n",
    "  df$Peer_Interaction <- relevel(factor(df$Peer_Interaction), ref = BASELINE_Peer_Interaction)\n",
    "  cat(\"  ✅ Peer_Interaction: reference = \", BASELINE_Peer_Interaction, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# No visual cue as reference (audio-only baseline)\n",
    "if (\"Visual_Cue\" %in% names(df)) {\n",
    "  BASELINE_Visual_Cue <- \"No\"\n",
    "  BASELINE_LEVELS$Visual_Cue <- BASELINE_Visual_Cue\n",
    "  df$Visual_Cue <- relevel(factor(df$Visual_Cue), ref = BASELINE_Visual_Cue)\n",
    "  cat(\"  ✅ Visual_Cue: reference = \", BASELINE_Visual_Cue, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# Long duration as reference (extended treatment baseline)\n",
    "if (\"Treatment_Duration\" %in% names(df)) {\n",
    "  BASELINE_Treatment_Duration <- \"Long\"\n",
    "  BASELINE_LEVELS$Treatment_Duration <- BASELINE_Treatment_Duration\n",
    "  df$Treatment_Duration <- relevel(factor(df$Treatment_Duration), ref = BASELINE_Treatment_Duration)\n",
    "  cat(\"  ✅ Treatment_Duration: reference = \", BASELINE_Treatment_Duration, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# METHODOLOGICAL FEATURES\n",
    "# Passive comparator as reference (no-treatment baseline)\n",
    "if (\"Comparator_Type\" %in% names(df)) {\n",
    "  BASELINE_Comparator_Type <- \"Passive\"\n",
    "  BASELINE_LEVELS$Comparator_Type <- BASELINE_Comparator_Type\n",
    "  df$Comparator_Type <- relevel(factor(df$Comparator_Type), ref = BASELINE_Comparator_Type)\n",
    "  cat(\"  ✅ Comparator_Type: reference = \", BASELINE_Comparator_Type, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# Quasi-experimental as reference (most common design)\n",
    "if (\"Design_Type\" %in% names(df)) {\n",
    "  BASELINE_Design_Type <- \"Quasi_Experiment\"\n",
    "  BASELINE_LEVELS$Design_Type <- BASELINE_Design_Type\n",
    "  df$Design_Type <- relevel(factor(df$Design_Type), ref = BASELINE_Design_Type)\n",
    "  cat(\"  ✅ Design_Type: reference = \", BASELINE_Design_Type, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# Pronunciation accuracy as reference (most common outcome)\n",
    "if (\"Outcome_Domain\" %in% names(df)) {\n",
    "  BASELINE_Outcome_Domain <- \"Pronunciation_Accuracy\"\n",
    "  BASELINE_LEVELS$Outcome_Domain <- BASELINE_Outcome_Domain\n",
    "  df$Outcome_Domain <- relevel(factor(df$Outcome_Domain), ref = BASELINE_Outcome_Domain)\n",
    "  cat(\"  ✅ Outcome_Domain: reference = \", BASELINE_Outcome_Domain, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# Human rater as reference (traditional assessment)\n",
    "if (\"Rater_Type\" %in% names(df)) {\n",
    "  BASELINE_Rater_Type <- \"Human\"\n",
    "  BASELINE_LEVELS$Rater_Type <- BASELINE_Rater_Type\n",
    "  df$Rater_Type <- relevel(factor(df$Rater_Type), ref = BASELINE_Rater_Type)\n",
    "  cat(\"  ✅ Rater_Type: reference = \", BASELINE_Rater_Type, \"\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# L1 - set most common or theoretically meaningful L1 as reference\n",
    "# For this dataset, we can check which L1 has the most observations\n",
    "if (\"L1\" %in% names(df)) {\n",
    "  l1_counts <- table(df$L1)\n",
    "  BASELINE_L1 <- \"Arabic\"\n",
    "  BASELINE_LEVELS$L1 <- BASELINE_L1\n",
    "  df$L1 <- relevel(factor(df$L1), ref = BASELINE_L1)\n",
    "  cat(\"  ✅ L1: reference = \", BASELINE_L1, \" (most common, auto-detected)\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "cat(\"\\n  ✅ Reference levels set for all categorical moderators\\n\")\n",
    "cat(\"  ✅ Baseline levels stored in BASELINE_LEVELS list\\n\\n\")\n",
    "\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "986f038f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================ \n",
      "STEP 1: OVERALL RANDOM-EFFECTS META-ANALYSIS\n",
      "================================================================================ \n",
      "Research Question: Is L2 pronunciation training effective overall?\n",
      "\n",
      "1.1: Fitting random-effects model (REML)...\n",
      "--------------------------------------------------------------------------------\n",
      "  ✅ Model fitted | Method: REML | Test: Z-distribution\n",
      "\n",
      "1.2: Overall effect size estimate...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  OVERALL EFFECT (Hedges' g):\n",
      "  ----------------------------------------------------------------------------\n",
      "    g = 0.5272, SE = 0.0761, 95% CI [0.3781, 0.6763]\n",
      "    Z = 6.9306, p = 0.0000 ***\n",
      "    HIGHLY SIGNIFICANT (p < .001)\n",
      "\n",
      "1.3: Heterogeneity statistics...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  HETEROGENEITY:\n",
      "  ----------------------------------------------------------------------------\n",
      "    Q = 60.4647 (df = 28, p < .001 ***)\n",
      "    I² = 54.64% | τ² = 0.0882 | H² = 2.2047\n",
      "\n",
      "  I² Interpretation: Substantial heterogeneity (50% ≤ I² < 75%)\n",
      "    → ✅ MODERATOR ANALYSIS WARRANTED\n",
      "\n",
      "  95% PREDICTION INTERVAL:\n",
      "  ----------------------------------------------------------------------------\n",
      "    Interval: [-0.1019, 1.1564]\n",
      "\n",
      "  Interpretation:\n",
      "    → In 95% of contexts, the true effect is expected to fall\n",
      "      within this range\n",
      "    → Wide interval indicates substantial heterogeneity\n",
      "\n",
      "Step 1.5: Overall meta-analysis summary...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  SUMMARY:\n",
      "  ============================================================================\n",
      "\n",
      "  1. EFFECT SIZE:\n",
      "     → Training effect: g = 0.5272 [0.3781, 0.6763]\n",
      "     → Interpretation:  HIGHLY SIGNIFICANT (p < .001)\n",
      "     → Magnitude:       Medium to large (Cohen, 1988)\n",
      "\n",
      "  2. HETEROGENEITY:\n",
      "     → Substantial heterogeneity (50% ≤ I² < 75%)\n",
      "     → CONCLUSION: Moderator analysis is justified\n",
      "\n",
      "  3. NEXT STEPS:\n",
      "     ✅ Proceed to STEP 2: Moderator Analyses\n",
      "        (High I² indicates systematic variation to explain)\n",
      "\n",
      "Step 1.6: Exporting overall meta-analysis results...\n",
      "--------------------------------------------------------------------------------\n",
      "  ✅ Saved: overall_meta_analysis_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1.7: Generating forest plot for overall effect...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>agg_record_1588552183:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{agg\\textbackslash{}\\_record\\textbackslash{}\\_1588552183:} 2"
      ],
      "text/markdown": [
       "**agg_record_1588552183:** 2"
      ],
      "text/plain": [
       "agg_record_1588552183 \n",
       "                    2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Forest plot saved to: c:/Users/Lenovo/Desktop/github/Meta_Analysis_Results/Step1_Overall_Model/forest_overall.png\n",
      "\n",
      "✅ STEP 1 COMPLETE: Overall random-effects meta-analysis finished\n",
      "================================================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: OVERALL RANDOM-EFFECTS META-ANALYSIS\n",
    "# ============================================================================\n",
    "# PURPOSE: Estimate pooled training effectiveness & assess heterogeneity\n",
    "# MODEL:   yi ~ N(θ + ui, vi) where ui ~ N(0, τ²)\n",
    "#          REML estimation | Z-test | 95% CI & prediction interval\n",
    "#\n",
    "# OUTPUTS (in Meta_Analysis_Results/Step1_Overall_Model/):\n",
    "#   1. overall_meta_analysis_results.csv  - Pooled effect size & heterogeneity statistics\n",
    "#   2. forest_overall.png                 - Forest plot visualization of all studies\n",
    "# ============================================================================\n",
    "\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\")\n",
    "cat(\"STEP 1: OVERALL RANDOM-EFFECTS META-ANALYSIS\\n\")\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\")\n",
    "cat(\"Research Question: Is L2 pronunciation training effective overall?\\n\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1.1: Fit REML Random-Effects Model\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"1.1: Fitting random-effects model (REML)...\\n\", paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "# Explicitly use df$vi for clarity and robustness\n",
    "res_overall <- rma(yi = Hedges_g, vi = df$vi, data = df, method = \"REML\", test = \"z\")\n",
    "cat(\"  ✅ Model fitted | Method: REML | Test: Z-distribution\\n\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1.2: Overall Effect Size\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"1.2: Overall effect size estimate...\\n\", paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\", sep = \"\")\n",
    "\n",
    "overall_g <- res_overall$b[1]\n",
    "overall_se <- res_overall$se\n",
    "overall_ci_lb <- res_overall$ci.lb\n",
    "overall_ci_ub <- res_overall$ci.ub\n",
    "overall_z <- res_overall$zval\n",
    "overall_p <- res_overall$pval\n",
    "\n",
    "sig_marker <- if (overall_p < 0.001) \" ***\" else if (overall_p < 0.01) \" **\" else if (overall_p < 0.05) \" *\" else \"\"\n",
    "sig_interpretation <- if (overall_p < 0.001) \"HIGHLY SIGNIFICANT (p < .001)\" else \n",
    "                      if (overall_p < 0.01) \"Very significant (p < .01)\" else \n",
    "                      if (overall_p < 0.05) \"Significant (p < .05)\" else \n",
    "                      \"Not significant (p ≥ .05)\"\n",
    "\n",
    "cat(\"  OVERALL EFFECT (Hedges' g):\\n  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"    g = \", sprintf(\"%.4f\", overall_g), \", SE = \", sprintf(\"%.4f\", overall_se), \n",
    "    \", 95% CI [\", sprintf(\"%.4f\", overall_ci_lb), \", \", sprintf(\"%.4f\", overall_ci_ub), \"]\\n\", sep = \"\")\n",
    "cat(\"    Z = \", sprintf(\"%.4f\", overall_z), \", p = \", sprintf(\"%.4f\", overall_p), sig_marker, \"\\n\", sep = \"\")\n",
    "cat(\"    \", sig_interpretation, \"\\n\\n\", sep = \"\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1.3: Heterogeneity Assessment\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"1.3: Heterogeneity statistics...\\n\", paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\", sep = \"\")\n",
    "\n",
    "Q_stat <- res_overall$QE\n",
    "Q_df <- res_overall$k - 1\n",
    "Q_p <- res_overall$QEp\n",
    "I2 <- res_overall$I2\n",
    "tau2 <- res_overall$tau2\n",
    "tau <- sqrt(tau2)\n",
    "H2 <- res_overall$H2\n",
    "\n",
    "cat(\"  HETEROGENEITY:\\n  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "# Improved Q statistic formatting\n",
    "cat(\"    Q = \", sprintf(\"%.4f\", Q_stat), \" (df = \", Q_df, \n",
    "    if (Q_p < 0.001) \", p < .001 ***)\\n\" else paste0(\", p = \", sprintf(\"%.4f\", Q_p), \")\\n\"), sep = \"\")\n",
    "cat(\"    I² = \", sprintf(\"%.2f\", I2), \"% | τ² = \", sprintf(\"%.4f\", tau2), \n",
    "    \" | H² = \", sprintf(\"%.4f\", H2), \"\\n\\n\", sep = \"\")\n",
    "\n",
    "I2_interpretation <- if (I2 < 25) \"Low heterogeneity (I² < 25%)\" else \n",
    "                     if (I2 < 50) \"Moderate heterogeneity (25% ≤ I² < 50%)\" else \n",
    "                     if (I2 < 75) \"Substantial heterogeneity (50% ≤ I² < 75%)\" else \n",
    "                     \"Very high heterogeneity (I² ≥ 75%)\"\n",
    "\n",
    "cat(\"  I² Interpretation: \", I2_interpretation, \"\\n\", sep = \"\")\n",
    "# Use consistent threshold: I2 >= 50\n",
    "if (I2 >= 50) cat(\"    → ✅ MODERATOR ANALYSIS WARRANTED\\n\")\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Calculate 95% prediction interval\n",
    "# PI = estimate ± t(k-2) × sqrt(τ² + SE²)\n",
    "k <- res_overall$k\n",
    "t_crit <- qt(0.975, df = k - 2)\n",
    "pi_lower <- overall_g - t_crit * sqrt(tau2 + overall_se^2)\n",
    "pi_upper <- overall_g + t_crit * sqrt(tau2 + overall_se^2)\n",
    "\n",
    "cat(\"  95% PREDICTION INTERVAL:\\n\")\n",
    "cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"    Interval: [\", sprintf(\"%.4f\", pi_lower), \", \", \n",
    "    sprintf(\"%.4f\", pi_upper), \"]\\n\", sep = \"\")\n",
    "cat(\"\\n\")\n",
    "cat(\"  Interpretation:\\n\")\n",
    "cat(\"    → In 95% of contexts, the true effect is expected to fall\\n\")\n",
    "cat(\"      within this range\\n\")\n",
    "cat(\"    → Wide interval indicates substantial heterogeneity\\n\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 1.5: Summary and Interpretation\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 1.5: Overall meta-analysis summary...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "cat(\"  SUMMARY:\\n\")\n",
    "cat(\"  \", paste0(rep(\"=\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Effect size interpretation\n",
    "cat(\"  1. EFFECT SIZE:\\n\")\n",
    "cat(\"     → Training effect: g = \", sprintf(\"%.4f\", overall_g), \n",
    "    \" [\", sprintf(\"%.4f\", overall_ci_lb), \", \", \n",
    "    sprintf(\"%.4f\", overall_ci_ub), \"]\\n\", sep = \"\")\n",
    "cat(\"     → Interpretation:  \", sig_interpretation, \"\\n\", sep = \"\")\n",
    "\n",
    "# Effect size magnitude (Cohen's benchmarks)\n",
    "if (abs(overall_g) < 0.2) {\n",
    "  magnitude <- \"Negligible to small\"\n",
    "} else if (abs(overall_g) < 0.5) {\n",
    "  magnitude <- \"Small to medium\"\n",
    "} else if (abs(overall_g) < 0.8) {\n",
    "  magnitude <- \"Medium to large\"\n",
    "} else {\n",
    "  magnitude <- \"Large to very large\"\n",
    "}\n",
    "cat(\"     → Magnitude:       \", magnitude, \" (Cohen, 1988)\\n\", sep = \"\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"  2. HETEROGENEITY:\\n\")\n",
    "cat(\"     → \", I2_interpretation, \"\\n\", sep = \"\")\n",
    "# Use consistent threshold: I2 >= 50\n",
    "if (I2 >= 50) {\n",
    "  cat(\"     → CONCLUSION: Moderator analysis is justified\\n\")\n",
    "  proceed_to_moderators <- TRUE\n",
    "} else {\n",
    "  cat(\"     → CONCLUSION: Moderator analysis optional\\n\")\n",
    "  proceed_to_moderators <- FALSE\n",
    "}\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"  3. NEXT STEPS:\\n\")\n",
    "if (proceed_to_moderators) {\n",
    "  cat(\"     ✅ Proceed to STEP 2: Moderator Analyses\\n\")\n",
    "  cat(\"        (High I² indicates systematic variation to explain)\\n\")\n",
    "} else {\n",
    "  cat(\"     → Consider exploratory moderator analyses\\n\")\n",
    "  cat(\"        (Low-moderate I² suggests limited systematic variation)\\n\")\n",
    "}\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 1.6: Export Overall Results\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 1.6: Exporting overall meta-analysis results...\\n\", paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "overall_results <- data.frame(\n",
    "  Statistic = c(\"Effect Size (g)\", \"SE\", \"95% CI Lower\", \"95% CI Upper\", \n",
    "                \"Z-value\", \"p-value\", \"Q\", \"Q df\", \"Q p-value\", \n",
    "                \"I²\", \"τ²\", \"H²\", \"PI Lower\", \"PI Upper\"),\n",
    "  Value = c(overall_g, overall_se, overall_ci_lb, overall_ci_ub, \n",
    "            overall_z, overall_p, Q_stat, Q_df, Q_p, \n",
    "            I2, tau2, H2, pi_lower, pi_upper)\n",
    ")\n",
    "\n",
    "safe_write_csv(overall_results, \"overall_meta_analysis_results.csv\", step1_dir)\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ---------------------[FOREST PLOT GENERATION]---------------------\n",
    "# Step 1.7: Generate Forest Plot for Overall Effect\n",
    "# ---------------------[New: Forest plot for overall meta-analysis]---------------------\n",
    "cat(\"Step 1.7: Generating forest plot for overall effect...\\n\", paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "# Create forest plot\n",
    "forest_filename <- file.path(step1_dir, \"forest_overall.png\")\n",
    "png(forest_filename, width = 1400, height = 900, res = 120)\n",
    "\n",
    "forest(res_overall,\n",
    "       header = TRUE,\n",
    "       xlim = c(-3, 5),\n",
    "       at = c(-1, -0.5, 0, 0.5, 1, 1.5),\n",
    "       xlab = \"Hedges' g\",\n",
    "       slab = paste(df$Study_ID),\n",
    "       main = paste0(\"Forest Plot: Overall Effect (g = \", sprintf(\"%.4f\", overall_g), \n",
    "                     \", 95% CI [\", sprintf(\"%.4f\", overall_ci_lb), \", \", \n",
    "                     sprintf(\"%.4f\", overall_ci_ub), \"], p = \", sprintf(\"%.4f\", overall_p), \")\"))\n",
    "\n",
    "dev.off()\n",
    "\n",
    "cat(\"  ✅ Forest plot saved to: \", forest_filename, \"\\n\", sep = \"\")\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"✅ STEP 1 COMPLETE: Overall random-effects meta-analysis finished\\n\")\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cfdb44c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################################################################\n",
      "#                   STEP 2: MODERATOR META-ANALYSIS                          #\n",
      "###############################################################################\n",
      "\n",
      "Verifying STEP 1 dependencies...\n",
      "-------------------------------------------------------------------------------- \n",
      "  ✅ tau2 found: τ² = 0.08823\n",
      "  ✅ res_overall found: k = 29\n",
      "\n",
      "================================================================================\n",
      "STEP 2.1: UNIVARIATE MODERATOR ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Step 2.1.1: Defining moderator variables...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  Category 1: Participant Characteristics (n = 5)\n",
      "    1. L1\n",
      "    2. Age_Group\n",
      "    3. Proficiency_Level\n",
      "    4. English_Major\n",
      "    5. Education_Stage\n",
      "\n",
      "  Category 2: Treatment Characteristics (n = 7)\n",
      "    1. Treatment_Duration\n",
      "    2. Training_TotalMinute\n",
      "    3. Training_TotalWeeks\n",
      "    4. Training_Context\n",
      "    5. Feedback_Type\n",
      "    6. Visual_Cue\n",
      "    7. Instructor_Type\n",
      "\n",
      "  Category 3: Linguistic Features (n = 2)\n",
      "    1. Target_Feature\n",
      "    2. Focus_Type\n",
      "\n",
      "  Category 4: Methodological Features (n = 5)\n",
      "    1. Design_Type\n",
      "    2. Comparator_Type\n",
      "    3. Learning_Context\n",
      "    4. Rater_Type\n",
      "    5. Peer_Interaction\n",
      "\n",
      "  Category 5: Outcome Characteristics (n = 1)\n",
      "    1. Outcome_Domain\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  TOTAL CANDIDATE MODERATORS: 20\n",
      "  ----------------------------------------------------------------------------\n",
      "\n",
      "  ✅ Available moderators: 20/20\n",
      "\n",
      "Step 2.1.2: Running univariate meta-regressions...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  Testing moderator: L1\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 22.5717, p = 0.0020\n",
      "       τ² = 0.0248, R² = 71.94%\n",
      "\n",
      "  Testing moderator: Age_Group\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 1.1773, p = 0.2779\n",
      "       τ² = 0.0881, R² = 0.11%\n",
      "\n",
      "  Testing moderator: Proficiency_Level\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 4.2658, p = 0.2342\n",
      "       τ² = 0.0823, R² = 6.78%\n",
      "\n",
      "  Testing moderator: English_Major\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 12.4787, p = 0.0020\n",
      "       τ² = 0.0386, R² = 56.26%\n",
      "\n",
      "  Testing moderator: Education_Stage\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 6.9669, p = 0.0307\n",
      "       τ² = 0.0642, R² = 27.22%\n",
      "\n",
      "  Testing moderator: Treatment_Duration\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 10.7672, p = 0.0131\n",
      "       τ² = 0.0485, R² = 44.98%\n",
      "\n",
      "  Testing moderator: Training_TotalMinute\n",
      "    ✅ Model fitted successfully\n",
      "       k = 16, QM = 0.7503, p = 0.3864\n",
      "       τ² = 0.0062, R² = 92.99%\n",
      "\n",
      "  Testing moderator: Training_TotalWeeks\n",
      "    ✅ Model fitted successfully\n",
      "       k = 28, QM = 0.2136, p = 0.6440\n",
      "       τ² = 0.0430, R² = 51.25%\n",
      "\n",
      "  Testing moderator: Training_Context\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 0.2670, p = 0.6054\n",
      "       τ² = 0.0927, R² = 0.00%\n",
      "\n",
      "  Testing moderator: Feedback_Type\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 5.3109, p = 0.1504\n",
      "       τ² = 0.0783, R² = 11.25%\n",
      "\n",
      "  Testing moderator: Visual_Cue\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 0.2752, p = 0.5999\n",
      "       τ² = 0.0952, R² = 0.00%\n",
      "\n",
      "  Testing moderator: Instructor_Type\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 1.0040, p = 0.6053\n",
      "       τ² = 0.0981, R² = 0.00%\n",
      "\n",
      "  Testing moderator: Target_Feature\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 0.5802, p = 0.9010\n",
      "       τ² = 0.1051, R² = 0.00%\n",
      "\n",
      "  Testing moderator: Focus_Type\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 2.3719, p = 0.3055\n",
      "       τ² = 0.0889, R² = 0.00%\n",
      "\n",
      "  Testing moderator: Design_Type\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 3.0131, p = 0.0826\n",
      "       τ² = 0.0782, R² = 11.40%\n",
      "\n",
      "  Testing moderator: Comparator_Type\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 3.3773, p = 0.1848\n",
      "       τ² = 0.0793, R² = 10.14%\n",
      "\n",
      "  Testing moderator: Learning_Context\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 1.9437, p = 0.1633\n",
      "       τ² = 0.0800, R² = 9.36%\n",
      "\n",
      "  Testing moderator: Rater_Type\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 1.2914, p = 0.5243\n",
      "       τ² = 0.0942, R² = 0.00%\n",
      "\n",
      "  Testing moderator: Peer_Interaction\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 0.0099, p = 0.9208\n",
      "       τ² = 0.0947, R² = 0.00%\n",
      "\n",
      "  Testing moderator: Outcome_Domain\n",
      "    ✅ Model fitted successfully\n",
      "       k = 29, QM = 4.5887, p = 0.3322\n",
      "       τ² = 0.0891, R² = 0.00%\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "  SUMMARY:\n",
      "    Total candidate moderators:  20\n",
      "    Successfully fitted models:  20\n",
      "    Skipped moderators:          0\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "Step 2.1.3: Creating summary table...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  Top 5 moderators by R²:\n",
      "    1. Training_TotalMinute: R² = 92.99%, p = 0.3864\n",
      "    2. L1: R² = 71.94%, p = 0.0020\n",
      "    3. English_Major: R² = 56.26%, p = 0.0020\n",
      "    4. Training_TotalWeeks: R² = 51.25%, p = 0.6440\n",
      "    5. Treatment_Duration: R² = 44.98%, p = 0.0131\n",
      "\n",
      "Step 2.1.4: Exporting univariate results...\n",
      "-------------------------------------------------------------------------------- \n",
      "  ✅ Saved: univariate_moderator_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Univariate summary saved to: c:/Users/Lenovo/Desktop/github/Meta_Analysis_Results/Step2_Moderator_Analysis\n",
      "\n",
      "Step 2.1.3b: Generating detailed level-by-level results...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  ✅ Saved: univariate_moderator_results.csv\n",
      "  ✅ Detailed level-by-level results saved\n",
      "     Rows: 63\n",
      "\n",
      "Step 2.1.7: Identifying significant moderators (p < .05)...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  Found 4 significant moderator(s):\n",
      "\n",
      "    1. L1\n",
      "       QM = 22.5717 (df = 7, p = 0.0020)\n",
      "       τ² = 0.0248, R² = 71.94%\n",
      "\n",
      "    2. English_Major\n",
      "       QM = 12.4787 (df = 2, p = 0.0020)\n",
      "       τ² = 0.0386, R² = 56.26%\n",
      "\n",
      "    3. Education_Stage\n",
      "       QM = 6.9669 (df = 2, p = 0.0307)\n",
      "       τ² = 0.0642, R² = 27.22%\n",
      "\n",
      "    4. Treatment_Duration\n",
      "       QM = 10.7672 (df = 3, p = 0.0131)\n",
      "       τ² = 0.0485, R² = 44.98%\n",
      "\n",
      "  ✅ Significant moderators stored for multivariate analysis\n",
      "\n",
      "✅ STEP 2.1 COMPLETE: Univariate moderator analysis complete\n",
      "================================================================================ \n",
      "\n",
      "================================================================================\n",
      "STEP 2.2: MULTIVARIATE MODERATOR ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Step 2.2.1: Building multivariate model...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  Including 4 significant moderator(s):\n",
      "    1. L1\n",
      "    2. English_Major\n",
      "    3. Education_Stage\n",
      "    4. Treatment_Duration\n",
      "\n",
      "  Formula: Hedges_g ~ L1 + English_Major + Education_Stage + Treatment_Duration\n",
      "\n",
      "Step 2.2.2: Preparing dataset...\n",
      "-------------------------------------------------------------------------------- \n",
      "  Original dataset:     29 rows\n",
      "  Complete-case data:   29 rows\n",
      "  Missing data removed: 0 rows\n",
      "\n",
      "Step 2.2.3: Fitting multivariate meta-regression...\n",
      "-------------------------------------------------------------------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"Redundant predictors dropped from the model.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Model fitted successfully\n",
      "\n",
      "Step 2.2.4: Multivariate meta-regression results...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  MODEL-LEVEL STATISTICS:\n",
      "  ----------------------------------------------------------------------------\n",
      "    k (studies):         29\n",
      "    QM (omnibus test):   36.8227 (df = 13, p = 0.0004)\n",
      "    QE (residual het.):  19.8100 (df = 15, p = 0.1793)\n",
      "    τ² (residual):       0.0075\n",
      "    I² (residual):       9.71%\n",
      "    Pseudo-R²:           91.47%\n",
      "\n",
      "  REGRESSION COEFFICIENTS:\n",
      "  ============================================================================\n",
      "\n",
      "  intrcpt \n",
      "    β = -0.4689 [-1.1805, 0.2426]\n",
      "    z = -1.2917, p = 0.1965 (n.s.)\n",
      "\n",
      "  L1 \n",
      "    β = 0.3633 [-0.5723, 1.2990]\n",
      "    z = 0.7611, p = 0.4466 (n.s.)\n",
      "\n",
      "  L1Chinese *\n",
      "    β = 0.6163 [0.0344, 1.1983]\n",
      "    z = 2.0758, p = 0.0379 (p < .05)\n",
      "\n",
      "  L1Farsi **\n",
      "    β = 1.4003 [0.4293, 2.3714]\n",
      "    z = 2.8265, p = 0.0047 (p < .01)\n",
      "\n",
      "  L1Japanese \n",
      "    β = 0.4056 [-0.2812, 1.0923]\n",
      "    z = 1.1575, p = 0.2471 (n.s.)\n",
      "\n",
      "  L1Korean \n",
      "    β = 0.6539 [-0.5248, 1.8325]\n",
      "    z = 1.0873, p = 0.2769 (n.s.)\n",
      "\n",
      "  L1Persian \n",
      "    β = 0.7460 [-0.3746, 1.8666]\n",
      "    z = 1.3047, p = 0.1920 (n.s.)\n",
      "\n",
      "  L1Turkish \n",
      "    β = 0.6221 [-0.0284, 1.2726]\n",
      "    z = 1.8743, p = 0.0609 (n.s.)\n",
      "\n",
      "  English_Major \n",
      "    β = 0.4462 [-0.1502, 1.0426]\n",
      "    z = 1.4662, p = 0.1426 (n.s.)\n",
      "\n",
      "  English_MajorYes \n",
      "    β = 0.4125 [-0.0857, 0.9108]\n",
      "    z = 1.6229, p = 0.1046 (n.s.)\n",
      "\n",
      "  Education_Stage \n",
      "    β = -0.0620 [-0.7452, 0.6211]\n",
      "    z = -0.1780, p = 0.8587 (n.s.)\n",
      "\n",
      "  Education_StageUndergraduate \n",
      "    β = 0.2634 [-0.0261, 0.5530]\n",
      "    z = 1.7833, p = 0.0745 (n.s.)\n",
      "\n",
      "  Treatment_DurationMedium \n",
      "    β = 0.2846 [-0.1173, 0.6864]\n",
      "    z = 1.3879, p = 0.1652 (n.s.)\n",
      "\n",
      "  Treatment_DurationShort \n",
      "    β = 0.2297 [-0.0678, 0.5271]\n",
      "    z = 1.5131, p = 0.1302 (n.s.)\n",
      "\n",
      "Step 2.2.5: Exporting multivariate results...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  Raw coefficient names from model:\n",
      "    1. intrcpt\n",
      "    2. L1\n",
      "    3. L1Chinese\n",
      "    4. L1Farsi\n",
      "    5. L1Japanese\n",
      "    6. L1Korean\n",
      "    7. L1Persian\n",
      "    8. L1Turkish\n",
      "    9. English_Major\n",
      "    10. English_MajorYes\n",
      "    11. Education_Stage\n",
      "    12. Education_StageUndergraduate\n",
      "    13. Treatment_DurationMedium\n",
      "    14. Treatment_DurationShort\n",
      "\n",
      "  Moderator type detection:\n",
      "    Continuous moderators (n=0):\n",
      "    Categorical moderators (n=4):\n",
      "      - L1\n",
      "      - English_Major\n",
      "      - Education_Stage\n",
      "      - Treatment_Duration\n",
      "\n",
      "  ⚠️  WARNING: Skipping invalid coefficient 'L1' (categorical moderator without level)\n",
      "  ⚠️  WARNING: Skipping invalid coefficient 'English_Major' (categorical moderator without level)\n",
      "  ⚠️  WARNING: Skipping invalid coefficient 'Education_Stage' (categorical moderator without level)\n",
      "\n",
      "  Parsed 11 valid coefficients\n",
      "\n",
      "  Adding baseline rows for categorical moderators...\n",
      "    ✅ Added baseline for L1: Arabic\n",
      "    ✅ Added baseline for English_Major: No\n",
      "    ✅ Added baseline for Education_Stage: SecondarySchool\n",
      "    ✅ Added baseline for Treatment_Duration: Long\n",
      "\n",
      "  Final export structure:\n",
      "    Total rows:       15\n",
      "    Intercept:        1\n",
      "    Continuous:       0\n",
      "    Categorical:      10\n",
      "    Baselines:        4\n",
      "\n",
      "  ✅ Saved: multivariate_model_coefficients.csv\n",
      "  ✅ Saved: multivariate_model_fit.csv\n",
      "  ✅ Exported coefficients with safe parsing logic\n",
      "  ✅ Format: Moderator_Family + Level_Label\n",
      "  ✅ Categorical moderators: Family + Level (baselines added with β=0)\n",
      "  ✅ Continuous moderators: Family = Level = moderator name\n",
      "\n",
      "================================================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: MODERATOR ANALYSES\n",
    "# ============================================================================\n",
    "#\n",
    "# OUTPUT FILES GENERATED IN STEP 2 (in Meta_Analysis_Results/Step2_Moderator_Analysis/):\n",
    "#\n",
    "# (A) UNIVARIATE ANALYSES (STEP 2.1)\n",
    "#     1. univariate_moderator_summary.csv\n",
    "#        • Contains: One summary row per moderator with omnibus statistics\n",
    "#        • Columns: Moderator, k, QM, df_QM, p_QM, tau2, R²\n",
    "#        • Use for: Overview table, identifying significant moderators\n",
    "#\n",
    "#     2. univariate_moderator_results.csv (NEW)\n",
    "#        • Contains: Level-by-level detailed results for each moderator\n",
    "#        • Columns: Moderator, Level, Type, n, Estimate, SE, CI_Lower, CI_Upper,\n",
    "#                   z_value, p_value, QM, QM_p, tau2_residual, I2_residual, R2\n",
    "#        • Rows: One per moderator level (categorical) or per moderator (continuous)\n",
    "#        • Use for: Forest plots, detailed visualization, level-specific inference\n",
    "#\n",
    "# (B) MULTIVARIATE ANALYSIS (STEP 2.2)\n",
    "#     *Generated only if ≥ 1 significant moderator from STEP 2.1*\n",
    "#\n",
    "#     3. multivariate_model_coefficients.csv\n",
    "#        • Regression coefficients for each moderator (adjusted model)\n",
    "#        • Format: Moderator_Family + Level_Label\n",
    "#        • Includes: β, SE, CI, z, p\n",
    "#        • Categorical: Multiple rows per moderator (one per level + baseline)\n",
    "#        • Continuous: One row (Family = Label = moderator name)\n",
    "#\n",
    "#     4. multivariate_model_fit.csv\n",
    "#        • Overall model statistics\n",
    "#        • Includes: QM, QE, τ², I², pseudo-R², k, p\n",
    "#\n",
    "# NOTE: Forest and funnel plots are NOT generated in Step 2\n",
    "# ============================================================================\n",
    "\n",
    "cat(\"###############################################################################\\n\")\n",
    "cat(\"#                   STEP 2: MODERATOR META-ANALYSIS                          #\\n\")\n",
    "cat(\"###############################################################################\\n\\n\")\n",
    "\n",
    "# Verify STEP 1 dependencies\n",
    "cat(\"Verifying STEP 1 dependencies...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\")\n",
    "\n",
    "if (!exists(\"tau2\")) {\n",
    "  stop(\"ERROR: Global variable 'tau2' not found. Please run STEP 1 first.\\n\",\n",
    "       \"       STEP 2 requires tau2 for R² calculation: (tau2 - tau2_res) / tau2\")\n",
    "}\n",
    "\n",
    "if (!exists(\"res_overall\")) {\n",
    "  stop(\"ERROR: Overall meta-analysis results not found. Please run STEP 1 first.\\n\",\n",
    "       \"       STEP 2 requires res_overall for model comparison.\")\n",
    "}\n",
    "\n",
    "cat(\"  ✅ tau2 found: τ² = \", tau2, \"\\n\", sep = \"\")\n",
    "cat(\"  ✅ res_overall found: k = \", res_overall$k, \"\\n\", sep = \"\")\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 2.1: Univariate Moderator Analysis\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"================================================================================\\n\")\n",
    "cat(\"STEP 2.1: UNIVARIATE MODERATOR ANALYSIS\\n\")\n",
    "cat(\"================================================================================\\n\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 2.1.1: Define Moderator Categories\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 2.1.1: Defining moderator variables...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "# Category 1: Participant Characteristics\n",
    "participant_moderators <- c(\n",
    "  \"L1\",                    # Native language\n",
    "  \"Age_Group\",             # Age group\n",
    "  \"Proficiency_Level\",     # Proficiency level\n",
    "  \"English_Major\",         # English major status\n",
    "  \"Education_Stage\"        # Education level\n",
    ")\n",
    "\n",
    "# Category 2: Treatment Characteristics\n",
    "treatment_moderators <- c(\n",
    "  \"Treatment_Duration\",    # Duration category\n",
    "  \"Training_TotalMinute\",  # Total minutes\n",
    "  \"Training_TotalWeeks\",   # Total weeks\n",
    "  \"Training_Context\",      # Training context\n",
    "  \"Feedback_Type\",         # Feedback type\n",
    "  \"Visual_Cue\",            # Visual cue usage\n",
    "  \"Instructor_Type\"        # Instructor type\n",
    ")\n",
    "\n",
    "# Category 3: Linguistic Features\n",
    "linguistic_moderators <- c(\n",
    "  \"Target_Feature\",        # Target feature\n",
    "  \"Focus_Type\"             # Focus type\n",
    ")\n",
    "\n",
    "# Category 4: Methodological Features\n",
    "method_moderators <- c(\n",
    "  \"Design_Type\",           # Study design\n",
    "  \"Comparator_Type\",       # Comparator type\n",
    "  \"Learning_Context\",      # Learning context\n",
    "  \"Rater_Type\",            # Rater type\n",
    "  \"Peer_Interaction\"       # Peer interaction\n",
    ")\n",
    "\n",
    "# Category 5: Outcome Characteristics\n",
    "outcome_moderators <- c(\n",
    "  \"Outcome_Domain\"         # Outcome domain\n",
    ")\n",
    "\n",
    "# Combine all moderators\n",
    "all_moderators <- c(\n",
    "  participant_moderators,\n",
    "  treatment_moderators,\n",
    "  linguistic_moderators,\n",
    "  method_moderators,\n",
    "  outcome_moderators\n",
    ")\n",
    "\n",
    "# Display moderator categories\n",
    "cat(\"  Category 1: Participant Characteristics (n = \", length(participant_moderators), \")\\n\", sep = \"\")\n",
    "for (i in seq_along(participant_moderators)) {\n",
    "  cat(\"    \", i, \". \", participant_moderators[i], \"\\n\", sep = \"\")\n",
    "}\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"  Category 2: Treatment Characteristics (n = \", length(treatment_moderators), \")\\n\", sep = \"\")\n",
    "for (i in seq_along(treatment_moderators)) {\n",
    "  cat(\"    \", i, \". \", treatment_moderators[i], \"\\n\", sep = \"\")\n",
    "}\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"  Category 3: Linguistic Features (n = \", length(linguistic_moderators), \")\\n\", sep = \"\")\n",
    "for (i in seq_along(linguistic_moderators)) {\n",
    "  cat(\"    \", i, \". \", linguistic_moderators[i], \"\\n\", sep = \"\")\n",
    "}\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"  Category 4: Methodological Features (n = \", length(method_moderators), \")\\n\", sep = \"\")\n",
    "for (i in seq_along(method_moderators)) {\n",
    "  cat(\"    \", i, \". \", method_moderators[i], \"\\n\", sep = \"\")\n",
    "}\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"  Category 5: Outcome Characteristics (n = \", length(outcome_moderators), \")\\n\", sep = \"\")\n",
    "for (i in seq_along(outcome_moderators)) {\n",
    "  cat(\"    \", i, \". \", outcome_moderators[i], \"\\n\", sep = \"\")\n",
    "}\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"  TOTAL CANDIDATE MODERATORS: \", length(all_moderators), \"\\n\", sep = \"\")\n",
    "cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Filter to only include moderators present in dataset\n",
    "available_moderators <- intersect(all_moderators, names(df))\n",
    "missing_moderators <- setdiff(all_moderators, names(df))\n",
    "\n",
    "if (length(missing_moderators) > 0) {\n",
    "  cat(\"  ⚠️  WARNING: \", length(missing_moderators), \" moderator(s) not in dataset:\\n\", sep = \"\")\n",
    "  for (mod in missing_moderators) {\n",
    "    cat(\"     - \", mod, \"\\n\", sep = \"\")\n",
    "  }\n",
    "  cat(\"\\n\")\n",
    "}\n",
    "\n",
    "cat(\"  ✅ Available moderators: \", length(available_moderators), \"/\", \n",
    "    length(all_moderators), \"\\n\", sep = \"\")\n",
    "\n",
    "# Update moderator list\n",
    "all_moderators <- available_moderators\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 2.1.2: Iterate Through Moderators\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 2.1.2: Running univariate meta-regressions...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "# Initialize storage\n",
    "univariate_results_list <- list()\n",
    "skipped_moderators <- data.frame(\n",
    "  Moderator = character(),\n",
    "  Reason = character(),\n",
    "  stringsAsFactors = FALSE\n",
    ")\n",
    "usable_moderators <- character()\n",
    "\n",
    "for (mod in all_moderators) {\n",
    "  cat(\"  Testing moderator: \", mod, \"\\n\", sep = \"\")\n",
    "  \n",
    "  # Create temporary dataset with complete cases for this moderator\n",
    "  df_temp <- df[!is.na(df[[mod]]) & !is.na(df$Hedges_g) & !is.na(df$vi), ]\n",
    "  \n",
    "  # Check sample size\n",
    "  n_complete <- nrow(df_temp)\n",
    "  if (n_complete < 5) {\n",
    "    cat(\"    ⚠️  SKIPPED: Insufficient data (n = \", n_complete, \")\\n\\n\", sep = \"\")\n",
    "    skipped_moderators <- rbind(\n",
    "      skipped_moderators,\n",
    "      data.frame(Moderator = mod, Reason = paste0(\"n < 5 (n=\", n_complete, \")\"))\n",
    "    )\n",
    "    next\n",
    "  }\n",
    "  \n",
    "  # Check number of levels for categorical moderators\n",
    "  if (is.character(df_temp[[mod]]) || is.factor(df_temp[[mod]])) {\n",
    "    n_levels <- length(unique(df_temp[[mod]]))\n",
    "    if (n_levels < 2) {\n",
    "      cat(\"    ⚠️  SKIPPED: Insufficient levels (k = \", n_levels, \")\\n\\n\", sep = \"\")\n",
    "      skipped_moderators <- rbind(\n",
    "        skipped_moderators,\n",
    "        data.frame(Moderator = mod, Reason = paste0(\"k < 2 (k=\", n_levels, \")\"))\n",
    "      )\n",
    "      next\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Fit univariate meta-regression\n",
    "  mod_formula <- as.formula(paste(\"Hedges_g ~\", mod))\n",
    "  \n",
    "  res_mod <- tryCatch(\n",
    "    {\n",
    "      rma(yi = Hedges_g, \n",
    "          vi = df_temp$vi,  # Explicitly use dataframe column\n",
    "          mods = mod_formula, \n",
    "          data = df_temp, \n",
    "          method = \"REML\")\n",
    "    },\n",
    "    error = function(e) {\n",
    "      cat(\"    ❌ ERROR: \", e$message, \"\\n\\n\", sep = \"\")\n",
    "      return(NULL)\n",
    "    }\n",
    "  )\n",
    "  \n",
    "  # Check if model fitted successfully\n",
    "  if (is.null(res_mod)) {\n",
    "    skipped_moderators <- rbind(\n",
    "      skipped_moderators,\n",
    "      data.frame(Moderator = mod, Reason = \"Model convergence failure\")\n",
    "    )\n",
    "    next\n",
    "  }\n",
    "  \n",
    "  # Calculate pseudo-R²\n",
    "  # R² = (τ²_overall - τ²_moderator) / τ²_overall × 100%\n",
    "  R2 <- max(0, (tau2 - res_mod$tau2) / tau2 * 100)\n",
    "  \n",
    "  # Store results\n",
    "  univariate_results_list[[mod]] <- list(\n",
    "    model = res_mod,\n",
    "    moderator = mod,\n",
    "    k = res_mod$k,\n",
    "    QM = res_mod$QM,\n",
    "    QMp = res_mod$QMp,\n",
    "    tau2 = res_mod$tau2,\n",
    "    R2 = R2\n",
    "  )\n",
    "  \n",
    "  usable_moderators <- c(usable_moderators, mod)\n",
    "  \n",
    "  # Display summary\n",
    "  cat(\"    ✅ Model fitted successfully\\n\")\n",
    "  cat(\"       k = \", res_mod$k, \", QM = \", sprintf(\"%.4f\", res_mod$QM), \n",
    "      \", p = \", sprintf(\"%.4f\", res_mod$QMp), \"\\n\", sep = \"\")\n",
    "  cat(\"       τ² = \", sprintf(\"%.4f\", res_mod$tau2), \", R² = \", \n",
    "      sprintf(\"%.2f\", R2), \"%\\n\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "# Summary statistics\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\")\n",
    "cat(\"  SUMMARY:\\n\")\n",
    "cat(\"    Total candidate moderators:  \", length(all_moderators), \"\\n\", sep = \"\")\n",
    "cat(\"    Successfully fitted models:  \", length(usable_moderators), \"\\n\", sep = \"\")\n",
    "cat(\"    Skipped moderators:          \", nrow(skipped_moderators), \"\\n\", sep = \"\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "if (nrow(skipped_moderators) > 0) {\n",
    "  cat(\"  Skipped moderators:\\n\")\n",
    "  for (i in 1:nrow(skipped_moderators)) {\n",
    "    cat(\"    - \", skipped_moderators$Moderator[i], \": \", \n",
    "        skipped_moderators$Reason[i], \"\\n\", sep = \"\")\n",
    "  }\n",
    "  cat(\"\\n\")\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 2.1.3: Create Summary Table\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 2.1.3: Creating summary table...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "# Compile univariate results\n",
    "univariate_summary <- data.frame(\n",
    "  Moderator = character(),\n",
    "  k = integer(),\n",
    "  QM = numeric(),\n",
    "  df_QM = integer(),\n",
    "  p_QM = numeric(),\n",
    "  tau2 = numeric(),\n",
    "  R2 = numeric(),\n",
    "  stringsAsFactors = FALSE\n",
    ")\n",
    "\n",
    "for (mod in usable_moderators) {\n",
    "  res <- univariate_results_list[[mod]]\n",
    "  \n",
    "  univariate_summary <- rbind(\n",
    "    univariate_summary,\n",
    "    data.frame(\n",
    "      Moderator = mod,\n",
    "      k = res$k,\n",
    "      QM = round(res$QM, 4),\n",
    "      df_QM = res$model$p - 1,\n",
    "      p_QM = round(res$QMp, 4),\n",
    "      tau2 = round(res$tau2, 4),\n",
    "      R2 = round(res$R2, 2),\n",
    "      stringsAsFactors = FALSE\n",
    "    )\n",
    "  )\n",
    "}\n",
    "\n",
    "# Display top 5 moderators by R²\n",
    "cat(\"  Top 5 moderators by R²:\\n\")\n",
    "top5 <- univariate_summary[order(-univariate_summary$R2), ][1:min(5, nrow(univariate_summary)), ]\n",
    "for (i in 1:nrow(top5)) {\n",
    "  cat(\"    \", i, \". \", top5$Moderator[i], \": R² = \", top5$R2[i], \n",
    "      \"%, p = \", sprintf(\"%.4f\", top5$p_QM[i]), \"\\n\", sep = \"\")\n",
    "}\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 2.1.4: Export Univariate Results\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 2.1.4: Exporting univariate results...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\")\n",
    "\n",
    "# Create output directory for Step 2\n",
    "step2_dir <- file.path(getwd(), \"Meta_Analysis_Results\", \"Step2_Moderator_Analysis\")\n",
    "if (!dir.exists(step2_dir)) {\n",
    "  dir.create(step2_dir, recursive = TRUE)\n",
    "}\n",
    "\n",
    "# Write CSV file using safe write function\n",
    "safe_write_csv(univariate_summary, \"univariate_moderator_summary.csv\", output_dir = step2_dir)\n",
    "\n",
    "cat(\"  ✅ Univariate summary saved to: \", step2_dir, \"\\n\", sep = \"\")\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Generate detailed univariate_moderator_results.csv with level-by-level info\n",
    "cat(\"Step 2.1.3b: Generating detailed level-by-level results...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "univariate_results_detailed <- data.frame(\n",
    "  Moderator = character(),\n",
    "  Level = character(),\n",
    "  Type = character(),\n",
    "  n = integer(),\n",
    "  Estimate = numeric(),\n",
    "  SE = numeric(),\n",
    "  CI_Lower = numeric(),\n",
    "  CI_Upper = numeric(),\n",
    "  z_value = numeric(),\n",
    "  p_value = numeric(),\n",
    "  QM = numeric(),\n",
    "  QM_p = numeric(),\n",
    "  tau2_residual = numeric(),\n",
    "  I2_residual = numeric(),\n",
    "  R2 = numeric(),\n",
    "  stringsAsFactors = FALSE\n",
    ")\n",
    "\n",
    "for (mod in usable_moderators) {\n",
    "  res_mod <- univariate_results_list[[mod]]$model\n",
    "  mod_name <- mod\n",
    "  \n",
    "  # Determine moderator type\n",
    "  df_temp <- df[!is.na(df[[mod]]) & !is.na(df$Hedges_g) & !is.na(df$vi), ]\n",
    "  is_categorical <- is.character(df_temp[[mod]]) || is.factor(df_temp[[mod]])\n",
    "  mod_type <- ifelse(is_categorical, \"Categorical\", \"Continuous\")\n",
    "  \n",
    "  # Extract model results\n",
    "  n_coefs <- length(res_mod$b)\n",
    "  \n",
    "  if (n_coefs == 0) {\n",
    "    next  # Skip if no coefficients\n",
    "  }\n",
    "  \n",
    "  omnibus_QM <- res_mod$QM\n",
    "  omnibus_QMp <- res_mod$QMp\n",
    "  tau2_res <- res_mod$tau2\n",
    "  I2_res <- res_mod$I2\n",
    "  R2_val <- max(0, (tau2 - res_mod$tau2) / tau2 * 100)\n",
    "  \n",
    "  # Extract coefficients for each level\n",
    "  for (i in 1:n_coefs) {\n",
    "    # Get coefficient name safely\n",
    "    coef_names <- names(res_mod$b)\n",
    "    if (is.null(coef_names) || length(coef_names) < i) {\n",
    "      level_name <- paste0(\"Level_\", i)\n",
    "    } else {\n",
    "      level_name <- coef_names[i]\n",
    "    }\n",
    "    \n",
    "    # Determine level label\n",
    "    if (is_categorical) {\n",
    "      # For categorical, create meaningful labels\n",
    "      if (grepl(\"intrcpt\", level_name, ignore.case = TRUE) || i == 1) {\n",
    "        level_label <- paste0(mod_name, \" (Baseline)\")\n",
    "      } else {\n",
    "        # Extract level name from coefficient name\n",
    "        level_label <- gsub(paste0(\"^\", mod_name), \"\", level_name)\n",
    "        level_label <- trimws(level_label)\n",
    "        if (level_label == \"\") {\n",
    "          level_label <- paste0(mod_name, \" Level \", i)\n",
    "        }\n",
    "      }\n",
    "    } else {\n",
    "      # For continuous, use moderator name\n",
    "      level_label <- mod_name\n",
    "    }\n",
    "    \n",
    "    # Count studies for this level\n",
    "    if (is_categorical && !grepl(\"Baseline\", level_label)) {\n",
    "      # Try to match the level name in the data\n",
    "      n_studies <- sum(df_temp[[mod]] == level_label, na.rm = TRUE)\n",
    "      if (n_studies == 0) {\n",
    "        n_studies <- nrow(df_temp) / n_coefs  # Estimate if can't find exact match\n",
    "      }\n",
    "    } else {\n",
    "      n_studies <- nrow(df_temp)\n",
    "    }\n",
    "    \n",
    "    # Add row to detailed results\n",
    "    univariate_results_detailed <- rbind(\n",
    "      univariate_results_detailed,\n",
    "      data.frame(\n",
    "        Moderator = mod_name,\n",
    "        Level = level_label,\n",
    "        Type = mod_type,\n",
    "        n = as.integer(n_studies),\n",
    "        Estimate = round(as.numeric(res_mod$b[i]), 4),\n",
    "        SE = round(res_mod$se[i], 4),\n",
    "        CI_Lower = round(res_mod$ci.lb[i], 4),\n",
    "        CI_Upper = round(res_mod$ci.ub[i], 4),\n",
    "        z_value = round(res_mod$zval[i], 4),\n",
    "        p_value = round(res_mod$pval[i], 4),\n",
    "        QM = round(omnibus_QM, 4),\n",
    "        QM_p = round(omnibus_QMp, 4),\n",
    "        tau2_residual = round(tau2_res, 4),\n",
    "        I2_residual = round(I2_res, 2),\n",
    "        R2 = round(R2_val, 2),\n",
    "        stringsAsFactors = FALSE\n",
    "      )\n",
    "    )\n",
    "  }\n",
    "}\n",
    "\n",
    "# Save detailed results\n",
    "if (nrow(univariate_results_detailed) > 0) {\n",
    "  safe_write_csv(univariate_results_detailed, \"univariate_moderator_results.csv\", output_dir = step2_dir)\n",
    "  cat(\"  ✅ Detailed level-by-level results saved\\n\")\n",
    "  cat(\"     Rows: \", nrow(univariate_results_detailed), \"\\n\", sep = \"\")\n",
    "} else {\n",
    "  cat(\"  ⚠️  No detailed results generated\\n\")\n",
    "}\n",
    "cat(\"\\n\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 2.1.5: Identify Significant Moderators (p < .05)\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 2.1.7: Identifying significant moderators (p < .05)...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "# Filter for significant moderators\n",
    "significant_moderators <- univariate_summary[univariate_summary$p_QM < 0.05, ]\n",
    "\n",
    "cat(\"  Found \", nrow(significant_moderators), \" significant moderator(s):\\n\\n\", sep = \"\")\n",
    "\n",
    "if (nrow(significant_moderators) > 0) {\n",
    "  for (i in 1:nrow(significant_moderators)) {\n",
    "    row <- significant_moderators[i, ]\n",
    "    cat(\"    \", i, \". \", row$Moderator, \"\\n\", sep = \"\")\n",
    "    cat(\"       QM = \", sprintf(\"%.4f\", row$QM), \" (df = \", row$df_QM, \n",
    "        \", p = \", sprintf(\"%.4f\", row$p_QM), \")\\n\", sep = \"\")\n",
    "    cat(\"       τ² = \", sprintf(\"%.4f\", row$tau2), \", R² = \", \n",
    "        sprintf(\"%.2f\", row$R2), \"%\\n\\n\", sep = \"\")\n",
    "  }\n",
    "} else {\n",
    "  cat(\"    (none)\\n\\n\")\n",
    "}\n",
    "\n",
    "# Store significant moderator names for multivariate analysis\n",
    "significant_mod_names <- significant_moderators$Moderator\n",
    "\n",
    "cat(\"  ✅ Significant moderators stored for multivariate analysis\\n\")\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"✅ STEP 2.1 COMPLETE: Univariate moderator analysis complete\\n\")\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 2.2: Multivariate Moderator Analysis\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"================================================================================\\n\")\n",
    "cat(\"STEP 2.2: MULTIVARIATE MODERATOR ANALYSIS\\n\")\n",
    "cat(\"================================================================================\\n\\n\")\n",
    "\n",
    "# Check if there are significant moderators\n",
    "if (length(significant_mod_names) == 0) {\n",
    "  cat(\"  ⚠️  No significant moderators found (all p ≥ .05)\\n\")\n",
    "  cat(\"  ⚠️  Skipping multivariate analysis\\n\\n\")\n",
    "  \n",
    "  cat(\"✅ STEP 2.2 COMPLETE: Multivariate analysis skipped\\n\")\n",
    "  cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "  \n",
    "  run_multivariate <- FALSE\n",
    "} else {\n",
    "  run_multivariate <- TRUE\n",
    "  \n",
    "  # ----------------------------------------------------------------------------\n",
    "  # Step 2.2.1: Define Multivariate Model\n",
    "  # ----------------------------------------------------------------------------\n",
    "  cat(\"Step 2.2.1: Building multivariate model...\\n\")\n",
    "  cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "  \n",
    "  cat(\"  Including \", length(significant_mod_names), \" significant moderator(s):\\n\", sep = \"\")\n",
    "  for (i in seq_along(significant_mod_names)) {\n",
    "    cat(\"    \", i, \". \", significant_mod_names[i], \"\\n\", sep = \"\")\n",
    "  }\n",
    "  cat(\"\\n\")\n",
    "  \n",
    "  # Create formula\n",
    "  formula_str <- paste(\"Hedges_g ~\", paste(significant_mod_names, collapse = \" + \"))\n",
    "  multi_formula <- as.formula(formula_str)\n",
    "  \n",
    "  cat(\"  Formula: \", formula_str, \"\\n\\n\", sep = \"\")\n",
    "  \n",
    "  # ----------------------------------------------------------------------------\n",
    "  # Step 2.2.2: Prepare Dataset\n",
    "  # ----------------------------------------------------------------------------\n",
    "  cat(\"Step 2.2.2: Preparing dataset...\\n\")\n",
    "  cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\")\n",
    "  \n",
    "  # Create complete-case dataset\n",
    "  required_vars <- c(\"Hedges_g\", \"vi\", significant_mod_names)\n",
    "  df_multi <- df[complete.cases(df[, required_vars]), ]\n",
    "  \n",
    "  cat(\"  Original dataset:     \", nrow(df), \" rows\\n\", sep = \"\")\n",
    "  cat(\"  Complete-case data:   \", nrow(df_multi), \" rows\\n\", sep = \"\")\n",
    "  cat(\"  Missing data removed: \", nrow(df) - nrow(df_multi), \" rows\\n\\n\", sep = \"\")\n",
    "  \n",
    "  # Check sample size\n",
    "  if (nrow(df_multi) < 10) {\n",
    "    cat(\"  ⚠️  WARNING: Very small sample size (n = \", nrow(df_multi), \")\\n\", sep = \"\")\n",
    "    cat(\"  ⚠️  Results may be unreliable\\n\\n\")\n",
    "  }\n",
    "  \n",
    "  # ----------------------------------------------------------------------------\n",
    "  # Step 2.2.3: Fit Multivariate Model\n",
    "  # ----------------------------------------------------------------------------\n",
    "  cat(\"Step 2.2.3: Fitting multivariate meta-regression...\\n\")\n",
    "  cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\")\n",
    "  \n",
    "  res_multi <- tryCatch(\n",
    "    {\n",
    "      rma(yi = Hedges_g, \n",
    "          vi = vi, \n",
    "          mods = multi_formula, \n",
    "          data = df_multi, \n",
    "          method = \"REML\")\n",
    "    },\n",
    "    error = function(e) {\n",
    "      cat(\"  ❌ ERROR: Model fitting failed\\n\")\n",
    "      cat(\"     Message: \", e$message, \"\\n\\n\", sep = \"\")\n",
    "      return(NULL)\n",
    "    }\n",
    "  )\n",
    "  \n",
    "  # Check if model fitted successfully\n",
    "  if (is.null(res_multi)) {\n",
    "    cat(\"  ⚠️  Multivariate model could not be fitted\\n\")\n",
    "    cat(\"  ⚠️  Possible reasons:\\n\")\n",
    "    cat(\"       - Too many moderators relative to sample size\\n\")\n",
    "    cat(\"       - Multicollinearity among moderators\\n\")\n",
    "    cat(\"       - Convergence issues\\n\\n\")\n",
    "    \n",
    "    run_multivariate <- FALSE\n",
    "    \n",
    "  } else {\n",
    "    cat(\"  ✅ Model fitted successfully\\n\\n\")\n",
    "    \n",
    "    # ----------------------------------------------------------------------------\n",
    "    # Step 2.2.4: Display Multivariate Results\n",
    "    # ----------------------------------------------------------------------------\n",
    "    cat(\"Step 2.2.4: Multivariate meta-regression results...\\n\")\n",
    "    cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "    \n",
    "    # Model-level statistics\n",
    "    cat(\"  MODEL-LEVEL STATISTICS:\\n\")\n",
    "    cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "    cat(\"    k (studies):         \", res_multi$k, \"\\n\", sep = \"\")\n",
    "    cat(\"    QM (omnibus test):   \", sprintf(\"%.4f\", res_multi$QM), \n",
    "        \" (df = \", res_multi$p - 1, \", p = \", sprintf(\"%.4f\", res_multi$QMp), \")\\n\", sep = \"\")\n",
    "    cat(\"    QE (residual het.):  \", sprintf(\"%.4f\", res_multi$QE), \n",
    "        \" (df = \", res_multi$k - res_multi$p, \", p = \", sprintf(\"%.4f\", res_multi$QEp), \")\\n\", sep = \"\")\n",
    "    cat(\"    τ² (residual):       \", sprintf(\"%.4f\", res_multi$tau2), \"\\n\", sep = \"\")\n",
    "    cat(\"    I² (residual):       \", sprintf(\"%.2f\", res_multi$I2), \"%\\n\", sep = \"\")\n",
    "    \n",
    "    # Calculate pseudo-R²\n",
    "    # R² = (τ²_baseline - τ²_multivariate) / τ²_baseline\n",
    "    R2_multi <- max(0, (tau2 - res_multi$tau2) / tau2 * 100)\n",
    "    cat(\"    Pseudo-R²:           \", sprintf(\"%.2f\", R2_multi), \"%\\n\", sep = \"\")\n",
    "    \n",
    "    cat(\"\\n\")\n",
    "    \n",
    "    # Coefficient table\n",
    "    cat(\"  REGRESSION COEFFICIENTS:\\n\")\n",
    "    cat(\"  \", paste0(rep(\"=\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "    cat(\"\\n\")\n",
    "    \n",
    "    coef_table <- data.frame(\n",
    "      Moderator = rownames(res_multi$b),\n",
    "      Estimate = as.numeric(res_multi$b),\n",
    "      SE = res_multi$se,\n",
    "      CI_Lower = res_multi$ci.lb,\n",
    "      CI_Upper = res_multi$ci.ub,\n",
    "      z_value = res_multi$zval,\n",
    "      p_value = res_multi$pval,\n",
    "      stringsAsFactors = FALSE\n",
    "    )\n",
    "    \n",
    "    for (i in 1:nrow(coef_table)) {\n",
    "      row <- coef_table[i, ]\n",
    "      \n",
    "      # Determine significance\n",
    "      if (row$p_value < 0.001) {\n",
    "        sig_marker <- \"***\"\n",
    "        sig_level <- \"p < .001\"\n",
    "      } else if (row$p_value < 0.01) {\n",
    "        sig_marker <- \"**\"\n",
    "        sig_level <- \"p < .01\"\n",
    "      } else if (row$p_value < 0.05) {\n",
    "        sig_marker <- \"*\"\n",
    "        sig_level <- \"p < .05\"\n",
    "      } else {\n",
    "        sig_marker <- \"\"\n",
    "        sig_level <- \"n.s.\"\n",
    "      }\n",
    "      \n",
    "      cat(\"  \", row$Moderator, \" \", sig_marker, \"\\n\", sep = \"\")\n",
    "      cat(\"    β = \", sprintf(\"%.4f\", row$Estimate), \n",
    "          \" [\", sprintf(\"%.4f\", row$CI_Lower), \", \", \n",
    "          sprintf(\"%.4f\", row$CI_Upper), \"]\\n\", sep = \"\")\n",
    "      cat(\"    z = \", sprintf(\"%.4f\", row$z_value), \n",
    "          \", p = \", sprintf(\"%.4f\", row$p_value), \" (\", sig_level, \")\\n\", sep = \"\")\n",
    "      cat(\"\\n\")\n",
    "    }\n",
    "    \n",
    "    # ----------------------------------------------------------------------------\n",
    "    # Step 2.2.5: Export Multivariate Results (SAFE VERSION)\n",
    "    # ----------------------------------------------------------------------------\n",
    "    cat(\"Step 2.2.5: Exporting multivariate results...\\n\")\n",
    "    cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "    \n",
    "    # Get coefficient names from the fitted model\n",
    "    coef_names <- rownames(res_multi$b)\n",
    "    \n",
    "    cat(\"  Raw coefficient names from model:\\n\")\n",
    "    for (i in seq_along(coef_names)) {\n",
    "      cat(\"    \", i, \". \", coef_names[i], \"\\n\", sep = \"\")\n",
    "    }\n",
    "    cat(\"\\n\")\n",
    "    \n",
    "    # ----------------------------------------------------------------------------\n",
    "    # SAFE PARSING LOGIC\n",
    "    # ----------------------------------------------------------------------------\n",
    "    # Strategy:\n",
    "    # 1. Get model.matrix to identify TRUE variable types\n",
    "    # 2. For each coefficient, determine if it's:\n",
    "    #    - Intercept\n",
    "    #    - Continuous moderator (numeric variable)\n",
    "    #    - Categorical level (factor dummy variable)\n",
    "    # 3. NEVER assume coef_name == mod means anything - check actual data type\n",
    "    # ----------------------------------------------------------------------------\n",
    "    \n",
    "    # Get model matrix to understand variable structure\n",
    "    X <- model.matrix(res_multi)\n",
    "    \n",
    "    # Identify moderator types from original data\n",
    "    continuous_mods <- character()\n",
    "    categorical_mods <- character()\n",
    "    \n",
    "    for (mod in significant_mod_names) {\n",
    "      if (is.numeric(df_multi[[mod]])) {\n",
    "        continuous_mods <- c(continuous_mods, mod)\n",
    "      } else {\n",
    "        categorical_mods <- c(categorical_mods, mod)\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    cat(\"  Moderator type detection:\\n\")\n",
    "    cat(\"    Continuous moderators (n=\", length(continuous_mods), \"):\\n\", sep = \"\")\n",
    "    for (mod in continuous_mods) {\n",
    "      cat(\"      - \", mod, \"\\n\", sep = \"\")\n",
    "    }\n",
    "    cat(\"    Categorical moderators (n=\", length(categorical_mods), \"):\\n\", sep = \"\")\n",
    "    for (mod in categorical_mods) {\n",
    "      cat(\"      - \", mod, \"\\n\", sep = \"\")\n",
    "    }\n",
    "    cat(\"\\n\")\n",
    "    \n",
    "    # Parse each coefficient\n",
    "    parsed_coefficients <- list()\n",
    "    \n",
    "    for (coef_name in coef_names) {\n",
    "      # Handle intercept\n",
    "      if (coef_name == \"intrcpt\" || coef_name == \"(Intercept)\") {\n",
    "        parsed_coefficients[[length(parsed_coefficients) + 1]] <- list(\n",
    "          original_name = coef_name,\n",
    "          moderator_family = \"Intercept\",\n",
    "          level_label = \"Intercept\",\n",
    "          type = \"intercept\"\n",
    "        )\n",
    "        next\n",
    "      }\n",
    "      \n",
    "      # Check if this is a continuous moderator\n",
    "      # For continuous: coefficient name == moderator name (exact match)\n",
    "      if (coef_name %in% continuous_mods) {\n",
    "        parsed_coefficients[[length(parsed_coefficients) + 1]] <- list(\n",
    "          original_name = coef_name,\n",
    "          moderator_family = coef_name,\n",
    "          level_label = coef_name,  # Use full name as label\n",
    "          type = \"continuous\"\n",
    "        )\n",
    "        next\n",
    "      }\n",
    "      \n",
    "      # For categorical moderators: try to match moderator family\n",
    "      matched <- FALSE\n",
    "      for (cat_mod in categorical_mods) {\n",
    "        # Check if coefficient name contains this categorical moderator\n",
    "        # e.g., \"L1Arabic\" contains \"L1\", \"Education_StageUndergraduate\" contains \"Education_Stage\"\n",
    "        if (grepl(paste0(\"^\", cat_mod), coef_name)) {\n",
    "          # Extract level label by removing moderator prefix\n",
    "          level_label <- sub(paste0(\"^\", cat_mod), \"\", coef_name)\n",
    "          \n",
    "          # CRITICAL: If level_label is empty after removal, this means\n",
    "          # coef_name == cat_mod, which should NEVER happen for categorical moderators\n",
    "          # This would be a parsing error - skip it\n",
    "          if (level_label == \"\" || nchar(level_label) == 0) {\n",
    "            cat(\"  ⚠️  WARNING: Skipping invalid coefficient '\", coef_name, \n",
    "                \"' (categorical moderator without level)\\n\", sep = \"\")\n",
    "            matched <- TRUE\n",
    "            break\n",
    "          }\n",
    "          \n",
    "          parsed_coefficients[[length(parsed_coefficients) + 1]] <- list(\n",
    "            original_name = coef_name,\n",
    "            moderator_family = cat_mod,\n",
    "            level_label = level_label,\n",
    "            type = \"categorical\"\n",
    "          )\n",
    "          matched <- TRUE\n",
    "          break\n",
    "        }\n",
    "      }\n",
    "      \n",
    "      # If no match found, this is an unknown coefficient - skip it\n",
    "      if (!matched) {\n",
    "        cat(\"  ⚠️  WARNING: Could not parse coefficient '\", coef_name, \"' - skipping\\n\", sep = \"\")\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    cat(\"\\n  Parsed \", length(parsed_coefficients), \" valid coefficients\\n\\n\", sep = \"\")\n",
    "    \n",
    "    # Create export dataframe\n",
    "    coef_export <- data.frame(\n",
    "      Moderator_Family = character(),\n",
    "      Level_Label = character(),\n",
    "      Estimate = numeric(),\n",
    "      SE = numeric(),\n",
    "      CI_Lower = numeric(),\n",
    "      CI_Upper = numeric(),\n",
    "      z_value = numeric(),\n",
    "      p_value = numeric(),\n",
    "      stringsAsFactors = FALSE\n",
    "    )\n",
    "    \n",
    "    # Add parsed coefficients to export\n",
    "    for (i in seq_along(parsed_coefficients)) {\n",
    "      parsed <- parsed_coefficients[[i]]\n",
    "      \n",
    "      # Find matching row in res_multi results\n",
    "      coef_idx <- which(coef_names == parsed$original_name)\n",
    "      \n",
    "      coef_export <- rbind(coef_export, data.frame(\n",
    "        Moderator_Family = parsed$moderator_family,\n",
    "        Level_Label = parsed$level_label,\n",
    "        Estimate = round(as.numeric(res_multi$b[coef_idx]), 4),\n",
    "        SE = round(res_multi$se[coef_idx], 4),\n",
    "        CI_Lower = round(res_multi$ci.lb[coef_idx], 4),\n",
    "        CI_Upper = round(res_multi$ci.ub[coef_idx], 4),\n",
    "        z_value = round(res_multi$zval[coef_idx], 4),\n",
    "        p_value = round(res_multi$pval[coef_idx], 4),\n",
    "        stringsAsFactors = FALSE\n",
    "      ))\n",
    "    }\n",
    "    \n",
    "    # ----------------------------------------------------------------------------\n",
    "    # Add baseline rows for categorical moderators\n",
    "    # ----------------------------------------------------------------------------\n",
    "    cat(\"  Adding baseline rows for categorical moderators...\\n\")\n",
    "    \n",
    "    # Get unique categorical moderators that appear in the export\n",
    "    categorical_mods_in_export <- unique(coef_export$Moderator_Family[\n",
    "      coef_export$Moderator_Family != \"Intercept\" &\n",
    "      coef_export$Moderator_Family %in% categorical_mods\n",
    "    ])\n",
    "    \n",
    "    baseline_rows <- list()\n",
    "    \n",
    "    for (cat_mod in categorical_mods_in_export) {\n",
    "      # Get baseline from BASELINE_LEVELS\n",
    "      baseline_level <- NULL\n",
    "      \n",
    "      # Try BASELINE_<Moderator> variable\n",
    "      baseline_var_name <- paste0(\"BASELINE_\", cat_mod)\n",
    "      if (exists(baseline_var_name)) {\n",
    "        baseline_level <- get(baseline_var_name)\n",
    "      } else if (exists(\"BASELINE_LEVELS\") && cat_mod %in% names(BASELINE_LEVELS)) {\n",
    "        baseline_level <- BASELINE_LEVELS[[cat_mod]]\n",
    "      }\n",
    "      \n",
    "      # Only add baseline if we found it\n",
    "      if (!is.null(baseline_level)) {\n",
    "        baseline_rows[[length(baseline_rows) + 1]] <- data.frame(\n",
    "          Moderator_Family = cat_mod,\n",
    "          Level_Label = baseline_level,\n",
    "          Estimate = 0.0000,\n",
    "          SE = 0.0000,\n",
    "          CI_Lower = 0.0000,\n",
    "          CI_Upper = 0.0000,\n",
    "          z_value = 0.0000,\n",
    "          p_value = 1.0000,\n",
    "          stringsAsFactors = FALSE\n",
    "        )\n",
    "        \n",
    "        cat(\"    ✅ Added baseline for \", cat_mod, \": \", baseline_level, \"\\n\", sep = \"\")\n",
    "      } else {\n",
    "        cat(\"    ⚠️  No baseline found for \", cat_mod, \"\\n\", sep = \"\")\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    cat(\"\\n\")\n",
    "    \n",
    "    # Combine with baseline rows\n",
    "    if (length(baseline_rows) > 0) {\n",
    "      coef_export <- rbind(coef_export, do.call(rbind, baseline_rows))\n",
    "      \n",
    "      # Sort: Intercept first, then by Moderator_Family, then by level\n",
    "      # Within each family: contrasts first, baseline last (Estimate=0)\n",
    "      coef_export <- coef_export[order(\n",
    "        -(coef_export$Moderator_Family == \"Intercept\"),  # Intercept first\n",
    "        coef_export$Moderator_Family,                     # Alphabetical by family\n",
    "        -(coef_export$Estimate == 0),                     # Baseline last within family\n",
    "        coef_export$Level_Label                           # Alphabetical by level\n",
    "      ), ]\n",
    "    }\n",
    "    \n",
    "    # Display final export structure\n",
    "    cat(\"  Final export structure:\\n\")\n",
    "    cat(\"    Total rows:       \", nrow(coef_export), \"\\n\", sep = \"\")\n",
    "    cat(\"    Intercept:        \", sum(coef_export$Moderator_Family == \"Intercept\"), \"\\n\", sep = \"\")\n",
    "    cat(\"    Continuous:       \", sum(coef_export$Moderator_Family %in% continuous_mods & \n",
    "                                       coef_export$Estimate != 0), \"\\n\", sep = \"\")\n",
    "    cat(\"    Categorical:      \", sum(coef_export$Moderator_Family %in% categorical_mods & \n",
    "                                       coef_export$Estimate != 0), \"\\n\", sep = \"\")\n",
    "    cat(\"    Baselines:        \", sum(coef_export$Estimate == 0 & \n",
    "                                       coef_export$Moderator_Family != \"Intercept\"), \"\\n\\n\", sep = \"\")\n",
    "    \n",
    "    # Model fit statistics\n",
    "    model_fit <- data.frame(\n",
    "      Statistic = c(\"k\", \"QM\", \"QM_df\", \"QM_p\", \"QE\", \"QE_df\", \"QE_p\", \n",
    "                    \"tau2\", \"I2\", \"Pseudo_R2\"),\n",
    "      Value = c(\n",
    "        res_multi$k,\n",
    "        round(res_multi$QM, 4),\n",
    "        res_multi$p - 1,\n",
    "        round(res_multi$QMp, 4),\n",
    "        round(res_multi$QE, 4),\n",
    "        res_multi$k - res_multi$p,\n",
    "        round(res_multi$QEp, 4),\n",
    "        round(res_multi$tau2, 4),\n",
    "        round(res_multi$I2, 2),\n",
    "        round(R2_multi, 2)\n",
    "      ),\n",
    "      stringsAsFactors = FALSE\n",
    "    )\n",
    "    \n",
    "    # Verify step2_dir exists\n",
    "    if (!exists(\"step2_dir\") || is.null(step2_dir)) {\n",
    "      step2_dir <- file.path(getwd(), \"Meta_Analysis_Results\", \"Step2_Moderator_Analysis\")\n",
    "      if (!dir.exists(step2_dir)) dir.create(step2_dir, recursive = TRUE)\n",
    "    }\n",
    "    \n",
    "    # Write CSV files to Step2 folder\n",
    "    safe_write_csv(coef_export, \"multivariate_model_coefficients.csv\", output_dir = step2_dir)\n",
    "    safe_write_csv(model_fit, \"multivariate_model_fit.csv\", output_dir = step2_dir)\n",
    "    \n",
    "    cat(\"  ✅ Exported coefficients with safe parsing logic\\n\")\n",
    "    cat(\"  ✅ Format: Moderator_Family + Level_Label\\n\")\n",
    "    cat(\"  ✅ Categorical moderators: Family + Level (baselines added with β=0)\\n\")\n",
    "    cat(\"  ✅ Continuous moderators: Family = Level = moderator name\\n\")\n",
    "    \n",
    "    cat(\"\\n\")\n",
    "  }\n",
    "}\n",
    "\n",
    "if (!run_multivariate) {\n",
    "  cat(\"  ⚠️  Multivariate analysis not performed\\n\\n\")\n",
    "  cat(\"✅ STEP 2.2 COMPLETE: Multivariate analysis not performed\\n\")\n",
    "}\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "218e5465",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================ \n",
      "STEP 3.1: LEAVE-ONE-OUT SENSITIVITY ANALYSIS\n",
      "================================================================================ \n",
      "\n",
      "Research Question: Is the overall effect robust to study exclusion?\n",
      "\n",
      "Step 3.1.1: Baseline overall effect (for comparison)...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  BASELINE (All studies included):\n",
      "    Effect size:  g = 0.5272 [0.3781, 0.6763]\n",
      "    p-value:      0.0000 ***\n",
      "    τ²:           0.0882\n",
      "    I²:           54.64%\n",
      "    k:            29 effect sizes\n",
      "\n",
      "Step 3.1.2: Running leave-one-out analysis...\n",
      "-------------------------------------------------------------------------------- \n",
      "  Systematically excluding each effect size...\n",
      "\n",
      "  ✅ Leave-one-out analysis completed\n",
      "     Iterations: \n",
      "\n",
      "Step 3.1.3: Organizing sensitivity results...\n",
      "-------------------------------------------------------------------------------- \n",
      "  ✅ Results organized with change metrics\n",
      "\n",
      "Step 3.1.4: Summary statistics across leave-one-out iterations...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  EFFECT SIZE RANGE WHEN EACH STUDY EXCLUDED:\n",
      "  ----------------------------------------------------------------------------\n",
      "    Minimum:  0.4767\n",
      "    Maximum:  0.5454\n",
      "    Range:    0.0687\n",
      "    Mean:     0.5272\n",
      "    Median:   0.5323\n",
      "    SD:       0.0160\n",
      "\n",
      "  I² RANGE:\n",
      "  ----------------------------------------------------------------------------\n",
      "    Minimum:  34.60%\n",
      "    Maximum:  56.45%\n",
      "    Range:    21.85%\n",
      "\n",
      "Step 3.1.5: Identifying influential studies...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  INFLUENCE DETECTION:\n",
      "  ============================================================================\n",
      "\n",
      "  ⚠️  INFLUENTIAL STUDIES DETECTED: 1/29\n",
      "\n",
      "  1. JamshidiSaleh2021 (JamshidiSaleh2021_Post)\n",
      "     When excluded: g = 0.4767 (change: -9.58%)\n",
      "     I² change: -20.04 percentage points\n",
      "     ⚠️  Large effect on heterogeneity (ΔI² >10%)\n",
      "\n",
      "  ✅ SIGNIFICANCE IS STABLE\n",
      "     Statistical significance consistent across all iterations\n",
      "\n",
      "Step 3.1.6: Sensitivity analysis interpretation...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  ROBUSTNESS ASSESSMENT:\n",
      "  ============================================================================\n",
      "\n",
      "  ✅ CONCLUSION: ROBUST\n",
      "     Minimal influence from individual studies\n",
      "\n",
      "  RECOMMENDATION:\n",
      "     → Report overall effect\n",
      "     → Note influential studies in supplementary materials\n",
      "\n",
      "Step 3.1.7: Exporting leave-one-out results...\n",
      "-------------------------------------------------------------------------------- \n",
      "  ✅ Saved: leave_one_out_analysis.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ STEP 3.1 COMPLETE: Leave-one-out sensitivity analysis finished\n",
      "================================================================================ \n",
      "\n",
      "================================================================================ \n",
      "STEP 3.2: INFLUENCE DIAGNOSTICS\n",
      "================================================================================ \n",
      "\n",
      "Research Question: Are there influential outliers affecting results?\n",
      "\n",
      "Step 3.2.1: Calculating influence diagnostics...\n",
      "-------------------------------------------------------------------------------- \n",
      "  Computing diagnostic metrics:\n",
      "    → Cook's Distance (overall influence)\n",
      "    → DFBETAS (coefficient influence)\n",
      "    → Hat values (leverage)\n",
      "    → Standardized residuals (outliers)\n",
      "\n",
      "  ✅ Diagnostic calculations complete\n",
      "\n",
      "Step 3.2.2: Organizing diagnostic statistics...\n",
      "-------------------------------------------------------------------------------- \n",
      "  ⚠️  DFBETAS not available from influence(), using zeros\n",
      "  Vector lengths: Cook's D = 29, DFBETAS = 29, Hat = 29, Resid = 29\n",
      "  ✅ Diagnostics organized for 29 effect sizes\n",
      "\n",
      "Step 3.2.3: Defining influence thresholds...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  INFLUENCE THRESHOLDS:\n",
      "  ----------------------------------------------------------------------------\n",
      "    Cook's D:         > 0.1481 (4/(k-p-1))\n",
      "    DFBETAS:          > 0.3714 (2/√k)\n",
      "    Hat values:       > 0.0690 (2p/k)\n",
      "    Std. residuals:   > 2 (moderate outlier)\n",
      "                      > 3 (extreme outlier)\n",
      "\n",
      "Step 3.2.4: Identifying influential cases...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  INFLUENCE DETECTION SUMMARY:\n",
      "  ============================================================================\n",
      "\n",
      "    High Cook's D:           1 cases (3.4%)\n",
      "    High DFBETAS:            0 cases (0.0%)\n",
      "    High leverage (hat):     0 cases (0.0%)\n",
      "    Moderate outliers (|r|>2): 2 cases (6.9%)\n",
      "    Extreme outliers (|r|>3):  0 cases (0.0%)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "    TOTAL INFLUENTIAL CASES: 1/29 (3.4%)\n",
      "  ----------------------------------------------------------------------------\n",
      "\n",
      "Step 3.2.5: Detailed information on influential cases...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  ⚠️  INFLUENTIAL CASES DETECTED:\n",
      "  ============================================================================\n",
      "\n",
      "  1. JamshidiSaleh2021 (JamshidiSaleh2021_Post)\n",
      "     Effect size:      g = 1.6410\n",
      "     Cook's D:         0.4411 ⚠️  HIGH\n",
      "     DFBETAS:          0.0000\n",
      "     Hat value:        0.0353\n",
      "     Std. residual:    2.8023 ⚠️  MODERATE OUTLIER\n",
      "     Issues:           high influence\n",
      "\n",
      "  RECOMMENDATIONS:\n",
      "  ----------------------------------------------------------------------------\n",
      "    1. Review influential studies for data accuracy\n",
      "    2. Examine study characteristics (design, sample, etc.)\n",
      "    3. Consider sensitivity analysis excluding influential cases\n",
      "    4. Report results both with and without influential cases\n",
      "\n",
      "Step 3.2.6: Sensitivity analysis excluding influential cases...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  Refitting model without influential cases...\n",
      "    Original k:  29 effect sizes\n",
      "    Excluded:    1 influential cases\n",
      "    Remaining:   28 effect sizes\n",
      "\n",
      "  ✅ Robust model fitted\n",
      "\n",
      "  COMPARISON: ORIGINAL vs. ROBUST (without influential cases)\n",
      "  ============================================================================\n",
      "\n",
      "  Effect size:\n",
      "    Original:  g = 0.5272 [0.3781, 0.6763]\n",
      "    Robust:    g = 0.4767 [0.3508, 0.6027]\n",
      "    Change:    -0.0505 (-9.6%)\n",
      "\n",
      "  Statistical significance:\n",
      "    Original:  p = 0.0000 ***\n",
      "    Robust:    p = 0.0000 ***\n",
      "    → Significance UNCHANGED\n",
      "\n",
      "  Heterogeneity:\n",
      "    Original:  I² = 54.64%, τ² = 0.0882\n",
      "    Robust:    I² = 34.60%, τ² = 0.0387\n",
      "\n",
      "  ⚠️  INTERPRETATION: Results are MODERATELY AFFECTED\n",
      "     Excluding influential cases changes estimate by 5-10%\n",
      "     → Report both original and robust estimates\n",
      "\n",
      "Step 3.2.7: Exporting influence diagnostics...\n",
      "-------------------------------------------------------------------------------- \n",
      "  ✅ Saved: influence_diagnostics.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ STEP 3.2 COMPLETE: Influence diagnostics finished\n",
      "================================================================================ \n",
      "\n",
      "================================================================================ \n",
      "STEP 3.3: ROBUST VARIANCE ESTIMATION (RVE)\n",
      "================================================================================ \n",
      "\n",
      "Purpose: Account for dependency from multiple effect sizes per study\n",
      "\n",
      "Step 3.3.1: Assessing data structure...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  DATA STRUCTURE:\n",
      "  ----------------------------------------------------------------------------\n",
      "    Total studies:              24\n",
      "    Total effect sizes:         29\n",
      "    Average ES per study:       1.21\n",
      "    Median ES per study:        1\n",
      "    Range ES per study:         1 to 3\n",
      "\n",
      "  DEPENDENCY ASSESSMENT:\n",
      "  ----------------------------------------------------------------------------\n",
      "    Studies with >1 effect:     4 (16.7% of studies)\n",
      "    Effect sizes from these:    9 (31.0% of total ES)\n",
      "\n",
      "  Effect sizes per study (distribution):\n",
      "    1 ES: 20 studies (83.3%)\n",
      "    2 ES: 3 studies (12.5%)\n",
      "    3 ES: 1 studies (4.2%)\n",
      "\n",
      "  ⚠️  DECISION: RVE is ESSENTIAL\n",
      "     Multiple effect sizes per study create statistical dependency\n",
      "     → RVE adjusts standard errors for within-study correlation\n",
      "     → RVE results should be reported as primary analysis\n",
      "\n",
      "Step 3.3.2: Fitting RVE model for overall effect...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  MODEL SPECIFICATIONS:\n",
      "    Assumed ρ (within-study correlation): 0.8\n",
      "    Small sample correction: Yes\n",
      "    Estimation method: Hierarchical effects\n",
      "\n",
      "  Fitting RVE model...\n",
      "  ✅ RVE model fitted successfully\n",
      "\n",
      "Step 3.3.3: RVE overall effect estimate...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  RVE OVERALL EFFECT:\n",
      "  ============================================================================\n",
      "\n",
      "    Estimate (g):     0.5732\n",
      "    Standard Error:   0.0897\n",
      "    95% CI:           [0.3872, 0.7592]\n",
      "    t-value:          6.3911\n",
      "    df:               22.1\n",
      "    p-value:          0.0000 ***\n",
      "\n",
      "    τ²:               0.1058\n",
      "    I²:               57.96%\n",
      "\n",
      "Step 3.3.4: Comparing standard meta-analysis vs. RVE...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  STANDARD vs. RVE COMPARISON:\n",
      "  ============================================================================\n",
      "\n",
      "  Effect Size Estimate:\n",
      "    Standard MA: g = 0.5272 [0.3781, 0.6763]\n",
      "    RVE:         g = 0.5732 [0.3872, 0.7592]\n",
      "    Difference:      +0.0460\n",
      "\n",
      "  Standard Error:\n",
      "    Standard MA: SE = 0.0761\n",
      "    RVE:         SE = 0.0897\n",
      "    SE Ratio:        1.18x\n",
      "    SE Inflation:    +17.9%\n",
      "\n",
      "  Confidence Interval Width:\n",
      "    Standard MA: 0.2982\n",
      "    RVE:         0.3719\n",
      "    Increase:    +24.7%\n",
      "\n",
      "  Statistical Significance:\n",
      "    Standard MA: p = 0.0000 (significant)\n",
      "    RVE:         p = 0.0000 (significant)\n",
      "\n",
      "    → Significance UNCHANGED\n",
      "\n",
      "Step 3.3.5: Interpreting dependency impact...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  DEPENDENCY IMPACT ASSESSMENT:\n",
      "  ============================================================================\n",
      "\n",
      "  ⚠️  MODERATE DEPENDENCY IMPACT (SE inflation 10-25%)\n",
      "     → Within-study correlation moderately affects inference\n",
      "     → RVE provides more conservative estimates\n",
      "     → RECOMMEND: Report RVE as primary analysis\n",
      "\n",
      "Step 3.3.6: RVE analysis for significant moderators...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  Testing 4 significant moderator(s) with RVE...\n",
      "\n",
      "  [1/4] L1\n",
      "      ✅ β = -0.1881, SE = 0.1213, p = 0.3646\n",
      "\n",
      "  [2/4] English_Major\n",
      "      ✅ β = 0.7743, SE = 0.4001, p = 0.2649\n",
      "\n",
      "  [3/4] Education_Stage\n",
      "      ✅ β = -0.1566, SE = 0.1140, p = 0.2428\n",
      "\n",
      "  [4/4] Treatment_Duration\n",
      "      ✅ β = 1.2073, SE = 0.1235, p = 0.0001 ***\n",
      "\n",
      "  MODERATOR COMPARISON: Standard MA vs. RVE\n",
      "  ============================================================================\n",
      "\n",
      "  L1\n",
      "    Standard: QM = 22.5717, p = 0.0020 (omnibus test)\n",
      "    RVE:      β = -0.1881, SE = 0.1213, p = 0.3646\n",
      "\n",
      "  English_Major\n",
      "    Standard: QM = 12.4787, p = 0.0020 (omnibus test)\n",
      "    RVE:      β = 0.7743, SE = 0.4001, p = 0.2649\n",
      "\n",
      "  Education_Stage\n",
      "    Standard: QM = 6.9669, p = 0.0307 (omnibus test)\n",
      "    RVE:      β = -0.1566, SE = 0.1140, p = 0.2428\n",
      "\n",
      "  Treatment_Duration\n",
      "    Standard: QM = 10.7672, p = 0.0131 (omnibus test)\n",
      "    RVE:      β = 1.2073, SE = 0.1235, p = 0.0001\n",
      "\n",
      "Step 3.3.7: Exporting RVE results...\n",
      "-------------------------------------------------------------------------------- \n",
      "  ✅ Saved: rve_overall_effect.csv\n",
      "  ✅ Saved: rve_moderator_results.csv\n",
      "\n",
      "✅ STEP 3.3 COMPLETE: Robust variance estimation finished\n",
      "================================================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: SENSITIVITY & ROBUSTNESS ANALYSES (LEAVE-ONE-OUT, INFLUENCE, RVE)\n",
    "# ============================================================================\n",
    "#\n",
    "# Outputs (All CSV files):\n",
    "#   STEP 3.1 — Leave-one-out Sensitivity:\n",
    "#       • leave_one_out_analysis.csv\n",
    "#\n",
    "#   STEP 3.2 — Influence Diagnostics:\n",
    "#       • influence_diagnostics.csv\n",
    "#\n",
    "#   STEP 3.3 — Robust Variance Estimation (RVE):\n",
    "#       • rve_overall_effect.csv\n",
    "#       • rve_moderator_results.csv          (only if significant moderators exist)\n",
    "#\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3.1: LEAVE-ONE-OUT SENSITIVITY ANALYSIS\n",
    "# ============================================================================\n",
    "#\n",
    "# Purpose:  Test robustness of pooled effect to individual study exclusion\n",
    "# Method:   Iteratively refit model with k-1 studies (leave1out)\n",
    "#\n",
    "# Influence Criteria:\n",
    "#   • |Δg| > 10% (estimate changes >10%)\n",
    "#   • Significance flip (p crosses .05 threshold)\n",
    "#   • ΔI² > 10% (heterogeneity shift)\n",
    "#\n",
    "# Outputs:\n",
    "#   Effect estimate range, influential cases, stability classification\n",
    "#\n",
    "# Interpretation:\n",
    "#   Narrow range (Δg <5%) → Highly robust\n",
    "#   Moderate range (5-10%) → Robust\n",
    "#   Wide range (>10%) → Potentially fragile, driven by specific studies\n",
    "#\n",
    "# ============================================================================\n",
    "\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\")\n",
    "cat(\"STEP 3.1: LEAVE-ONE-OUT SENSITIVITY ANALYSIS\\n\")\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "cat(\"Research Question: Is the overall effect robust to study exclusion?\\n\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3.1.1: Review Overall Effect (Baseline)\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 3.1.1: Baseline overall effect (for comparison)...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "cat(\"  BASELINE (All studies included):\\n\")\n",
    "cat(\"    Effect size:  g = \", sprintf(\"%.4f\", overall_g), \n",
    "    \" [\", sprintf(\"%.4f\", overall_ci_lb), \", \",\n",
    "    sprintf(\"%.4f\", overall_ci_ub), \"]\\n\", sep = \"\")\n",
    "cat(\"    p-value:      \", sprintf(\"%.4f\", overall_p), sep = \"\")\n",
    "if (overall_p < 0.001) {\n",
    "  cat(\" ***\\n\")\n",
    "} else if (overall_p < 0.01) {\n",
    "  cat(\" **\\n\")\n",
    "} else if (overall_p < 0.05) {\n",
    "  cat(\" *\\n\")\n",
    "} else {\n",
    "  cat(\"\\n\")\n",
    "}\n",
    "cat(\"    τ²:           \", sprintf(\"%.4f\", tau2), \"\\n\", sep = \"\")\n",
    "cat(\"    I²:           \", sprintf(\"%.2f\", I2), \"%\\n\", sep = \"\")\n",
    "cat(\"    k:            \", res_overall$k, \" effect sizes\\n\", sep = \"\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3.1.2: Perform Leave-One-Out Analysis\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 3.1.2: Running leave-one-out analysis...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\")\n",
    "\n",
    "cat(\"  Systematically excluding each effect size...\\n\\n\")\n",
    "\n",
    "# Use metafor's built-in function\n",
    "loo_results <- leave1out(res_overall)\n",
    "\n",
    "cat(\"  ✅ Leave-one-out analysis completed\\n\")\n",
    "cat(\"     Iterations: \", nrow(loo_results), \"\\n\", sep = \"\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3.1.3: Organize Leave-One-Out Results\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 3.1.3: Organizing sensitivity results...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\")\n",
    "\n",
    "# Create comprehensive results dataframe\n",
    "loo_summary <- data.frame(\n",
    "  Study_ID = df$Study_ID,\n",
    "  Effect_ID = df$Effect_ID,\n",
    "  Estimate = loo_results$estimate,\n",
    "  SE = loo_results$se,\n",
    "  CI_Lower = loo_results$ci.lb,\n",
    "  CI_Upper = loo_results$ci.ub,\n",
    "  z_value = loo_results$zval,\n",
    "  p_value = loo_results$pval,\n",
    "  Q = loo_results$Q,\n",
    "  Q_p = loo_results$Qp,\n",
    "  tau2 = loo_results$tau2,\n",
    "  I2 = loo_results$I2,\n",
    "  H2 = loo_results$H2,\n",
    "  stringsAsFactors = FALSE\n",
    ")\n",
    "\n",
    "# Calculate change metrics\n",
    "loo_summary$Change_Estimate <- loo_summary$Estimate - overall_g\n",
    "loo_summary$Pct_Change_Estimate <- (loo_summary$Change_Estimate / overall_g) * 100\n",
    "loo_summary$Change_I2 <- loo_summary$I2 - I2\n",
    "\n",
    "cat(\"  ✅ Results organized with change metrics\\n\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3.1.4: Summary Statistics\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 3.1.4: Summary statistics across leave-one-out iterations...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "cat(\"  EFFECT SIZE RANGE WHEN EACH STUDY EXCLUDED:\\n\")\n",
    "cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"    Minimum:  \", sprintf(\"%.4f\", min(loo_summary$Estimate)), \"\\n\", sep = \"\")\n",
    "cat(\"    Maximum:  \", sprintf(\"%.4f\", max(loo_summary$Estimate)), \"\\n\", sep = \"\")\n",
    "cat(\"    Range:    \", sprintf(\"%.4f\", max(loo_summary$Estimate) - min(loo_summary$Estimate)), \"\\n\", sep = \"\")\n",
    "cat(\"    Mean:     \", sprintf(\"%.4f\", mean(loo_summary$Estimate)), \"\\n\", sep = \"\")\n",
    "cat(\"    Median:   \", sprintf(\"%.4f\", median(loo_summary$Estimate)), \"\\n\", sep = \"\")\n",
    "cat(\"    SD:       \", sprintf(\"%.4f\", sd(loo_summary$Estimate)), \"\\n\", sep = \"\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"  I² RANGE:\\n\")\n",
    "cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"    Minimum:  \", sprintf(\"%.2f\", min(loo_summary$I2)), \"%\\n\", sep = \"\")\n",
    "cat(\"    Maximum:  \", sprintf(\"%.2f\", max(loo_summary$I2)), \"%\\n\", sep = \"\")\n",
    "cat(\"    Range:    \", sprintf(\"%.2f\", max(loo_summary$I2) - min(loo_summary$I2)), \"%\\n\", sep = \"\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3.1.5: Identify Influential Studies\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 3.1.5: Identifying influential studies...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "# Define influence criteria\n",
    "influence_threshold_estimate <- 10  # 10% change in estimate\n",
    "influence_threshold_I2 <- 10        # 10 percentage point change in I²\n",
    "\n",
    "# Flag influential cases\n",
    "loo_summary$Influential_Estimate <- abs(loo_summary$Pct_Change_Estimate) > influence_threshold_estimate\n",
    "loo_summary$Influential_I2 <- abs(loo_summary$Change_I2) > influence_threshold_I2\n",
    "loo_summary$Influential_Any <- loo_summary$Influential_Estimate | loo_summary$Influential_I2\n",
    "\n",
    "# Check for significance changes\n",
    "loo_summary$Sig_Original <- overall_p < 0.05\n",
    "loo_summary$Sig_LOO <- loo_summary$p_value < 0.05\n",
    "loo_summary$Sig_Changed <- loo_summary$Sig_Original != loo_summary$Sig_LOO\n",
    "\n",
    "# Count influential cases\n",
    "n_influential_estimate <- sum(loo_summary$Influential_Estimate)\n",
    "n_influential_I2 <- sum(loo_summary$Influential_I2)\n",
    "n_influential_any <- sum(loo_summary$Influential_Any)\n",
    "n_sig_changed <- sum(loo_summary$Sig_Changed)\n",
    "\n",
    "cat(\"  INFLUENCE DETECTION:\\n\")\n",
    "cat(\"  \", paste0(rep(\"=\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"\\n\")\n",
    "\n",
    "if (n_influential_any > 0) {\n",
    "  cat(\"  ⚠️  INFLUENTIAL STUDIES DETECTED: \", n_influential_any, \"/\", nrow(loo_summary), \"\\n\\n\", sep = \"\")\n",
    "  \n",
    "  # Show influential studies\n",
    "  influential_studies <- loo_summary[loo_summary$Influential_Any, ]\n",
    "  influential_studies <- influential_studies[order(-abs(influential_studies$Pct_Change_Estimate)), ]\n",
    "  \n",
    "  for (i in 1:nrow(influential_studies)) {\n",
    "    row <- influential_studies[i, ]\n",
    "    cat(\"  \", i, \". \", row$Study_ID, \" (\", row$Effect_ID, \")\\n\", sep = \"\")\n",
    "    cat(\"     When excluded: g = \", sprintf(\"%.4f\", row$Estimate), \n",
    "        \" (change: \", sprintf(\"%+.2f\", row$Pct_Change_Estimate), \"%)\\n\", sep = \"\")\n",
    "    cat(\"     I² change: \", sprintf(\"%+.2f\", row$Change_I2), \" percentage points\\n\", sep = \"\")\n",
    "    \n",
    "    if (row$Influential_Estimate) {\n",
    "      cat(\"     ⚠️  Large effect on estimate (>10%)\\n\")\n",
    "    }\n",
    "    if (row$Influential_I2) {\n",
    "      cat(\"     ⚠️  Large effect on heterogeneity (ΔI² >10%)\\n\")\n",
    "    }\n",
    "    cat(\"\\n\")\n",
    "  }\n",
    "  \n",
    "} else {\n",
    "  cat(\"  ✅ NO HIGHLY INFLUENTIAL STUDIES DETECTED\\n\")\n",
    "  cat(\"     All individual exclusions change estimate by <10%\\n\")\n",
    "  cat(\"     All individual exclusions change I² by <10 percentage points\\n\\n\")\n",
    "}\n",
    "\n",
    "# Check significance stability\n",
    "if (n_sig_changed > 0) {\n",
    "  cat(\"  ⚠️  SIGNIFICANCE INSTABILITY DETECTED\\n\")\n",
    "  cat(\"     \", n_sig_changed, \" study/studies alter statistical significance\\n\\n\", sep = \"\")\n",
    "  \n",
    "  sig_changed_studies <- loo_summary[loo_summary$Sig_Changed, ]\n",
    "  for (i in 1:nrow(sig_changed_studies)) {\n",
    "    row <- sig_changed_studies[i, ]\n",
    "    cat(\"     - \", row$Study_ID, \" (\", row$Effect_ID, \"): \", sep = \"\")\n",
    "    cat(\"p = \", sprintf(\"%.4f\", row$p_value), \"\\n\", sep = \"\")\n",
    "  }\n",
    "  cat(\"\\n\")\n",
    "} else {\n",
    "  cat(\"  ✅ SIGNIFICANCE IS STABLE\\n\")\n",
    "  cat(\"     Statistical significance consistent across all iterations\\n\\n\")\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3.1.6: Interpretation and Conclusion\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 3.1.6: Sensitivity analysis interpretation...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "cat(\"  ROBUSTNESS ASSESSMENT:\\n\")\n",
    "cat(\"  \", paste0(rep(\"=\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Determine robustness level\n",
    "if (n_influential_any == 0 && n_sig_changed == 0) {\n",
    "  robustness_level <- \"HIGHLY ROBUST\"\n",
    "  robustness_desc <- \"Results are stable across all leave-one-out iterations\"\n",
    "  robustness_icon <- \"✅\"\n",
    "} else if (n_influential_any <= 2 && n_sig_changed == 0) {\n",
    "  robustness_level <- \"ROBUST\"\n",
    "  robustness_desc <- \"Minimal influence from individual studies\"\n",
    "  robustness_icon <- \"✅\"\n",
    "} else if (n_sig_changed == 0) {\n",
    "  robustness_level <- \"MODERATELY ROBUST\"\n",
    "  robustness_desc <- \"Some individual influence but significance is stable\"\n",
    "  robustness_icon <- \"⚠️ \"\n",
    "} else {\n",
    "  robustness_level <- \"FRAGILE\"\n",
    "  robustness_desc <- \"Results depend on specific studies\"\n",
    "  robustness_icon <- \"⚠️ \"\n",
    "}\n",
    "\n",
    "cat(\"  \", robustness_icon, \" CONCLUSION: \", robustness_level, \"\\n\", sep = \"\")\n",
    "cat(\"     \", robustness_desc, \"\\n\\n\", sep = \"\")\n",
    "\n",
    "cat(\"  RECOMMENDATION:\\n\")\n",
    "if (n_influential_any == 0) {\n",
    "  cat(\"     → Report overall effect with confidence\\n\")\n",
    "  cat(\"     → No sensitivity concerns\\n\")\n",
    "} else if (n_influential_any <= 2) {\n",
    "  cat(\"     → Report overall effect\\n\")\n",
    "  cat(\"     → Note influential studies in supplementary materials\\n\")\n",
    "} else {\n",
    "  cat(\"     → Report overall effect with caution\\n\")\n",
    "  cat(\"     → Conduct influence diagnostics (STEP 3.2)\\n\")\n",
    "  cat(\"     → Consider excluding outliers in sensitivity analysis\\n\")\n",
    "}\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3.1.7: Export Leave-One-Out Results\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 3.1.7: Exporting leave-one-out results...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\")\n",
    "\n",
    "# Round for export\n",
    "loo_export <- loo_summary\n",
    "numeric_cols <- c(\"Estimate\", \"SE\", \"CI_Lower\", \"CI_Upper\", \"z_value\", \"p_value\",\n",
    "                  \"Q\", \"Q_p\", \"tau2\", \"I2\", \"H2\", \"Change_Estimate\", \n",
    "                  \"Pct_Change_Estimate\", \"Change_I2\")\n",
    "for (col in numeric_cols) {\n",
    "  if (col %in% names(loo_export)) {\n",
    "    loo_export[[col]] <- round(loo_export[[col]], 4)\n",
    "  }\n",
    "}\n",
    "\n",
    "# Verify step3_dir exists\n",
    "if (!exists(\"step3_dir\") || is.null(step3_dir)) {\n",
    "  step3_dir <- file.path(getwd(), \"Meta_Analysis_Results\", \"Step3_Robustness_Checks\")\n",
    "  if (!dir.exists(step3_dir)) dir.create(step3_dir, recursive = TRUE)\n",
    "}\n",
    "\n",
    "# Save to Step3 folder\n",
    "safe_write_csv(loo_export, \"leave_one_out_analysis.csv\", output_dir = step3_dir)\n",
    "\n",
    "cat(\"\\n\")\n",
    "cat(\"✅ STEP 3.1 COMPLETE: Leave-one-out sensitivity analysis finished\\n\")\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3.2: INFLUENCE DIAGNOSTICS\n",
    "# ============================================================================\n",
    "#\n",
    "# Purpose:  Detect outliers and high-leverage cases via formal diagnostics\n",
    "# Metrics:  Cook's D, DFBETAS, Hat values, Standardized residuals\n",
    "#\n",
    "# Thresholds (established criteria):\n",
    "#   Cook's D:    Di > 4/(k-p-1)\n",
    "#   DFBETAS:     |DFBETAS| > 2/√k\n",
    "#   Hat values:  hi > 2p/k (leverage)\n",
    "#   Residuals:   |ri| > 2 (moderate), |ri| > 3 (extreme)\n",
    "#\n",
    "# Outputs:\n",
    "#   Flagged influential cases, sensitivity analysis excluding outliers\n",
    "#\n",
    "# Interpretation:\n",
    "#   Cases exceeding multiple thresholds warrant exclusion sensitivity tests\n",
    "#   Compare results with/without influential cases for robustness assessment\n",
    "#\n",
    "# ============================================================================\n",
    "\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\")\n",
    "cat(\"STEP 3.2: INFLUENCE DIAGNOSTICS\\n\")\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "cat(\"Research Question: Are there influential outliers affecting results?\\n\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3.2.1: Calculate Influence Diagnostics\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 3.2.1: Calculating influence diagnostics...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\")\n",
    "\n",
    "cat(\"  Computing diagnostic metrics:\\n\")\n",
    "cat(\"    → Cook's Distance (overall influence)\\n\")\n",
    "cat(\"    → DFBETAS (coefficient influence)\\n\")\n",
    "cat(\"    → Hat values (leverage)\\n\")\n",
    "cat(\"    → Standardized residuals (outliers)\\n\\n\")\n",
    "\n",
    "# Use metafor's influence function\n",
    "influence_stats <- influence(res_overall)\n",
    "\n",
    "cat(\"  ✅ Diagnostic calculations complete\\n\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3.2.2: Extract and Organize Diagnostics\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 3.2.2: Organizing diagnostic statistics...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\")\n",
    "\n",
    "# Extract diagnostics\n",
    "cooks_d <- influence_stats$inf$cook.d        # Cook's distance\n",
    "dfbetas_raw <- influence_stats$inf$dfbs      # DFBETAS (may be matrix or NULL)\n",
    "hat_values <- influence_stats$inf$hat        # Hat values (leverage)\n",
    "std_resid_obj <- rstandard(res_overall)      # Standardized residuals object\n",
    "\n",
    "# Extract standardized residuals\n",
    "if (is.list(std_resid_obj) && \"z\" %in% names(std_resid_obj)) {\n",
    "  std_resid <- std_resid_obj$z\n",
    "} else if (is.numeric(std_resid_obj)) {\n",
    "  std_resid <- std_resid_obj\n",
    "} else {\n",
    "  std_resid <- as.numeric(std_resid_obj)\n",
    "}\n",
    "\n",
    "# Handle DFBETAS - can be matrix, vector, or NULL\n",
    "if (is.null(dfbetas_raw) || length(dfbetas_raw) == 0) {\n",
    "  # If DFBETAS not available, calculate it manually\n",
    "  dfbetas <- rep(0, length(cooks_d))\n",
    "  cat(\"  ⚠️  DFBETAS not available from influence(), using zeros\\n\")\n",
    "} else if (is.matrix(dfbetas_raw)) {\n",
    "  # For each case, take maximum absolute DFBETAS across all coefficients\n",
    "  dfbetas <- apply(abs(dfbetas_raw), 1, max)\n",
    "} else if (is.numeric(dfbetas_raw)) {\n",
    "  dfbetas <- abs(dfbetas_raw)\n",
    "} else {\n",
    "  # Fallback: try to convert to numeric\n",
    "  dfbetas <- abs(as.numeric(dfbetas_raw))\n",
    "}\n",
    "\n",
    "# Ensure all vectors have same length\n",
    "cat(\"  Vector lengths: Cook's D = \", length(cooks_d), \n",
    "    \", DFBETAS = \", length(dfbetas),\n",
    "    \", Hat = \", length(hat_values),\n",
    "    \", Resid = \", length(std_resid), \"\\n\", sep = \"\")\n",
    "\n",
    "# Verify all have same length as df\n",
    "if (length(cooks_d) != nrow(df) || length(dfbetas) != nrow(df) || \n",
    "    length(hat_values) != nrow(df) || length(std_resid) != nrow(df)) {\n",
    "  cat(\"  ⚠️  Dimension mismatch detected!\\n\")\n",
    "  cat(\"     df has \", nrow(df), \" rows\\n\", sep = \"\")\n",
    "  cat(\"     Adjusting to match...\\n\")\n",
    "  \n",
    "  # Pad shorter vectors with NA\n",
    "  max_len <- nrow(df)\n",
    "  if (length(cooks_d) < max_len) cooks_d <- c(cooks_d, rep(NA, max_len - length(cooks_d)))\n",
    "  if (length(dfbetas) < max_len) dfbetas <- c(dfbetas, rep(NA, max_len - length(dfbetas)))\n",
    "  if (length(hat_values) < max_len) hat_values <- c(hat_values, rep(NA, max_len - length(hat_values)))\n",
    "  if (length(std_resid) < max_len) std_resid <- c(std_resid, rep(NA, max_len - length(std_resid)))\n",
    "  \n",
    "  # Truncate longer vectors\n",
    "  cooks_d <- cooks_d[1:max_len]\n",
    "  dfbetas <- dfbetas[1:max_len]\n",
    "  hat_values <- hat_values[1:max_len]\n",
    "  std_resid <- std_resid[1:max_len]\n",
    "}\n",
    "\n",
    "# Create comprehensive diagnostics dataframe\n",
    "influence_df <- data.frame(\n",
    "  Study_ID = df$Study_ID,\n",
    "  Effect_ID = df$Effect_ID,\n",
    "  Hedges_g = df$Hedges_g,\n",
    "  Cooks_D = cooks_d,\n",
    "  DFBETAS = dfbetas,\n",
    "  Hat = hat_values,\n",
    "  Std_Resid = std_resid,\n",
    "  stringsAsFactors = FALSE\n",
    ")\n",
    "\n",
    "cat(\"  ✅ Diagnostics organized for \", nrow(influence_df), \" effect sizes\\n\", sep = \"\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3.2.3: Define Influence Thresholds\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 3.2.3: Defining influence thresholds...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "k <- res_overall$k          # Number of studies\n",
    "p <- res_overall$p          # Number of parameters\n",
    "\n",
    "# Standard thresholds\n",
    "threshold_cooks <- 4 / (k - p - 1)\n",
    "threshold_dfbetas <- 2 / sqrt(k)\n",
    "threshold_hat <- 2 * p / k\n",
    "threshold_resid_moderate <- 2\n",
    "threshold_resid_extreme <- 3\n",
    "\n",
    "cat(\"  INFLUENCE THRESHOLDS:\\n\")\n",
    "cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"    Cook's D:         > \", sprintf(\"%.4f\", threshold_cooks), \n",
    "    \" (4/(k-p-1))\\n\", sep = \"\")\n",
    "cat(\"    DFBETAS:          > \", sprintf(\"%.4f\", threshold_dfbetas), \n",
    "    \" (2/√k)\\n\", sep = \"\")\n",
    "cat(\"    Hat values:       > \", sprintf(\"%.4f\", threshold_hat), \n",
    "    \" (2p/k)\\n\", sep = \"\")\n",
    "cat(\"    Std. residuals:   > \", threshold_resid_moderate, \n",
    "    \" (moderate outlier)\\n\", sep = \"\")\n",
    "cat(\"                      > \", threshold_resid_extreme, \n",
    "    \" (extreme outlier)\\n\", sep = \"\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3.2.4: Flag Influential Cases\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 3.2.4: Identifying influential cases...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "# Apply thresholds\n",
    "influence_df$Flag_Cooks <- influence_df$Cooks_D > threshold_cooks\n",
    "influence_df$Flag_DFBETAS <- abs(influence_df$DFBETAS) > threshold_dfbetas\n",
    "influence_df$Flag_Hat <- influence_df$Hat > threshold_hat\n",
    "influence_df$Flag_Resid_Moderate <- abs(influence_df$Std_Resid) > threshold_resid_moderate\n",
    "influence_df$Flag_Resid_Extreme <- abs(influence_df$Std_Resid) > threshold_resid_extreme\n",
    "\n",
    "# Overall influence flag (any diagnostic exceeds threshold)\n",
    "influence_df$Influential <- (\n",
    "  influence_df$Flag_Cooks |\n",
    "  influence_df$Flag_DFBETAS |\n",
    "  influence_df$Flag_Hat |\n",
    "  influence_df$Flag_Resid_Extreme\n",
    ")\n",
    "\n",
    "# Count influential cases\n",
    "n_cooks <- sum(influence_df$Flag_Cooks)\n",
    "n_dfbetas <- sum(influence_df$Flag_DFBETAS)\n",
    "n_hat <- sum(influence_df$Flag_Hat)\n",
    "n_resid_mod <- sum(influence_df$Flag_Resid_Moderate)\n",
    "n_resid_ext <- sum(influence_df$Flag_Resid_Extreme)\n",
    "n_influential <- sum(influence_df$Influential)\n",
    "\n",
    "cat(\"  INFLUENCE DETECTION SUMMARY:\\n\")\n",
    "cat(\"  \", paste0(rep(\"=\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"\\n\")\n",
    "cat(\"    High Cook's D:           \", n_cooks, \" cases (\", \n",
    "    sprintf(\"%.1f\", (n_cooks/k)*100), \"%)\\n\", sep = \"\")\n",
    "cat(\"    High DFBETAS:            \", n_dfbetas, \" cases (\", \n",
    "    sprintf(\"%.1f\", (n_dfbetas/k)*100), \"%)\\n\", sep = \"\")\n",
    "cat(\"    High leverage (hat):     \", n_hat, \" cases (\", \n",
    "    sprintf(\"%.1f\", (n_hat/k)*100), \"%)\\n\", sep = \"\")\n",
    "cat(\"    Moderate outliers (|r|>2): \", n_resid_mod, \" cases (\", \n",
    "    sprintf(\"%.1f\", (n_resid_mod/k)*100), \"%)\\n\", sep = \"\")\n",
    "cat(\"    Extreme outliers (|r|>3):  \", n_resid_ext, \" cases (\", \n",
    "    sprintf(\"%.1f\", (n_resid_ext/k)*100), \"%)\\n\", sep = \"\")\n",
    "cat(\"\\n\")\n",
    "cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"    TOTAL INFLUENTIAL CASES: \", n_influential, \"/\", k, \" (\", \n",
    "    sprintf(\"%.1f\", (n_influential/k)*100), \"%)\\n\", sep = \"\")\n",
    "cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3.2.5: Display Influential Cases\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 3.2.5: Detailed information on influential cases...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "if (n_influential > 0) {\n",
    "  cat(\"  ⚠️  INFLUENTIAL CASES DETECTED:\\n\")\n",
    "  cat(\"  \", paste0(rep(\"=\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "  cat(\"\\n\")\n",
    "  \n",
    "  # Sort by Cook's D (descending)\n",
    "  influential_cases <- influence_df[influence_df$Influential, ]\n",
    "  influential_cases <- influential_cases[order(-influential_cases$Cooks_D), ]\n",
    "  \n",
    "  for (i in 1:nrow(influential_cases)) {\n",
    "    row <- influential_cases[i, ]\n",
    "    \n",
    "    cat(\"  \", i, \". \", row$Study_ID, \" (\", row$Effect_ID, \")\\n\", sep = \"\")\n",
    "    cat(\"     Effect size:      g = \", sprintf(\"%.4f\", row$Hedges_g), \"\\n\", sep = \"\")\n",
    "    cat(\"     Cook's D:         \", sprintf(\"%.4f\", row$Cooks_D), sep = \"\")\n",
    "    if (row$Flag_Cooks) cat(\" ⚠️  HIGH\")\n",
    "    cat(\"\\n\")\n",
    "    cat(\"     DFBETAS:          \", sprintf(\"%.4f\", row$DFBETAS), sep = \"\")\n",
    "    if (row$Flag_DFBETAS) cat(\" ⚠️  HIGH\")\n",
    "    cat(\"\\n\")\n",
    "    cat(\"     Hat value:        \", sprintf(\"%.4f\", row$Hat), sep = \"\")\n",
    "    if (row$Flag_Hat) cat(\" ⚠️  HIGH\")\n",
    "    cat(\"\\n\")\n",
    "    cat(\"     Std. residual:    \", sprintf(\"%.4f\", row$Std_Resid), sep = \"\")\n",
    "    if (row$Flag_Resid_Extreme) {\n",
    "      cat(\" ⚠️  EXTREME OUTLIER\")\n",
    "    } else if (row$Flag_Resid_Moderate) {\n",
    "      cat(\" ⚠️  MODERATE OUTLIER\")\n",
    "    }\n",
    "    cat(\"\\n\")\n",
    "    \n",
    "    # Interpretation\n",
    "    issues <- c()\n",
    "    if (row$Flag_Cooks) issues <- c(issues, \"high influence\")\n",
    "    if (row$Flag_DFBETAS) issues <- c(issues, \"affects coefficients\")\n",
    "    if (row$Flag_Hat) issues <- c(issues, \"high leverage\")\n",
    "    if (row$Flag_Resid_Extreme) issues <- c(issues, \"extreme outlier\")\n",
    "    \n",
    "    if (length(issues) > 0) {\n",
    "      cat(\"     Issues:           \", paste(issues, collapse = \", \"), \"\\n\", sep = \"\")\n",
    "    }\n",
    "    cat(\"\\n\")\n",
    "  }\n",
    "  \n",
    "  # Recommendations\n",
    "  cat(\"  RECOMMENDATIONS:\\n\")\n",
    "  cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "  cat(\"    1. Review influential studies for data accuracy\\n\")\n",
    "  cat(\"    2. Examine study characteristics (design, sample, etc.)\\n\")\n",
    "  cat(\"    3. Consider sensitivity analysis excluding influential cases\\n\")\n",
    "  cat(\"    4. Report results both with and without influential cases\\n\")\n",
    "  \n",
    "} else {\n",
    "  cat(\"  ✅ NO INFLUENTIAL CASES DETECTED\\n\")\n",
    "  cat(\"     All effect sizes fall within acceptable diagnostic ranges\\n\")\n",
    "  cat(\"     → Results are robust to individual case influence\\n\")\n",
    "}\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3.2.6: Sensitivity Analysis (Excluding Influential Cases)\n",
    "# ----------------------------------------------------------------------------\n",
    "if (n_influential > 0) {\n",
    "  cat(\"Step 3.2.6: Sensitivity analysis excluding influential cases...\\n\")\n",
    "  cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "  \n",
    "  # Create dataset without influential cases\n",
    "  df_robust <- df[!influence_df$Influential, ]\n",
    "  \n",
    "  cat(\"  Refitting model without influential cases...\\n\")\n",
    "  cat(\"    Original k:  \", k, \" effect sizes\\n\", sep = \"\")\n",
    "  cat(\"    Excluded:    \", n_influential, \" influential cases\\n\", sep = \"\")\n",
    "  cat(\"    Remaining:   \", nrow(df_robust), \" effect sizes\\n\\n\", sep = \"\")\n",
    "  \n",
    "  # Refit overall model\n",
    "  res_robust <- rma(yi = Hedges_g, vi = df_robust$vi, data = df_robust, method = \"REML\")\n",
    "  \n",
    "  cat(\"  ✅ Robust model fitted\\n\\n\")\n",
    "  \n",
    "  # Compare results\n",
    "  cat(\"  COMPARISON: ORIGINAL vs. ROBUST (without influential cases)\\n\")\n",
    "  cat(\"  \", paste0(rep(\"=\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "  cat(\"\\n\")\n",
    "  \n",
    "  cat(\"  Effect size:\\n\")\n",
    "  cat(\"    Original:  g = \", sprintf(\"%.4f\", overall_g), \n",
    "      \" [\", sprintf(\"%.4f\", overall_ci_lb), \", \",\n",
    "      sprintf(\"%.4f\", overall_ci_ub), \"]\\n\", sep = \"\")\n",
    "  cat(\"    Robust:    g = \", sprintf(\"%.4f\", res_robust$b[1]), \n",
    "      \" [\", sprintf(\"%.4f\", res_robust$ci.lb), \", \",\n",
    "      sprintf(\"%.4f\", res_robust$ci.ub), \"]\\n\", sep = \"\")\n",
    "  cat(\"    Change:    \", sprintf(\"%+.4f\", res_robust$b[1] - overall_g), \n",
    "      \" (\", sprintf(\"%+.1f\", ((res_robust$b[1] - overall_g)/overall_g)*100), \"%)\\n\\n\", sep = \"\")\n",
    "  \n",
    "  cat(\"  Statistical significance:\\n\")\n",
    "  cat(\"    Original:  p = \", sprintf(\"%.4f\", overall_p), sep = \"\")\n",
    "  if (overall_p < 0.001) {\n",
    "    cat(\" ***\\n\")\n",
    "  } else if (overall_p < 0.01) {\n",
    "    cat(\" **\\n\")\n",
    "  } else if (overall_p < 0.05) {\n",
    "    cat(\" *\\n\")\n",
    "  } else {\n",
    "    cat(\"\\n\")\n",
    "  }\n",
    "  cat(\"    Robust:    p = \", sprintf(\"%.4f\", res_robust$pval), sep = \"\")\n",
    "  if (res_robust$pval < 0.001) {\n",
    "    cat(\" ***\\n\")\n",
    "  } else if (res_robust$pval < 0.01) {\n",
    "    cat(\" **\\n\")\n",
    "  } else if (res_robust$pval < 0.05) {\n",
    "    cat(\" *\\n\")\n",
    "  } else {\n",
    "    cat(\"\\n\")\n",
    "  }\n",
    "  \n",
    "  # Check if significance changed\n",
    "  original_sig <- overall_p < 0.05\n",
    "  robust_sig <- res_robust$pval < 0.05\n",
    "  \n",
    "  if (original_sig == robust_sig) {\n",
    "    cat(\"    → Significance UNCHANGED\\n\\n\")\n",
    "  } else {\n",
    "    cat(\"    ⚠️  Significance CHANGED\\n\\n\")\n",
    "  }\n",
    "  \n",
    "  cat(\"  Heterogeneity:\\n\")\n",
    "  cat(\"    Original:  I² = \", sprintf(\"%.2f\", I2), \"%, τ² = \", \n",
    "      sprintf(\"%.4f\", tau2), \"\\n\", sep = \"\")\n",
    "  cat(\"    Robust:    I² = \", sprintf(\"%.2f\", res_robust$I2), \"%, τ² = \", \n",
    "      sprintf(\"%.4f\", res_robust$tau2), \"\\n\\n\", sep = \"\")\n",
    "  \n",
    "  # Overall interpretation\n",
    "  change_pct <- abs((res_robust$b[1] - overall_g)/overall_g) * 100\n",
    "  \n",
    "  if (change_pct < 5) {\n",
    "    cat(\"  ✅ INTERPRETATION: Results are ROBUST\\n\")\n",
    "    cat(\"     Excluding influential cases changes estimate by <5%\\n\")\n",
    "    cat(\"     → Main conclusions remain valid\\n\")\n",
    "  } else if (change_pct < 10) {\n",
    "    cat(\"  ⚠️  INTERPRETATION: Results are MODERATELY AFFECTED\\n\")\n",
    "    cat(\"     Excluding influential cases changes estimate by 5-10%\\n\")\n",
    "    cat(\"     → Report both original and robust estimates\\n\")\n",
    "  } else {\n",
    "    cat(\"  ⚠️  INTERPRETATION: Results are SUBSTANTIALLY AFFECTED\\n\")\n",
    "    cat(\"     Excluding influential cases changes estimate by >10%\\n\")\n",
    "    cat(\"     → Influential cases have major impact\\n\")\n",
    "    cat(\"     → Consider reporting robust estimate as primary\\n\")\n",
    "  }\n",
    "  \n",
    "  cat(\"\\n\")\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3.2.7: Export Influence Diagnostics\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 3.2.7: Exporting influence diagnostics...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\")\n",
    "\n",
    "# Round for export\n",
    "influence_export <- influence_df\n",
    "numeric_cols <- c(\"Hedges_g\", \"Cooks_D\", \"DFBETAS\", \"Hat\", \"Std_Resid\")\n",
    "for (col in numeric_cols) {\n",
    "  influence_export[[col]] <- round(influence_export[[col]], 4)\n",
    "}\n",
    "\n",
    "# Verify step3_dir exists\n",
    "if (!exists(\"step3_dir\") || is.null(step3_dir)) {\n",
    "  step3_dir <- file.path(getwd(), \"Meta_Analysis_Results\", \"Step3_Robustness_Checks\")\n",
    "  if (!dir.exists(step3_dir)) dir.create(step3_dir, recursive = TRUE)\n",
    "}\n",
    "\n",
    "# Save to Step3 folder\n",
    "safe_write_csv(influence_export, \"influence_diagnostics.csv\", output_dir = step3_dir)\n",
    "\n",
    "cat(\"\\n\")\n",
    "cat(\"✅ STEP 3.2 COMPLETE: Influence diagnostics finished\\n\")\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3.3: ROBUST VARIANCE ESTIMATION (RVE)\n",
    "# ============================================================================\n",
    "#\n",
    "# Purpose:  Correct for statistical dependency in clustered effect sizes\n",
    "# Problem:  Multiple ES per study violates independence → SE underestimation\n",
    "#\n",
    "# Method:   Hierarchical weights with robust variance (Hedges et al., 2010)\n",
    "#   • Assumes within-study correlation ρ (default: 0.8)\n",
    "#   • Small-sample corrections for limited clusters\n",
    "#   • robumeta package implementation\n",
    "#\n",
    "# Outputs:\n",
    "#   RVE-adjusted g, SE inflation %, comparison to standard MA\n",
    "#\n",
    "# Interpretation:\n",
    "#   SE inflation <10% → Minimal dependency impact\n",
    "#   SE inflation 10-25% → Moderate dependency, report RVE as primary\n",
    "#   SE inflation >25% → Strong dependency, RVE results essential\n",
    "#\n",
    "# Decision Rule:\n",
    "#   ≥15% of studies with multiple ES → Conduct RVE analysis\n",
    "#\n",
    "# ============================================================================\n",
    "\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\")\n",
    "cat(\"STEP 3.3: ROBUST VARIANCE ESTIMATION (RVE)\\n\")\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "cat(\"Purpose: Account for dependency from multiple effect sizes per study\\n\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 3.3.1: Assess Data Structure and Dependency\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 3.3.1: Assessing data structure...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "# Count effect sizes per study\n",
    "effects_per_study <- table(df$Study_ID)\n",
    "n_studies <- length(unique(df$Study_ID))\n",
    "n_effects <- nrow(df)\n",
    "\n",
    "cat(\"  DATA STRUCTURE:\\n\")\n",
    "cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"    Total studies:              \", n_studies, \"\\n\", sep = \"\")\n",
    "cat(\"    Total effect sizes:         \", n_effects, \"\\n\", sep = \"\")\n",
    "cat(\"    Average ES per study:       \", sprintf(\"%.2f\", n_effects/n_studies), \"\\n\", sep = \"\")\n",
    "cat(\"    Median ES per study:        \", median(effects_per_study), \"\\n\", sep = \"\")\n",
    "cat(\"    Range ES per study:         \", min(effects_per_study), \" to \", \n",
    "    max(effects_per_study), \"\\n\", sep = \"\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Identify studies with multiple effect sizes\n",
    "multi_es_studies <- names(effects_per_study[effects_per_study > 1])\n",
    "n_multi_es <- length(multi_es_studies)\n",
    "n_multi_effects <- sum(effects_per_study[effects_per_study > 1])\n",
    "\n",
    "cat(\"  DEPENDENCY ASSESSMENT:\\n\")\n",
    "cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"    Studies with >1 effect:     \", n_multi_es, \" (\", \n",
    "    sprintf(\"%.1f\", (n_multi_es/n_studies)*100), \"% of studies)\\n\", sep = \"\")\n",
    "cat(\"    Effect sizes from these:    \", n_multi_effects, \" (\", \n",
    "    sprintf(\"%.1f\", (n_multi_effects/n_effects)*100), \"% of total ES)\\n\", sep = \"\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Display distribution\n",
    "cat(\"  Effect sizes per study (distribution):\\n\")\n",
    "es_dist <- as.data.frame(table(effects_per_study))\n",
    "names(es_dist) <- c(\"ES_Count\", \"N_Studies\")\n",
    "for (i in 1:nrow(es_dist)) {\n",
    "  cat(\"    \", es_dist$ES_Count[i], \" ES: \", es_dist$N_Studies[i], \n",
    "      \" studies (\", sprintf(\"%.1f\", (as.numeric(es_dist$N_Studies[i])/n_studies)*100), \n",
    "      \"%)\\n\", sep = \"\")\n",
    "}\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Decision on RVE necessity\n",
    "if (n_multi_es == 0) {\n",
    "  cat(\"  ✅ DECISION: RVE not necessary\\n\")\n",
    "  cat(\"     All studies contribute exactly 1 effect size\\n\")\n",
    "  cat(\"     → No dependency issues\\n\")\n",
    "  cat(\"     → Standard meta-analysis is appropriate\\n\\n\")\n",
    "  \n",
    "  run_rve <- FALSE\n",
    "  \n",
    "} else {\n",
    "  cat(\"  ⚠️  DECISION: RVE is ESSENTIAL\\n\")\n",
    "  cat(\"     Multiple effect sizes per study create statistical dependency\\n\")\n",
    "  cat(\"     → RVE adjusts standard errors for within-study correlation\\n\")\n",
    "  cat(\"     → RVE results should be reported as primary analysis\\n\\n\")\n",
    "  \n",
    "  run_rve <- TRUE\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Conditional RVE Analysis (only if needed)\n",
    "# ----------------------------------------------------------------------------\n",
    "if (run_rve) {\n",
    "  \n",
    "  # --------------------------------------------------------------------------\n",
    "  # Step 3.3.2: Fit RVE Model for Overall Effect\n",
    "  # --------------------------------------------------------------------------\n",
    "  cat(\"Step 3.3.2: Fitting RVE model for overall effect...\\n\")\n",
    "  cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "  \n",
    "  # Check if robumeta is loaded\n",
    "  if (!require(robumeta, quietly = TRUE)) {\n",
    "    cat(\"  Installing robumeta package...\\n\")\n",
    "    install.packages(\"robumeta\", repos = \"https://cloud.r-project.org/\")\n",
    "    library(robumeta)\n",
    "  }\n",
    "  \n",
    "  # Set assumed within-study correlation\n",
    "  rho_assumed <- 0.8  # Common default (can be varied in sensitivity analysis)\n",
    "  \n",
    "  cat(\"  MODEL SPECIFICATIONS:\\n\")\n",
    "  cat(\"    Assumed ρ (within-study correlation): \", rho_assumed, \"\\n\", sep = \"\")\n",
    "  cat(\"    Small sample correction: Yes\\n\")\n",
    "  cat(\"    Estimation method: Hierarchical effects\\n\\n\")\n",
    "  \n",
    "  # Fit RVE model\n",
    "  cat(\"  Fitting RVE model...\\n\")\n",
    "  \n",
    "  rve_overall <- robu(\n",
    "    formula = Hedges_g ~ 1,\n",
    "    data = df,\n",
    "    studynum = Study_ID,\n",
    "    var.eff.size = vi,\n",
    "    rho = rho_assumed,\n",
    "    small = TRUE\n",
    "  )\n",
    "  \n",
    "  cat(\"  ✅ RVE model fitted successfully\\n\\n\")\n",
    "  \n",
    "  # --------------------------------------------------------------------------\n",
    "  # Step 3.3.3: Display RVE Results\n",
    "  # --------------------------------------------------------------------------\n",
    "  cat(\"Step 3.3.3: RVE overall effect estimate...\\n\")\n",
    "  cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "  \n",
    "  cat(\"  RVE OVERALL EFFECT:\\n\")\n",
    "  cat(\"  \", paste0(rep(\"=\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "  cat(\"\\n\")\n",
    "  \n",
    "  rve_g <- rve_overall$reg_table$b.r[1]\n",
    "  rve_se <- rve_overall$reg_table$SE[1]\n",
    "  rve_ci_lb <- rve_overall$reg_table$CI.L[1]\n",
    "  rve_ci_ub <- rve_overall$reg_table$CI.U[1]\n",
    "  rve_t <- rve_overall$reg_table$t[1]\n",
    "  rve_p <- rve_overall$reg_table$prob[1]\n",
    "  rve_df <- rve_overall$reg_table$dfs[1]\n",
    "  \n",
    "  cat(\"    Estimate (g):     \", sprintf(\"%.4f\", rve_g), \"\\n\", sep = \"\")\n",
    "  cat(\"    Standard Error:   \", sprintf(\"%.4f\", rve_se), \"\\n\", sep = \"\")\n",
    "  cat(\"    95% CI:           [\", sprintf(\"%.4f\", rve_ci_lb), \", \", \n",
    "      sprintf(\"%.4f\", rve_ci_ub), \"]\\n\", sep = \"\")\n",
    "  cat(\"    t-value:          \", sprintf(\"%.4f\", rve_t), \"\\n\", sep = \"\")\n",
    "  cat(\"    df:               \", sprintf(\"%.1f\", rve_df), \"\\n\", sep = \"\")\n",
    "  cat(\"    p-value:          \", sprintf(\"%.4f\", rve_p), sep = \"\")\n",
    "  \n",
    "  if (rve_p < 0.001) {\n",
    "    cat(\" ***\\n\")\n",
    "  } else if (rve_p < 0.01) {\n",
    "    cat(\" **\\n\")\n",
    "  } else if (rve_p < 0.05) {\n",
    "    cat(\" *\\n\")\n",
    "  } else {\n",
    "    cat(\"\\n\")\n",
    "  }\n",
    "  \n",
    "  cat(\"\\n\")\n",
    "  \n",
    "  # Heterogeneity from RVE\n",
    "  rve_tau2 <- rve_overall$mod_info$tau.sq\n",
    "  rve_I2 <- rve_overall$mod_info$I.2\n",
    "  \n",
    "  cat(\"    τ²:               \", sprintf(\"%.4f\", rve_tau2), \"\\n\", sep = \"\")\n",
    "  cat(\"    I²:               \", sprintf(\"%.2f\", rve_I2), \"%\\n\", sep = \"\")\n",
    "  \n",
    "  cat(\"\\n\")\n",
    "  \n",
    "  # --------------------------------------------------------------------------\n",
    "  # Step 3.3.4: Compare Standard vs. RVE\n",
    "  # --------------------------------------------------------------------------\n",
    "  cat(\"Step 3.3.4: Comparing standard meta-analysis vs. RVE...\\n\")\n",
    "  cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "  \n",
    "  cat(\"  STANDARD vs. RVE COMPARISON:\\n\")\n",
    "  cat(\"  \", paste0(rep(\"=\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "  cat(\"\\n\")\n",
    "  \n",
    "  cat(\"  Effect Size Estimate:\\n\")\n",
    "  cat(\"    Standard MA: g = \", sprintf(\"%.4f\", overall_g), \n",
    "      \" [\", sprintf(\"%.4f\", overall_ci_lb), \", \",\n",
    "      sprintf(\"%.4f\", overall_ci_ub), \"]\\n\", sep = \"\")\n",
    "  cat(\"    RVE:         g = \", sprintf(\"%.4f\", rve_g), \n",
    "      \" [\", sprintf(\"%.4f\", rve_ci_lb), \", \",\n",
    "      sprintf(\"%.4f\", rve_ci_ub), \"]\\n\", sep = \"\")\n",
    "  cat(\"    Difference:      \", sprintf(\"%+.4f\", rve_g - overall_g), \"\\n\\n\", sep = \"\")\n",
    "  \n",
    "  cat(\"  Standard Error:\\n\")\n",
    "  cat(\"    Standard MA: SE = \", sprintf(\"%.4f\", overall_se), \"\\n\", sep = \"\")\n",
    "  cat(\"    RVE:         SE = \", sprintf(\"%.4f\", rve_se), \"\\n\", sep = \"\")\n",
    "  \n",
    "  se_ratio <- rve_se / overall_se\n",
    "  se_inflation <- (se_ratio - 1) * 100\n",
    "  \n",
    "  cat(\"    SE Ratio:        \", sprintf(\"%.2f\", se_ratio), \"x\\n\", sep = \"\")\n",
    "  cat(\"    SE Inflation:    +\", sprintf(\"%.1f\", se_inflation), \"%\\n\\n\", sep = \"\")\n",
    "  \n",
    "  cat(\"  Confidence Interval Width:\\n\")\n",
    "  ci_width_standard <- overall_ci_ub - overall_ci_lb\n",
    "  ci_width_rve <- rve_ci_ub - rve_ci_lb\n",
    "  cat(\"    Standard MA: \", sprintf(\"%.4f\", ci_width_standard), \"\\n\", sep = \"\")\n",
    "  cat(\"    RVE:         \", sprintf(\"%.4f\", ci_width_rve), \"\\n\", sep = \"\")\n",
    "  cat(\"    Increase:    +\", sprintf(\"%.1f\", ((ci_width_rve/ci_width_standard - 1)*100)), \"%\\n\\n\", sep = \"\")\n",
    "  \n",
    "  cat(\"  Statistical Significance:\\n\")\n",
    "  cat(\"    Standard MA: p = \", sprintf(\"%.4f\", overall_p), sep = \"\")\n",
    "  if (overall_p < 0.05) cat(\" (significant)\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"    RVE:         p = \", sprintf(\"%.4f\", rve_p), sep = \"\")\n",
    "  if (rve_p < 0.05) cat(\" (significant)\")\n",
    "  cat(\"\\n\\n\")\n",
    "  \n",
    "  # Check if significance changed\n",
    "  standard_sig <- overall_p < 0.05\n",
    "  rve_sig <- rve_p < 0.05\n",
    "  \n",
    "  if (standard_sig == rve_sig) {\n",
    "    cat(\"    → Significance UNCHANGED\\n\")\n",
    "  } else {\n",
    "    cat(\"    ⚠️  Significance CHANGED with RVE adjustment\\n\")\n",
    "  }\n",
    "  \n",
    "  cat(\"\\n\")\n",
    "  \n",
    "  # --------------------------------------------------------------------------\n",
    "  # Step 3.3.5: Interpret Impact of Dependency\n",
    "  # --------------------------------------------------------------------------\n",
    "  cat(\"Step 3.3.5: Interpreting dependency impact...\\n\")\n",
    "  cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "  \n",
    "  cat(\"  DEPENDENCY IMPACT ASSESSMENT:\\n\")\n",
    "  cat(\"  \", paste0(rep(\"=\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "  cat(\"\\n\")\n",
    "  \n",
    "  if (se_inflation < 10) {\n",
    "    cat(\"  ✅ MINIMAL DEPENDENCY IMPACT (SE inflation < 10%)\\n\")\n",
    "    cat(\"     → Within-study correlation has limited effect\\n\")\n",
    "    cat(\"     → Standard and RVE results are similar\\n\")\n",
    "    cat(\"     → Either approach acceptable, but RVE preferred for transparency\\n\")\n",
    "  } else if (se_inflation < 25) {\n",
    "    cat(\"  ⚠️  MODERATE DEPENDENCY IMPACT (SE inflation 10-25%)\\n\")\n",
    "    cat(\"     → Within-study correlation moderately affects inference\\n\")\n",
    "    cat(\"     → RVE provides more conservative estimates\\n\")\n",
    "    cat(\"     → RECOMMEND: Report RVE as primary analysis\\n\")\n",
    "  } else {\n",
    "    cat(\"  ⚠️  SUBSTANTIAL DEPENDENCY IMPACT (SE inflation > 25%)\\n\")\n",
    "    cat(\"     → Within-study correlation substantially affects inference\\n\")\n",
    "    cat(\"     → Standard MA underestimates uncertainty\\n\")\n",
    "    cat(\"     → ESSENTIAL: Report RVE as primary analysis\\n\")\n",
    "    cat(\"     → Standard MA results may be misleading\\n\")\n",
    "  }\n",
    "  \n",
    "  cat(\"\\n\")\n",
    "  \n",
    "  # --------------------------------------------------------------------------\n",
    "  # Step 3.3.6: RVE for Significant Moderators (if any)\n",
    "  # --------------------------------------------------------------------------\n",
    "  if (exists(\"significant_moderators\") && nrow(significant_moderators) > 0) {\n",
    "    \n",
    "    cat(\"Step 3.3.6: RVE analysis for significant moderators...\\n\")\n",
    "    cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "    \n",
    "    cat(\"  Testing \", nrow(significant_moderators), \" significant moderator(s) with RVE...\\n\\n\", sep = \"\")\n",
    "    \n",
    "    rve_moderator_results <- list()\n",
    "    \n",
    "    for (i in 1:nrow(significant_moderators)) {\n",
    "      mod_name <- significant_moderators$Moderator[i]\n",
    "      \n",
    "      cat(\"  [\", i, \"/\", nrow(significant_moderators), \"] \", mod_name, \"\\n\", sep = \"\")\n",
    "      \n",
    "      # Check complete cases\n",
    "      temp_rve <- df[!is.na(df[[mod_name]]), ]\n",
    "      \n",
    "      if (nrow(temp_rve) < 5) {\n",
    "        cat(\"      ⚠️  Insufficient data (n = \", nrow(temp_rve), \") → SKIP\\n\\n\", sep = \"\")\n",
    "        next\n",
    "      }\n",
    "      \n",
    "      # Fit RVE model with moderator\n",
    "      rve_mod <- tryCatch(\n",
    "        {\n",
    "          robu(\n",
    "            formula = as.formula(paste(\"Hedges_g ~\", mod_name)),\n",
    "            data = temp_rve,\n",
    "            studynum = Study_ID,\n",
    "            var.eff.size = vi,\n",
    "            rho = rho_assumed,\n",
    "            small = TRUE\n",
    "          )\n",
    "        },\n",
    "        error = function(e) {\n",
    "          cat(\"      ❌ RVE model failed: \", e$message, \"\\n\\n\", sep = \"\")\n",
    "          return(NULL)\n",
    "        }\n",
    "      )\n",
    "      \n",
    "      if (is.null(rve_mod) || nrow(rve_mod$reg_table) < 2) {\n",
    "        cat(\"      ⚠️  No moderator coefficient → SKIP\\n\\n\")\n",
    "        next\n",
    "      }\n",
    "      \n",
    "      # Extract results (second row is moderator effect)\n",
    "      rve_mod_results <- data.frame(\n",
    "        Moderator = mod_name,\n",
    "        Estimate_RVE = rve_mod$reg_table$b.r[2],\n",
    "        SE_RVE = rve_mod$reg_table$SE[2],\n",
    "        CI_Lower_RVE = rve_mod$reg_table$CI.L[2],\n",
    "        CI_Upper_RVE = rve_mod$reg_table$CI.U[2],\n",
    "        t_value = rve_mod$reg_table$t[2],\n",
    "        df = rve_mod$reg_table$dfs[2],\n",
    "        p_value_RVE = rve_mod$reg_table$prob[2],\n",
    "        n_studies = length(unique(temp_rve$Study_ID)),\n",
    "        n_effects = nrow(temp_rve),\n",
    "        stringsAsFactors = FALSE\n",
    "      )\n",
    "      \n",
    "      rve_moderator_results[[mod_name]] <- rve_mod_results\n",
    "      \n",
    "      cat(\"      ✅ β = \", sprintf(\"%.4f\", rve_mod_results$Estimate_RVE), \n",
    "          \", SE = \", sprintf(\"%.4f\", rve_mod_results$SE_RVE), \n",
    "          \", p = \", sprintf(\"%.4f\", rve_mod_results$p_value_RVE), sep = \"\")\n",
    "      \n",
    "      if (rve_mod_results$p_value_RVE < 0.001) {\n",
    "        cat(\" ***\\n\")\n",
    "      } else if (rve_mod_results$p_value_RVE < 0.01) {\n",
    "        cat(\" **\\n\")\n",
    "      } else if (rve_mod_results$p_value_RVE < 0.05) {\n",
    "        cat(\" *\\n\")\n",
    "      } else {\n",
    "        cat(\"\\n\")\n",
    "      }\n",
    "      \n",
    "      cat(\"\\n\")\n",
    "    }\n",
    "    \n",
    "    # Combine RVE moderator results\n",
    "    if (length(rve_moderator_results) > 0) {\n",
    "      rve_mod_df <- do.call(rbind, rve_moderator_results)\n",
    "      rownames(rve_mod_df) <- NULL\n",
    "      \n",
    "      # Compare standard vs RVE for each moderator\n",
    "      cat(\"  MODERATOR COMPARISON: Standard MA vs. RVE\\n\")\n",
    "      cat(\"  \", paste0(rep(\"=\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "      cat(\"\\n\")\n",
    "      \n",
    "      for (mod in rve_mod_df$Moderator) {\n",
    "        rve_result <- rve_mod_df[rve_mod_df$Moderator == mod, ]\n",
    "        \n",
    "        cat(\"  \", mod, \"\\n\", sep = \"\")\n",
    "        \n",
    "        # Get standard result from univariate_results_list\n",
    "        if (exists(\"univariate_results_list\") && mod %in% names(univariate_results_list)) {\n",
    "          std_model <- univariate_results_list[[mod]]$model\n",
    "          \n",
    "          # For categorical moderators, get the omnibus test\n",
    "          # For continuous, get the coefficient\n",
    "          if (is.factor(df[[mod]]) || is.character(df[[mod]])) {\n",
    "            # Categorical: use omnibus QM test\n",
    "            std_QM <- std_model$QM\n",
    "            std_p <- std_model$QMp\n",
    "            \n",
    "            cat(\"    Standard: QM = \", sprintf(\"%.4f\", std_QM), \n",
    "                \", p = \", sprintf(\"%.4f\", std_p), \" (omnibus test)\\n\", sep = \"\")\n",
    "          } else {\n",
    "            # Continuous: use coefficient (second row)\n",
    "            if (nrow(std_model$b) >= 2) {\n",
    "              std_b <- as.numeric(std_model$b[2])\n",
    "              std_se <- std_model$se[2]\n",
    "              std_p <- std_model$pval[2]\n",
    "              \n",
    "              cat(\"    Standard: β = \", sprintf(\"%.4f\", std_b), \n",
    "                  \", SE = \", sprintf(\"%.4f\", std_se), \n",
    "                  \", p = \", sprintf(\"%.4f\", std_p), \"\\n\", sep = \"\")\n",
    "              \n",
    "              cat(\"    RVE:      β = \", sprintf(\"%.4f\", rve_result$Estimate_RVE), \n",
    "                  \", SE = \", sprintf(\"%.4f\", rve_result$SE_RVE), \n",
    "                  \", p = \", sprintf(\"%.4f\", rve_result$p_value_RVE), \"\\n\", sep = \"\")\n",
    "              \n",
    "              se_ratio_mod <- rve_result$SE_RVE / std_se\n",
    "              cat(\"    SE Ratio: \", sprintf(\"%.2f\", se_ratio_mod), \"x\", sep = \"\")\n",
    "              \n",
    "              # Check if significance changed\n",
    "              std_sig_mod <- std_p < 0.05\n",
    "              rve_sig_mod <- rve_result$p_value_RVE < 0.05\n",
    "              \n",
    "              if (std_sig_mod != rve_sig_mod) {\n",
    "                cat(\" ⚠️  Significance changed!\")\n",
    "              }\n",
    "              cat(\"\\n\\n\")\n",
    "              next\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "        \n",
    "        # If we couldn't get standard results, just show RVE\n",
    "        cat(\"    RVE:      β = \", sprintf(\"%.4f\", rve_result$Estimate_RVE), \n",
    "            \", SE = \", sprintf(\"%.4f\", rve_result$SE_RVE), \n",
    "            \", p = \", sprintf(\"%.4f\", rve_result$p_value_RVE), \"\\n\", sep = \"\")\n",
    "        cat(\"\\n\")\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # --------------------------------------------------------------------------\n",
    "  # Step 3.3.7: Export RVE Results\n",
    "  # --------------------------------------------------------------------------\n",
    "  cat(\"Step 3.3.7: Exporting RVE results...\\n\")\n",
    "  cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\")\n",
    "  \n",
    "  # Verify step3_dir exists\n",
    "  if (!exists(\"step3_dir\") || is.null(step3_dir)) {\n",
    "    step3_dir <- file.path(getwd(), \"Meta_Analysis_Results\", \"Step3_Robustness_Checks\")\n",
    "    if (!dir.exists(step3_dir)) dir.create(step3_dir, recursive = TRUE)\n",
    "  }\n",
    "  \n",
    "  # Overall effect\n",
    "  rve_overall_export <- data.frame(\n",
    "    Analysis = \"RVE Overall Effect\",\n",
    "    rho_assumed = rho_assumed,\n",
    "    k_studies = n_studies,\n",
    "    k_effects = n_effects,\n",
    "    Estimate = round(rve_g, 4),\n",
    "    SE = round(rve_se, 4),\n",
    "    CI_Lower = round(rve_ci_lb, 4),\n",
    "    CI_Upper = round(rve_ci_ub, 4),\n",
    "    t_value = round(rve_t, 4),\n",
    "    df = round(rve_df, 1),\n",
    "    p_value = round(rve_p, 4),\n",
    "    tau2 = round(rve_tau2, 4),\n",
    "    I2 = round(rve_I2, 2),\n",
    "    SE_ratio_vs_standard = round(se_ratio, 2),\n",
    "    SE_inflation_pct = round(se_inflation, 1),\n",
    "    stringsAsFactors = FALSE\n",
    "  )\n",
    "  \n",
    "  # Write RVE overall effect to Step3 folder\n",
    "  safe_write_csv(rve_overall_export, \"rve_overall_effect.csv\", output_dir = step3_dir)\n",
    "  \n",
    "  # Moderator results (if any)\n",
    "  if (exists(\"rve_mod_df\")) {\n",
    "    rve_mod_export <- rve_mod_df\n",
    "    numeric_cols <- c(\"Estimate_RVE\", \"SE_RVE\", \"CI_Lower_RVE\", \"CI_Upper_RVE\",\n",
    "                      \"t_value\", \"df\", \"p_value_RVE\")\n",
    "    for (col in numeric_cols) {\n",
    "      rve_mod_export[[col]] <- round(rve_mod_export[[col]], 4)\n",
    "    }\n",
    "    \n",
    "    # Write RVE moderator results to Step3 folder\n",
    "    safe_write_csv(rve_mod_export, \"rve_moderator_results.csv\", output_dir = step3_dir)\n",
    "  }\n",
    "  \n",
    "  cat(\"\\n\")\n",
    "}\n",
    "\n",
    "if (run_rve) {\n",
    "  cat(\"✅ STEP 3.3 COMPLETE: Robust variance estimation finished\\n\")\n",
    "} else {\n",
    "  cat(\"✅ STEP 3.3 COMPLETE: RVE not necessary (no dependency)\\n\")\n",
    "}\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a1c0faf",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================ \n",
      "STEP 4: PUBLICATION BIAS ASSESSMENT\n",
      "================================================================================ \n",
      "\n",
      "Research Question: Is there evidence of publication bias?\n",
      "\n",
      "Step 4.1: Funnel plot assessment...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  FUNNEL PLOT INTERPRETATION:\n",
      "  ----------------------------------------------------------------------------\n",
      "    Expected (no bias): Symmetric inverted funnel\n",
      "    Bias indicator:     Asymmetry, especially at bottom (low precision)\n",
      "    Missing studies:    Gaps in lower right (small non-significant)\n",
      "\n",
      "  NOTE: Funnel plot saved for visual inspection\n",
      "        (Requires graphical output - not shown in text)\n",
      "\n",
      "  ✅ Funnel plot saved: funnel_plot.png\n",
      "\n",
      "Step 4.2: Egger's regression test for funnel plot asymmetry...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  METHOD: Regression of standardized effect on precision\n",
      "  H₀: No small-study effects (intercept = 0)\n",
      "  H₁: Funnel plot asymmetry present\n",
      "\n",
      "  EGGER'S TEST RESULTS:\n",
      "  ============================================================================\n",
      "\n",
      "    Intercept:        -0.0910\n",
      "    Standard Error:   \n",
      "    z-value:          1.7155\n",
      "    p-value:          0.0977\n",
      "\n",
      "  INTERPRETATION:\n",
      "    No significant asymmetry (p ≥ .05)\n",
      "    ✅ No statistical evidence of publication bias\n",
      "\n",
      "Step 4.3: Trim-and-fill analysis...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  METHOD: Impute missing studies to restore funnel plot symmetry\n",
      "  PURPOSE: Estimate effect size adjusted for publication bias\n",
      "\n",
      "  TRIM-AND-FILL RESULTS:\n",
      "  ============================================================================\n",
      "\n",
      "    Studies imputed:    0\n",
      "    → No missing studies detected\n",
      "    → Funnel plot appears symmetric\n",
      "\n",
      "  ADJUSTED ESTIMATE: Same as original (no adjustment needed)\n",
      "\n",
      "Step 4.4: Fail-safe N analysis...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  METHOD: Calculate number of null studies needed to nullify effect\n",
      "  PURPOSE: Assess robustness to unreported non-significant studies\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"Setting type='General' when using fsn() on a model object.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FAIL-SAFE N RESULTS:\n",
      "  ============================================================================\n",
      "\n",
      "    Fail-safe N:      281 studies\n",
      "    Target (5k+5):    150 studies\n",
      "    → Fail-safe N EXCEEDS target\n",
      "    → Effect is robust to file-drawer problem\n",
      "\n",
      "  INTERPRETATION:\n",
      "    ✅ Effect robust to unreported null studies\n",
      "    281 null studies would be needed to nullify effect\n",
      "\n",
      "Step 4.5: Publication bias assessment summary...\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "  PUBLICATION BIAS ASSESSMENT SUMMARY:\n",
      "  ============================================================================\n",
      "\n",
      "  1. FUNNEL PLOT:\n",
      "     → Visual inspection recommended (see funnel_plot.png)\n",
      "\n",
      "  2. EGGER'S TEST:\n",
      "     → ✅ No statistical evidence of publication bias\n",
      "     → p = 0.0977\n",
      "\n",
      "  3. TRIM-AND-FILL:\n",
      "     → ✅ No publication bias detected by trim-and-fill\n",
      "\n",
      "  4. FAIL-SAFE N:\n",
      "     → ✅ Effect robust to unreported null studies\n",
      "     → N = 281 (target: 150)\n",
      "\n",
      "  ----------------------------------------------------------------------------\n",
      "  BIAS INDICATORS PRESENT: 0/3\n",
      "  ----------------------------------------------------------------------------\n",
      "\n",
      "  OVERALL CONCLUSION:\n",
      "    ✅ NO EVIDENCE OF PUBLICATION BIAS\n",
      "    Recommendation: Results appear unbiased; report with confidence\n",
      "\n",
      "Step 4.6: Exporting publication bias assessment results...\n",
      "-------------------------------------------------------------------------------- \n",
      "  ✅ Saved: publication_bias_tests.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ STEP 4 COMPLETE: Publication bias assessment finished\n",
      "================================================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: PUBLICATION BIAS ASSESSMENT\n",
    "# ============================================================================\n",
    "#\n",
    "# Purpose: To evaluate the potential presence of publication bias and small‐study effects.\n",
    "#\n",
    "# Methods:\n",
    "#   Multi-pronged publication bias detection:\n",
    "#     1. Funnel plot (visual asymmetry)\n",
    "#     2. Egger’s regression test for small-study effects\n",
    "#     3. Trim-and-fill procedure for bias-adjusted effect estimation\n",
    "#     4. Rosenthal’s fail-safe N to quantify robustness to unpublished null studies\n",
    "#\n",
    "# Files Generated (Output):\n",
    "#   • funnel_plot.png\n",
    "#   • publication_bias_tests.csv\n",
    "#   • publication_bias_trim_and_fill.csv → (Only generated when k_imputed > 0)\n",
    "#\n",
    "# Bias Interpretation Framework:\n",
    "#   0 indicators → No evidence of bias\n",
    "#   1 indicator  → Minimal concern\n",
    "#   2 indicators → Moderate concern\n",
    "#   3 indicators → Substantial bias likely present\n",
    "#\n",
    "# ============================================================================\n",
    "\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\")\n",
    "cat(\"STEP 4: PUBLICATION BIAS ASSESSMENT\\n\")\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "cat(\"Research Question: Is there evidence of publication bias?\\n\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 4.1: Funnel Plot Asymmetry (Visual Inspection)\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 4.1: Funnel plot assessment...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "cat(\"  FUNNEL PLOT INTERPRETATION:\\n\")\n",
    "cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"    Expected (no bias): Symmetric inverted funnel\\n\")\n",
    "cat(\"    Bias indicator:     Asymmetry, especially at bottom (low precision)\\n\")\n",
    "cat(\"    Missing studies:    Gaps in lower right (small non-significant)\\n\\n\")\n",
    "\n",
    "cat(\"  NOTE: Funnel plot saved for visual inspection\\n\")\n",
    "cat(\"        (Requires graphical output - not shown in text)\\n\\n\")\n",
    "\n",
    "# Save funnel plot (if graphical output available)\n",
    "# Verify step4_dir exists\n",
    "if (!exists(\"step4_dir\") || is.null(step4_dir)) {\n",
    "  step4_dir <- file.path(getwd(), \"Meta_Analysis_Results\", \"Step4_Publication_Bias\")\n",
    "  if (!dir.exists(step4_dir)) dir.create(step4_dir, recursive = TRUE)\n",
    "}\n",
    "\n",
    "tryCatch({\n",
    "  png(file.path(step4_dir, \"funnel_plot.png\"), width = 800, height = 600, res = 120)\n",
    "  funnel(res_overall, \n",
    "         xlab = \"Hedges' g\",\n",
    "         ylab = \"Standard Error\",\n",
    "         main = \"Funnel Plot for Publication Bias Assessment\",\n",
    "         back = \"white\",\n",
    "         shade = \"white\")\n",
    "  dev.off()\n",
    "  cat(\"  ✅ Funnel plot saved: funnel_plot.png\\n\\n\")\n",
    "}, error = function(e) {\n",
    "  cat(\"  ⚠️  Funnel plot not saved (graphical device not available)\\n\\n\")\n",
    "})\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 4.2: Egger's Regression Test\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 4.2: Egger's regression test for funnel plot asymmetry...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "cat(\"  METHOD: Regression of standardized effect on precision\\n\")\n",
    "cat(\"  H₀: No small-study effects (intercept = 0)\\n\")\n",
    "cat(\"  H₁: Funnel plot asymmetry present\\n\\n\")\n",
    "\n",
    "# Perform Egger's test\n",
    "egger_test <- regtest(res_overall, model = \"lm\")\n",
    "\n",
    "cat(\"  EGGER'S TEST RESULTS:\\n\")\n",
    "cat(\"  \", paste0(rep(\"=\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"\\n\")\n",
    "cat(\"    Intercept:        \", sprintf(\"%.4f\", egger_test$est), \"\\n\", sep = \"\")\n",
    "cat(\"    Standard Error:   \", sprintf(\"%.4f\", egger_test$se), \"\\n\", sep = \"\")\n",
    "cat(\"    z-value:          \", sprintf(\"%.4f\", egger_test$zval), \"\\n\", sep = \"\")\n",
    "cat(\"    p-value:          \", sprintf(\"%.4f\", egger_test$pval), sep = \"\")\n",
    "\n",
    "if (egger_test$pval < 0.001) {\n",
    "  cat(\" ***\\n\")\n",
    "  egger_interpretation <- \"HIGHLY SIGNIFICANT asymmetry (p < .001)\"\n",
    "  egger_conclusion <- \"⚠️  Strong evidence of publication bias\"\n",
    "} else if (egger_test$pval < 0.01) {\n",
    "  cat(\" **\\n\")\n",
    "  egger_interpretation <- \"Very significant asymmetry (p < .01)\"\n",
    "  egger_conclusion <- \"⚠️  Evidence of publication bias\"\n",
    "} else if (egger_test$pval < 0.05) {\n",
    "  cat(\" *\\n\")\n",
    "  egger_interpretation <- \"Significant asymmetry (p < .05)\"\n",
    "  egger_conclusion <- \"⚠️  Some evidence of publication bias\"\n",
    "} else {\n",
    "  cat(\"\\n\")\n",
    "  egger_interpretation <- \"No significant asymmetry (p ≥ .05)\"\n",
    "  egger_conclusion <- \"✅ No statistical evidence of publication bias\"\n",
    "}\n",
    "\n",
    "cat(\"\\n\")\n",
    "cat(\"  INTERPRETATION:\\n\")\n",
    "cat(\"    \", egger_interpretation, \"\\n\", sep = \"\")\n",
    "cat(\"    \", egger_conclusion, \"\\n\", sep = \"\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 4.3: Trim-and-Fill Analysis\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 4.3: Trim-and-fill analysis...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "cat(\"  METHOD: Impute missing studies to restore funnel plot symmetry\\n\")\n",
    "cat(\"  PURPOSE: Estimate effect size adjusted for publication bias\\n\\n\")\n",
    "\n",
    "# Perform trim-and-fill\n",
    "taf_results <- trimfill(res_overall)\n",
    "\n",
    "cat(\"  TRIM-AND-FILL RESULTS:\\n\")\n",
    "cat(\"  \", paste0(rep(\"=\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Number of imputed studies\n",
    "k_imputed <- taf_results$k0\n",
    "\n",
    "cat(\"    Studies imputed:    \", k_imputed, \"\\n\", sep = \"\")\n",
    "\n",
    "if (k_imputed == 0) {\n",
    "  cat(\"    → No missing studies detected\\n\")\n",
    "  cat(\"    → Funnel plot appears symmetric\\n\\n\")\n",
    "  \n",
    "  cat(\"  ADJUSTED ESTIMATE: Same as original (no adjustment needed)\\n\\n\")\n",
    "  \n",
    "  taf_conclusion <- \"✅ No publication bias detected by trim-and-fill\"\n",
    "  \n",
    "} else {\n",
    "  cat(\"    → \", k_imputed, \" studies imputed on \", \n",
    "      ifelse(taf_results$side == \"left\", \"left\", \"right\"), \" side\\n\", sep = \"\")\n",
    "  cat(\"    → Suggests missing \", \n",
    "      ifelse(taf_results$side == \"left\", \"negative\", \"positive\"), \n",
    "      \" studies\\n\\n\", sep = \"\")\n",
    "  \n",
    "  # Adjusted effect size\n",
    "  taf_g <- taf_results$b[1]\n",
    "  taf_ci_lb <- taf_results$ci.lb\n",
    "  taf_ci_ub <- taf_results$ci.ub\n",
    "  taf_p <- taf_results$pval\n",
    "  \n",
    "  cat(\"  ORIGINAL vs. ADJUSTED EFFECT:\\n\")\n",
    "  cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "  cat(\"    Original:  g = \", sprintf(\"%.4f\", overall_g), \n",
    "      \" [\", sprintf(\"%.4f\", overall_ci_lb), \", \",\n",
    "      sprintf(\"%.4f\", overall_ci_ub), \"], p = \", \n",
    "      sprintf(\"%.4f\", overall_p), \"\\n\", sep = \"\")\n",
    "  cat(\"    Adjusted:  g = \", sprintf(\"%.4f\", taf_g), \n",
    "      \" [\", sprintf(\"%.4f\", taf_ci_lb), \", \",\n",
    "      sprintf(\"%.4f\", taf_ci_ub), \"], p = \", \n",
    "      sprintf(\"%.4f\", taf_p), \"\\n\", sep = \"\")\n",
    "  \n",
    "  # Calculate change\n",
    "  taf_change <- taf_g - overall_g\n",
    "  taf_change_pct <- (taf_change / overall_g) * 100\n",
    "  \n",
    "  cat(\"    Change:    \", sprintf(\"%+.4f\", taf_change), \n",
    "      \" (\", sprintf(\"%+.1f\", taf_change_pct), \"%)\\n\\n\", sep = \"\")\n",
    "  \n",
    "  # Interpretation\n",
    "  if (abs(taf_change_pct) < 10) {\n",
    "    taf_conclusion <- \"⚠️  Minimal bias impact (adjustment < 10%)\"\n",
    "    taf_recommendation <- \"Report original effect; note trim-and-fill in supplementary\"\n",
    "  } else if (abs(taf_change_pct) < 25) {\n",
    "    taf_conclusion <- \"⚠️  Moderate bias impact (adjustment 10-25%)\"\n",
    "    taf_recommendation <- \"Report both original and adjusted effects\"\n",
    "  } else {\n",
    "    taf_conclusion <- \"⚠️  Substantial bias impact (adjustment > 25%)\"\n",
    "    taf_recommendation <- \"Consider adjusted effect as primary estimate\"\n",
    "  }\n",
    "  \n",
    "  cat(\"  INTERPRETATION:\\n\")\n",
    "  cat(\"    \", taf_conclusion, \"\\n\", sep = \"\")\n",
    "  cat(\"    Recommendation: \", taf_recommendation, \"\\n\", sep = \"\")\n",
    "  \n",
    "  cat(\"\\n\")\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 4.4: Fail-Safe N (Rosenthal's Method)\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 4.4: Fail-safe N analysis...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "cat(\"  METHOD: Calculate number of null studies needed to nullify effect\\n\")\n",
    "cat(\"  PURPOSE: Assess robustness to unreported non-significant studies\\n\\n\")\n",
    "\n",
    "# Calculate fail-safe N using the fitted model\n",
    "fsn_results <- fsn(res_overall, type = \"Rosenthal\")\n",
    "\n",
    "cat(\"  FAIL-SAFE N RESULTS:\\n\")\n",
    "cat(\"  \", paste0(rep(\"=\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"\\n\")\n",
    "cat(\"    Fail-safe N:      \", fsn_results$fsnum, \" studies\\n\", sep = \"\")\n",
    "cat(\"    Target (5k+5):    \", 5*k + 5, \" studies\\n\", sep = \"\")\n",
    "\n",
    "if (fsn_results$fsnum > (5*k + 5)) {\n",
    "  cat(\"    → Fail-safe N EXCEEDS target\\n\")\n",
    "  cat(\"    → Effect is robust to file-drawer problem\\n\")\n",
    "  fsn_conclusion <- \"✅ Effect robust to unreported null studies\"\n",
    "} else {\n",
    "  cat(\"    → Fail-safe N BELOW target\\n\")\n",
    "  cat(\"    → Effect may be vulnerable to file-drawer problem\\n\")\n",
    "  fsn_conclusion <- \"⚠️  Effect potentially vulnerable to unreported studies\"\n",
    "}\n",
    "\n",
    "cat(\"\\n\")\n",
    "cat(\"  INTERPRETATION:\\n\")\n",
    "cat(\"    \", fsn_conclusion, \"\\n\", sep = \"\")\n",
    "cat(\"    \", fsn_results$fsnum, \" null studies would be needed to nullify effect\\n\", sep = \"\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 4.5: Overall Publication Bias Summary\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 4.5: Publication bias assessment summary...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\\n\")\n",
    "\n",
    "cat(\"  PUBLICATION BIAS ASSESSMENT SUMMARY:\\n\")\n",
    "cat(\"  \", paste0(rep(\"=\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Count bias indicators\n",
    "bias_indicators <- 0\n",
    "if (egger_test$pval < 0.05) bias_indicators <- bias_indicators + 1\n",
    "if (k_imputed > 0) bias_indicators <- bias_indicators + 1\n",
    "if (fsn_results$fsnum < (5*k + 5)) bias_indicators <- bias_indicators + 1\n",
    "\n",
    "cat(\"  1. FUNNEL PLOT:\\n\")\n",
    "cat(\"     → Visual inspection recommended (see funnel_plot.png)\\n\\n\")\n",
    "\n",
    "cat(\"  2. EGGER'S TEST:\\n\")\n",
    "cat(\"     → \", egger_conclusion, \"\\n\", sep = \"\")\n",
    "cat(\"     → p = \", sprintf(\"%.4f\", egger_test$pval), \"\\n\\n\", sep = \"\")\n",
    "\n",
    "cat(\"  3. TRIM-AND-FILL:\\n\")\n",
    "cat(\"     → \", taf_conclusion, \"\\n\", sep = \"\")\n",
    "if (k_imputed > 0) {\n",
    "  cat(\"     → \", k_imputed, \" studies imputed\\n\", sep = \"\")\n",
    "  cat(\"     → Adjusted g = \", sprintf(\"%.4f\", taf_g), \n",
    "      \" (change: \", sprintf(\"%+.1f\", taf_change_pct), \"%)\\n\", sep = \"\")\n",
    "}\n",
    "cat(\"\\n\")\n",
    "\n",
    "cat(\"  4. FAIL-SAFE N:\\n\")\n",
    "cat(\"     → \", fsn_conclusion, \"\\n\", sep = \"\")\n",
    "cat(\"     → N = \", fsn_results$fsnum, \" (target: \", 5*k + 5, \")\\n\\n\", sep = \"\")\n",
    "\n",
    "cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"  BIAS INDICATORS PRESENT: \", bias_indicators, \"/3\\n\", sep = \"\")\n",
    "cat(\"  \", paste0(rep(\"-\", 76), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Overall conclusion\n",
    "if (bias_indicators == 0) {\n",
    "  overall_bias_conclusion <- \"✅ NO EVIDENCE OF PUBLICATION BIAS\"\n",
    "  overall_bias_recommendation <- \"Results appear unbiased; report with confidence\"\n",
    "} else if (bias_indicators == 1) {\n",
    "  overall_bias_conclusion <- \"⚠️  MINIMAL EVIDENCE OF PUBLICATION BIAS\"\n",
    "  overall_bias_recommendation <- \"Results likely robust; acknowledge limitations\"\n",
    "} else if (bias_indicators == 2) {\n",
    "  overall_bias_conclusion <- \"⚠️  MODERATE EVIDENCE OF PUBLICATION BIAS\"\n",
    "  overall_bias_recommendation <- \"Report bias tests; consider adjusted estimates\"\n",
    "} else {\n",
    "  overall_bias_conclusion <- \"⚠️  SUBSTANTIAL EVIDENCE OF PUBLICATION BIAS\"\n",
    "  overall_bias_recommendation <- \"Interpret results cautiously; report all bias assessments\"\n",
    "}\n",
    "\n",
    "cat(\"  OVERALL CONCLUSION:\\n\")\n",
    "cat(\"    \", overall_bias_conclusion, \"\\n\", sep = \"\")\n",
    "cat(\"    Recommendation: \", overall_bias_recommendation, \"\\n\", sep = \"\")\n",
    "\n",
    "cat(\"\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Step 4.6: Export Publication Bias Results\n",
    "# ----------------------------------------------------------------------------\n",
    "cat(\"Step 4.6: Exporting publication bias assessment results...\\n\")\n",
    "cat(paste0(rep(\"-\", 80), collapse = \"\"), \"\\n\")\n",
    "\n",
    "# Verify step4_dir exists\n",
    "if (!exists(\"step4_dir\") || is.null(step4_dir)) {\n",
    "  step4_dir <- file.path(getwd(), \"Meta_Analysis_Results\", \"Step4_Publication_Bias\")\n",
    "  if (!dir.exists(step4_dir)) dir.create(step4_dir, recursive = TRUE)\n",
    "}\n",
    "\n",
    "# Compile all bias test results\n",
    "bias_results <- data.frame(\n",
    "  Test = c(\"Egger's Regression\", \"Trim-and-Fill\", \"Fail-Safe N\"),\n",
    "  Statistic = c(\n",
    "    sprintf(\"Intercept = %.4f\", egger_test$est),\n",
    "    sprintf(\"%d studies imputed\", k_imputed),\n",
    "    sprintf(\"N = %d\", fsn_results$fsnum)\n",
    "  ),\n",
    "  p_value = c(\n",
    "    round(egger_test$pval, 4),\n",
    "    ifelse(k_imputed > 0, round(taf_p, 4), NA),\n",
    "    NA\n",
    "  ),\n",
    "  Interpretation = c(\n",
    "    ifelse(egger_test$pval < 0.05, \"Asymmetry detected\", \"No asymmetry\"),\n",
    "    ifelse(k_imputed > 0, \"Bias suspected\", \"No bias\"),\n",
    "    ifelse(fsn_results$fsnum > (5*k + 5), \"Robust\", \"Vulnerable\")\n",
    "  ),\n",
    "  Bias_Evidence = c(\n",
    "    ifelse(egger_test$pval < 0.05, \"Yes\", \"No\"),\n",
    "    ifelse(k_imputed > 0, \"Yes\", \"No\"),\n",
    "    ifelse(fsn_results$fsnum < (5*k + 5), \"Yes\", \"No\")\n",
    "  ),\n",
    "  stringsAsFactors = FALSE\n",
    ")\n",
    "\n",
    "# Add trim-and-fill adjusted effect if imputed\n",
    "if (k_imputed > 0) {\n",
    "  taf_effect <- data.frame(\n",
    "    Analysis = \"Trim-and-Fill Adjusted\",\n",
    "    k_original = k,\n",
    "    k_imputed = k_imputed,\n",
    "    Estimate_original = round(overall_g, 4),\n",
    "    Estimate_adjusted = round(taf_g, 4),\n",
    "    Change = round(taf_change, 4),\n",
    "    Change_pct = round(taf_change_pct, 2),\n",
    "    CI_Lower_adjusted = round(taf_ci_lb, 4),\n",
    "    CI_Upper_adjusted = round(taf_ci_ub, 4),\n",
    "    p_value_adjusted = round(taf_p, 4),\n",
    "    stringsAsFactors = FALSE\n",
    "  )\n",
    "  \n",
    "  # Save to Step4 folder\n",
    "  safe_write_csv(taf_effect, \"publication_bias_trim_and_fill.csv\", output_dir = step4_dir)\n",
    "}\n",
    "\n",
    "# Save publication bias tests to Step4 folder\n",
    "safe_write_csv(bias_results, \"publication_bias_tests.csv\", output_dir = step4_dir)\n",
    "\n",
    "cat(\"\\n\")\n",
    "cat(\"✅ STEP 4 COMPLETE: Publication bias assessment finished\\n\")\n",
    "cat(paste0(rep(\"=\", 80), collapse = \"\"), \"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
