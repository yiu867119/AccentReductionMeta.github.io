{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d6167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 1: Load raw data files\n",
      "======================================================================\n",
      "Moderator file: 28 rows × 24 columns\n",
      "Effect-size file: 29 rows × 32 columns\n",
      "\n",
      "======================================================================\n",
      "STEP 2: Standardize 'index' column and filter to common indices\n",
      "======================================================================\n",
      "Indices in moderator file: 28\n",
      "Indices in effect-size file: 29\n",
      "Common indices (in both): 28\n",
      "⚠️  Indices only in effect-size file (will be excluded): ['259']\n",
      "\n",
      "After filtering:\n",
      "Moderator file: 28 rows\n",
      "Effect-size file: 28 rows\n",
      "\n",
      "======================================================================\n",
      "STEP 3: Normalize missing-value codes to NaN\n",
      "======================================================================\n",
      "Missing codes normalized: NG, N/A, Mixed, etc. → NaN\n",
      "\n",
      "======================================================================\n",
      "STEP 4: Standardize Yes/No values\n",
      "======================================================================\n",
      "Yes/No values standardized (yes/no/y/n → Yes/No)\n",
      "\n",
      "======================================================================\n",
      "STEP 5: Standardize categorical labels\n",
      "======================================================================\n",
      "Age_Group standardized: adult → Adult, adolescent → Adolescent\n",
      "Proficiency_Level standardized: intermediate → Intermediate\n",
      "  (Mixed/compound levels set to NaN)\n",
      "\n",
      "======================================================================\n",
      "STEP 6: Transform Gender_Ratio_FM to proportion of females\n",
      "======================================================================\n",
      "Original Gender_Ratio_FM values (sample):\n",
      "[nan, '30F/0M', nan, nan, nan, nan, nan, nan, nan, '74F/19M', '74F/19M', '25F/24M']\n",
      "\n",
      "Transformed to proportion (female/total, 2 decimals):\n",
      "[nan, 1.0, nan, nan, nan, nan, nan, nan, nan, 0.8, 0.8, 0.51]\n",
      "✓ Gender_Ratio_FM now represents proportion of females (0-1 scale)\n",
      "\n",
      "======================================================================\n",
      "STEP 7: Transform Training_TotalMinute to numeric\n",
      "======================================================================\n",
      "Original Training_TotalMinute values (sample):\n",
      "['180', '720', nan, '240', '960', nan, '1170', nan, '240', '522']\n",
      "\n",
      "Transformed to numeric minutes:\n",
      "[180.0, 720.0, nan, 240.0, 960.0, nan, 1170.0, nan, 240.0, 522.0]\n",
      "✓ Training_TotalMinute: expressions evaluated (e.g., '13*90' → 1170.0)\n",
      "✓ Training_TotalWeeks converted to numeric\n",
      "\n",
      "======================================================================\n",
      "STEP 7.5: Create Treatment_Duration categorical variable\n",
      "======================================================================\n",
      "Original Training_TotalWeeks values (sample):\n",
      "[6.0, 6.0, 3.0, 4.0, 8.0, 12.0, 13.0, nan, 1.0, 1.0]\n",
      "\n",
      "Treatment_Duration created:\n",
      "  • Short (1-4 weeks)\n",
      "  • Medium (5-8 weeks)\n",
      "  • Long (≥9 weeks)\n",
      "\n",
      "Distribution:\n",
      "  Short   : 15 studies\n",
      "  Medium  :  6 studies\n",
      "  Long    :  6 studies\n",
      "  Missing :  1 studies\n",
      "\n",
      "✓ Treatment_Duration variable created successfully\n",
      "\n",
      "======================================================================\n",
      "STEP 8: Prepare effect-size data for merging\n",
      "======================================================================\n",
      "Effect-size data prepared: 28 rows\n",
      "\n",
      "======================================================================\n",
      "STEP 9: Merge moderator and effect-size data\n",
      "======================================================================\n",
      "Merged dataset: 28 rows × 32 columns\n",
      "\n",
      "======================================================================\n",
      "STEP 10: Verify data integrity\n",
      "======================================================================\n",
      "⚠️  Study_ID mismatches found: 16\n",
      "    index                     Study_ID        Study_ID_effect\n",
      "1      22       Almalki_Algethami_2022           Almalki_2022\n",
      "8      60            Yeldham_Choy_2022       YeldhamChoy_2022\n",
      "12   85_1            Hirschi_Kang_2025           Hirschi_2025\n",
      "13   85_2            Hirschi_Kang_2025           Hirschi_2025\n",
      "14     86                   Mahdi_2025  Hajmalek_Sabouri_2025\n",
      "16    125      Gooch_Saito_Lyster_2016             Gooch_2016\n",
      "17    127             Wu_Liu_Chen_2021                Wu_2021\n",
      "18    129               Liu_Wu_Ye_2020               Liu_2020\n",
      "19    150          Li_Mohamad_You_2025                Li_2025\n",
      "20    196        Zhang_Chang_Liao_2021              Zhang2021\n",
      "21  216_1     Zhang_Baills_Prieto_2023             Zhang_2023\n",
      "22  216_2     Zhang_Baills_Prieto_2023             Zhang_2023\n",
      "24  224_1                  Dai_Wu_2023               Dai_2023\n",
      "25  224_2                  Dai_Wu_2023               Dai_2023\n",
      "26  224_3                  Dai_Wu_2023               Dai_2023\n",
      "27    226  Huang_Barrett_Lo_Tseng_2024             Huang_2024\n",
      "⚠️  Effect_ID mismatches found: 15\n",
      "    index                              Effect_ID  \\\n",
      "6      38                          Leis2025_Post   \n",
      "8      60                       Yeldham2022_Post   \n",
      "9    61_1        Tseng2025_Nonverbal_Post_Stress   \n",
      "10   61_2     Tseng2025_Nonverbal_Post_Segmental   \n",
      "12   85_1       Hirschi2025_VN_Post_Accentedness   \n",
      "13   85_2  Hirschi2025_VN_Post_Comprehensibility   \n",
      "14     86                         Mahdi2025_Post   \n",
      "16    125                         Gooch2016_Post   \n",
      "19    150                            Li2025_Post   \n",
      "20    196              Zhang2021_Intonation_Post   \n",
      "21  216_1            Zhang2023_Post_Accentedness   \n",
      "22  216_2       Zhang2023_Post_Comprehensibility   \n",
      "24  224_1                         DaiWu2023_Post   \n",
      "25  224_2                         DaiWu2023_Post   \n",
      "26  224_3                         DaiWu2023_Post   \n",
      "\n",
      "                    Effect_ID_effect  \n",
      "6                   Leis2025_Overall  \n",
      "8               YeldhamChoy2022_Post  \n",
      "9              Tseng2025_Post_Stress  \n",
      "10         Tseng2025_Post_Segmentals  \n",
      "12              Hirschi2025_Acc_Post  \n",
      "13             Hirschi2025_Comp_Post  \n",
      "14                 Hajmalek2025_Post  \n",
      "16             Gooch2016_Prompt_Post  \n",
      "19                   Li2025_SAQ_Post  \n",
      "20                 Zhang2021_IT_Post  \n",
      "21            Zhang2023_Accentedness  \n",
      "22  Zhang2023_Comprehensibility_Post  \n",
      "24    Dai2023_Comprehensibility_Post  \n",
      "25            Dai2023_Segmental_Post  \n",
      "26               Dai2023_Stress_Post  \n",
      "\n",
      "======================================================================\n",
      "STEP 11: Export final dataset\n",
      "======================================================================\n",
      "✅ Final dataset exported: meta_ready_cleaned.csv\n",
      "   Total rows: 28\n",
      "   Total columns: 30\n",
      "\n",
      "Key transformations:\n",
      "   • Gender_Ratio_FM → proportion of females (0-1, 2 decimals)\n",
      "   • Training_TotalMinute → numeric minutes (expressions evaluated)\n",
      "   • Only studies present in BOTH input files are included\n",
      "\n",
      "======================================================================\n",
      "Data preparation complete. Ready for meta-analysis.\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_16064\\3859815534.py:53: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  moderator_raw = moderator_raw.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_16064\\3859815534.py:54: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  effect_size_raw = effect_size_raw.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Meta-analysis Data Preparation Script \n",
    "====================================================\n",
    "\n",
    "Input Files:\n",
    "-----------\n",
    "- moderator_raw.csv: Study-level moderator variables\n",
    "- effect_size_raw_results.csv: Effect-size estimates (Hedges' g, SE, CI)\n",
    "\n",
    "Output File:\n",
    "-----------\n",
    "- meta_ready_cleaned_23studies.csv: Final merged, cleaned dataset\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD RAW DATA FILES\n",
    "# ============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 1: Load raw data files\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load CSV files as strings to preserve original formatting and coding\n",
    "# dtype=str prevents automatic type conversion that might lose information\n",
    "# encoding=\"utf-8-sig\" handles BOM (byte order mark) in Excel-exported CSVs\n",
    "moderator_raw = pd.read_csv(\"moderator_raw.csv\", dtype=str, encoding=\"utf-8-sig\")\n",
    "effect_size_raw = pd.read_csv(\"effect_size_raw_results.csv\", dtype=str, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"Moderator file: {moderator_raw.shape[0]} rows × {moderator_raw.shape[1]} columns\")\n",
    "print(f\"Effect-size file: {effect_size_raw.shape[0]} rows × {effect_size_raw.shape[1]} columns\")\n",
    "\n",
    "# Remove leading/trailing whitespace from all string cells\n",
    "# This prevents merge failures due to inconsistent spacing\n",
    "moderator_raw = moderator_raw.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "effect_size_raw = effect_size_raw.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: STANDARDIZE 'INDEX' COLUMN AND FILTER TO COMMON INDICES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 2: Standardize 'index' column and filter to common indices\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Clean the 'index' column in both tables\n",
    "# Convert to string and remove any whitespace to ensure consistent matching\n",
    "moderator_raw[\"index\"] = moderator_raw[\"index\"].astype(str).str.strip()\n",
    "effect_size_raw[\"index\"] = effect_size_raw[\"index\"].astype(str).str.strip()\n",
    "\n",
    "# Identify indices that exist in BOTH tables\n",
    "# Using set intersection to find common indices\n",
    "indices_moderator = set(moderator_raw[\"index\"])\n",
    "indices_effect = set(effect_size_raw[\"index\"])\n",
    "common_indices = indices_moderator & indices_effect  # Intersection\n",
    "\n",
    "print(f\"Indices in moderator file: {len(indices_moderator)}\")\n",
    "print(f\"Indices in effect-size file: {len(indices_effect)}\")\n",
    "print(f\"Common indices (in both): {len(common_indices)}\")\n",
    "\n",
    "# Identify indices that appear in only one file\n",
    "# These will be excluded from the final dataset\n",
    "only_moderator = sorted(indices_moderator - indices_effect)\n",
    "only_effect = sorted(indices_effect - indices_moderator)\n",
    "\n",
    "if only_moderator:\n",
    "    print(f\"\\n⚠️  Indices only in moderator file (will be excluded): {only_moderator}\")\n",
    "if only_effect:\n",
    "    print(f\"⚠️  Indices only in effect-size file (will be excluded): {only_effect}\")\n",
    "\n",
    "# Filter BOTH tables to retain only common indices\n",
    "# This ensures a 1:1 merge without missing data on either side\n",
    "moderator_raw = moderator_raw[moderator_raw[\"index\"].isin(common_indices)].copy()\n",
    "effect_size_raw = effect_size_raw[effect_size_raw[\"index\"].isin(common_indices)].copy()\n",
    "\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(f\"Moderator file: {moderator_raw.shape[0]} rows\")\n",
    "print(f\"Effect-size file: {effect_size_raw.shape[0]} rows\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: NORMALIZE MISSING-VALUE CODES TO NaN\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 3: Normalize missing-value codes to NaN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define all representations of missing data used in the raw files\n",
    "# These will be standardized to numpy NaN for consistent handling\n",
    "missing_codes = [\n",
    "    \"NG\",      # Not Reported\n",
    "    \"N/R\",     # Not Reported (alternative)\n",
    "    \"n/a\",     # Not Applicable\n",
    "    \"N/A\",     # Not Applicable (capitalized)\n",
    "    \"NA\",      # Not Available\n",
    "    \"NaN\",     # Already NaN as string\n",
    "    \"\",        # Empty string\n",
    "    \"-\",       # Dash used as placeholder\n",
    "    \"Mixed\",   # Mixed/heterogeneous (cannot be analyzed as single category)\n",
    "    \"mixed\",   # Mixed (lowercase)\n",
    "    \"MIXED\"    # Mixed (uppercase)\n",
    "]\n",
    "\n",
    "# Replace all missing codes with numpy NaN across both dataframes\n",
    "moderator_raw = moderator_raw.replace(missing_codes, np.nan)\n",
    "effect_size_raw = effect_size_raw.replace(missing_codes, np.nan)\n",
    "\n",
    "print(\"Missing codes normalized: NG, N/A, Mixed, etc. → NaN\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: STANDARDIZE YES/NO VALUES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 4: Standardize Yes/No values\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Map all variations of Yes/No to standard capitalized format\n",
    "# This ensures consistency for categorical moderator analysis\n",
    "yes_no_map = {\n",
    "    # Yes variations\n",
    "    \"yes\": \"Yes\",\n",
    "    \"YES\": \"Yes\",\n",
    "    \"y\": \"Yes\",\n",
    "    \"Y\": \"Yes\",\n",
    "    \n",
    "    # No variations\n",
    "    \"no\": \"No\",\n",
    "    \"NO\": \"No\",\n",
    "    \"n\": \"No\",\n",
    "    \"N\": \"No\"\n",
    "}\n",
    "\n",
    "moderator_raw = moderator_raw.replace(yes_no_map)\n",
    "effect_size_raw = effect_size_raw.replace(yes_no_map)\n",
    "\n",
    "print(\"Yes/No values standardized (yes/no/y/n → Yes/No)\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: STANDARDIZE CATEGORICAL LABELS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 5: Standardize categorical labels\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# --- Standardize Age_Group ---\n",
    "# Convert to consistent capitalization: Adult, Adolescent\n",
    "if \"Age_Group\" in moderator_raw.columns:\n",
    "    moderator_raw[\"Age_Group\"] = moderator_raw[\"Age_Group\"].replace({\n",
    "        \"adult\": \"Adult\",\n",
    "        \"adolescent\": \"Adolescent\",\n",
    "        \"adolescent \": \"Adolescent\"  # Handle trailing space\n",
    "    })\n",
    "    print(\"Age_Group standardized: adult → Adult, adolescent → Adolescent\")\n",
    "\n",
    "# --- Standardize Proficiency_Level ---\n",
    "# Convert to consistent capitalization\n",
    "# Mixed/compound levels (e.g., \"Intermediate_Advanced\") → NaN\n",
    "# because they cannot be analyzed as a single proficiency category\n",
    "if \"Proficiency_Level\" in moderator_raw.columns:\n",
    "    moderator_raw[\"Proficiency_Level\"] = moderator_raw[\"Proficiency_Level\"].replace({\n",
    "        \"intermediate\": \"Intermediate\",\n",
    "        \"Intermediate_Advanced\": np.nan,  # Compound level → missing\n",
    "        \"mixed\": np.nan,\n",
    "        \"Mixed\": np.nan\n",
    "    })\n",
    "    print(\"Proficiency_Level standardized: intermediate → Intermediate\")\n",
    "    print(\"  (Mixed/compound levels set to NaN)\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: TRANSFORM Gender_Ratio_FM TO PROPORTION OF FEMALES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 6: Transform Gender_Ratio_FM to proportion of females\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if \"Gender_Ratio_FM\" in moderator_raw.columns:\n",
    "    # Store original column position to maintain column order\n",
    "    gender_col_position = moderator_raw.columns.get_loc(\"Gender_Ratio_FM\")\n",
    "    \n",
    "    print(\"Original Gender_Ratio_FM values (sample):\")\n",
    "    print(moderator_raw[\"Gender_Ratio_FM\"].head(12).tolist())\n",
    "    \n",
    "    # --- Extract female and male counts ---\n",
    "    # Pattern: \"numberF/numberM\" (e.g., \"20F/12M\")\n",
    "    # Regex explanation:\n",
    "    #   ^\\s*        : Start of string, optional whitespace\n",
    "    #   (\\d+)       : Capture group 1 - one or more digits (female count)\n",
    "    #   \\s*[Ff]\\s*  : Optional spaces + F or f + optional spaces\n",
    "    #   /           : Literal forward slash\n",
    "    #   \\s*         : Optional whitespace\n",
    "    #   (\\d+)       : Capture group 2 - one or more digits (male count)\n",
    "    #   \\s*[Mm]\\s*  : Optional spaces + M or m + optional spaces\n",
    "    #   $           : End of string\n",
    "    gender_parts = moderator_raw[\"Gender_Ratio_FM\"].str.extract(\n",
    "        r\"^\\s*(\\d+)\\s*[Ff]\\s*/\\s*(\\d+)\\s*[Mm]\\s*$\"\n",
    "    )\n",
    "    \n",
    "    # Convert extracted strings to numeric\n",
    "    n_female = pd.to_numeric(gender_parts[0], errors=\"coerce\")\n",
    "    n_male = pd.to_numeric(gender_parts[1], errors=\"coerce\")\n",
    "    \n",
    "    # Calculate total participants and proportion female\n",
    "    n_total = n_female + n_male\n",
    "    proportion_female = n_female / n_total\n",
    "    \n",
    "    # Round to 2 decimal places for interpretability\n",
    "    # Example: 20F/12M → 20/32 = 0.625 → 0.62\n",
    "    proportion_female = proportion_female.round(2)\n",
    "    \n",
    "    # Replace original column with proportion values\n",
    "    moderator_raw[\"Gender_Ratio_FM\"] = proportion_female\n",
    "    \n",
    "    # Ensure column stays in original position (not moved to end)\n",
    "    cols = moderator_raw.columns.tolist()\n",
    "    if cols[gender_col_position] != \"Gender_Ratio_FM\":\n",
    "        cols.remove(\"Gender_Ratio_FM\")\n",
    "        cols.insert(gender_col_position, \"Gender_Ratio_FM\")\n",
    "        moderator_raw = moderator_raw[cols]\n",
    "    \n",
    "    print(\"\\nTransformed to proportion (female/total, 2 decimals):\")\n",
    "    print(moderator_raw[\"Gender_Ratio_FM\"].head(12).tolist())\n",
    "    print(f\"✓ Gender_Ratio_FM now represents proportion of females (0-1 scale)\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: TRANSFORM Training_TotalMinute TO NUMERIC\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 7: Transform Training_TotalMinute to numeric\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if \"Training_TotalMinute\" in moderator_raw.columns:\n",
    "    print(\"Original Training_TotalMinute values (sample):\")\n",
    "    print(moderator_raw[\"Training_TotalMinute\"].head(10).tolist())\n",
    "    \n",
    "    # Get raw values as strings\n",
    "    minutes_str = moderator_raw[\"Training_TotalMinute\"].astype(str).str.strip()\n",
    "    \n",
    "    # Remove internal spaces (e.g., \"13 * 90\" → \"13*90\")\n",
    "    minutes_str = minutes_str.str.replace(\" \", \"\", regex=False)\n",
    "    \n",
    "    # Initialize result series with NaN values\n",
    "    minutes_numeric = pd.Series([np.nan] * len(minutes_str), index=moderator_raw.index)\n",
    "    \n",
    "    # --- Process each value individually ---\n",
    "    for idx, val in minutes_str.items():\n",
    "        # Case 1: Missing or empty value → keep as NaN\n",
    "        if pd.isna(val) or val == \"nan\" or val == \"\":\n",
    "            minutes_numeric[idx] = np.nan\n",
    "        \n",
    "        # Case 2: Multiplication expression (e.g., \"13*90\")\n",
    "        # This represents: weeks * minutes_per_week = total_minutes\n",
    "        elif \"*\" in val:\n",
    "            try:\n",
    "                parts = val.split(\"*\")\n",
    "                if len(parts) == 2:\n",
    "                    # Multiply the two numbers\n",
    "                    result = float(parts[0]) * float(parts[1])\n",
    "                    minutes_numeric[idx] = round(result, 2)\n",
    "                else:\n",
    "                    # Invalid format (more than one * symbol)\n",
    "                    minutes_numeric[idx] = np.nan\n",
    "            except:\n",
    "                # Parsing error → NaN\n",
    "                minutes_numeric[idx] = np.nan\n",
    "        \n",
    "        # Case 3: Direct numeric value (e.g., \"240\", \"1200\")\n",
    "        else:\n",
    "            try:\n",
    "                minutes_numeric[idx] = round(float(val), 2)\n",
    "            except:\n",
    "                # Cannot convert to number → NaN\n",
    "                minutes_numeric[idx] = np.nan\n",
    "    \n",
    "    # Replace original column with numeric values\n",
    "    moderator_raw[\"Training_TotalMinute\"] = minutes_numeric\n",
    "    \n",
    "    print(\"\\nTransformed to numeric minutes:\")\n",
    "    print(moderator_raw[\"Training_TotalMinute\"].head(10).tolist())\n",
    "    print(\"✓ Training_TotalMinute: expressions evaluated (e.g., '13*90' → 1170.0)\")\n",
    "\n",
    "# --- Also convert Training_TotalWeeks to numeric ---\n",
    "if \"Training_TotalWeeks\" in moderator_raw.columns:\n",
    "    moderator_raw[\"Training_TotalWeeks\"] = pd.to_numeric(\n",
    "        moderator_raw[\"Training_TotalWeeks\"], errors=\"coerce\"\n",
    "    )\n",
    "    print(\"✓ Training_TotalWeeks converted to numeric\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7.5: CREATE Treatment_Duration CATEGORICAL VARIABLE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 7.5: Create Treatment_Duration categorical variable\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if \"Training_TotalWeeks\" in moderator_raw.columns:\n",
    "    print(\"Original Training_TotalWeeks values (sample):\")\n",
    "    print(moderator_raw[\"Training_TotalWeeks\"].head(10).tolist())\n",
    "    \n",
    "    # Create Treatment_Duration based on Training_TotalWeeks\n",
    "    # Classification:\n",
    "    #   1-4 weeks   → Short\n",
    "    #   5-8 weeks   → Medium\n",
    "    #   9+ weeks    → Long\n",
    "    #   Missing/NaN → NaN\n",
    "    \n",
    "    def categorize_duration(weeks):\n",
    "        \"\"\"\n",
    "        Categorize training duration into Short/Medium/Long\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        weeks : float or NaN\n",
    "            Number of training weeks\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        str or NaN\n",
    "            'Short' (1-4 weeks), 'Medium' (5-8 weeks), or 'Long' (9+ weeks)\n",
    "        \"\"\"\n",
    "        if pd.isna(weeks):\n",
    "            return np.nan\n",
    "        elif weeks <= 4:\n",
    "            return \"Short\"\n",
    "        elif weeks <= 8:\n",
    "            return \"Medium\"\n",
    "        else:  # weeks >= 9\n",
    "            return \"Long\"\n",
    "    \n",
    "    # Apply categorization\n",
    "    moderator_raw[\"Treatment_Duration\"] = moderator_raw[\"Training_TotalWeeks\"].apply(categorize_duration)\n",
    "    \n",
    "    # Insert Treatment_Duration column right after Training_TotalWeeks\n",
    "    # to keep related variables together\n",
    "    weeks_col_position = moderator_raw.columns.get_loc(\"Training_TotalWeeks\")\n",
    "    cols = moderator_raw.columns.tolist()\n",
    "    \n",
    "    # Remove Treatment_Duration from its current position\n",
    "    cols.remove(\"Treatment_Duration\")\n",
    "    # Insert it right after Training_TotalWeeks\n",
    "    cols.insert(weeks_col_position + 1, \"Treatment_Duration\")\n",
    "    moderator_raw = moderator_raw[cols]\n",
    "    \n",
    "    print(\"\\nTreatment_Duration created:\")\n",
    "    print(\"  • Short (1-4 weeks)\")\n",
    "    print(\"  • Medium (5-8 weeks)\")\n",
    "    print(\"  • Long (≥9 weeks)\")\n",
    "    \n",
    "    # Show distribution\n",
    "    duration_counts = moderator_raw[\"Treatment_Duration\"].value_counts(dropna=False)\n",
    "    print(\"\\nDistribution:\")\n",
    "    for category in [\"Short\", \"Medium\", \"Long\"]:\n",
    "        count = duration_counts.get(category, 0)\n",
    "        print(f\"  {category:8s}: {count:2d} studies\")\n",
    "    \n",
    "    missing_count = moderator_raw[\"Treatment_Duration\"].isna().sum()\n",
    "    if missing_count > 0:\n",
    "        print(f\"  Missing : {missing_count:2d} studies\")\n",
    "    \n",
    "    print(\"\\n✓ Treatment_Duration variable created successfully\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: PREPARE EFFECT-SIZE DATA FOR MERGING\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 8: Prepare effect-size data for merging\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Select essential effect-size columns\n",
    "# Keep only the columns needed for meta-analysis\n",
    "effect_clean = effect_size_raw[[\n",
    "    \"index\",        # Merge key\n",
    "    \"Study_ID\",     # Study identifier\n",
    "    \"Effect_ID\",    # Effect-size identifier\n",
    "    \"Hedges_g\",     # Effect-size estimate (bias-corrected)\n",
    "    \"SE\",           # Standard error\n",
    "    \"Variance\",     # Variance of effect size\n",
    "    \"CI_Lower\",     # 95% CI lower bound\n",
    "    \"CI_Upper\"      # 95% CI upper bound\n",
    "]].copy()\n",
    "\n",
    "# Rename Study_ID and Effect_ID to avoid naming conflicts during merge\n",
    "# These will be used for validation after merging\n",
    "effect_clean = effect_clean.rename(columns={\n",
    "    \"Study_ID\": \"Study_ID_effect\",\n",
    "    \"Effect_ID\": \"Effect_ID_effect\"\n",
    "})\n",
    "\n",
    "print(f\"Effect-size data prepared: {effect_clean.shape[0]} rows\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 9: MERGE MODERATOR AND EFFECT-SIZE DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 9: Merge moderator and effect-size data\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Merge on 'index' column\n",
    "# how=\"inner\": Keep only rows present in BOTH tables\n",
    "# validate=\"1:1\": Ensure one-to-one relationship (no duplicate indices)\n",
    "merged_df = pd.merge(\n",
    "    moderator_raw,\n",
    "    effect_clean,\n",
    "    on=\"index\",\n",
    "    how=\"inner\",      # Inner join: only common indices\n",
    "    validate=\"1:1\"    # Enforce 1:1 relationship\n",
    ")\n",
    "\n",
    "print(f\"Merged dataset: {merged_df.shape[0]} rows × {merged_df.shape[1]} columns\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 10: VERIFY DATA INTEGRITY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 10: Verify data integrity\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# --- Check Study_ID consistency ---\n",
    "# Compare Study_ID from moderator table vs effect-size table\n",
    "study_mismatch = merged_df[\n",
    "    merged_df[\"Study_ID\"].astype(str) != merged_df[\"Study_ID_effect\"].astype(str)\n",
    "]\n",
    "\n",
    "if len(study_mismatch) > 0:\n",
    "    print(f\"⚠️  Study_ID mismatches found: {len(study_mismatch)}\")\n",
    "    print(study_mismatch[[\"index\", \"Study_ID\", \"Study_ID_effect\"]])\n",
    "else:\n",
    "    print(\"✓ All Study_ID values match between moderator and effect-size data\")\n",
    "\n",
    "# --- Check Effect_ID consistency ---\n",
    "# Compare Effect_ID from moderator table vs effect-size table\n",
    "effect_mismatch = merged_df[\n",
    "    merged_df[\"Effect_ID\"].astype(str) != merged_df[\"Effect_ID_effect\"].astype(str)\n",
    "]\n",
    "\n",
    "if len(effect_mismatch) > 0:\n",
    "    print(f\"⚠️  Effect_ID mismatches found: {len(effect_mismatch)}\")\n",
    "    print(effect_mismatch[[\"index\", \"Effect_ID\", \"Effect_ID_effect\"]])\n",
    "else:\n",
    "    print(\"✓ All Effect_ID values match between moderator and effect-size data\")\n",
    "\n",
    "# Remove duplicate ID columns\n",
    "# Keep the original columns from the moderator table\n",
    "merged_df = merged_df.drop(columns=[\"Study_ID_effect\", \"Effect_ID_effect\"])\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 11: EXPORT FINAL DATASET\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 11: Export final dataset\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save final cleaned dataset to CSV\n",
    "# index=False: Don't write row numbers\n",
    "# encoding=\"utf-8-sig\": Include BOM for Excel compatibility\n",
    "merged_df.to_csv(\"Meta_ready_cleaned.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"✅ Final dataset exported: meta_ready_cleaned.csv\")\n",
    "print(f\"   Total rows: {merged_df.shape[0]}\")\n",
    "print(f\"   Total columns: {merged_df.shape[1]}\")\n",
    "print(f\"\\nKey transformations:\")\n",
    "print(f\"   • Gender_Ratio_FM → proportion of females (0-1, 2 decimals)\")\n",
    "print(f\"   • Training_TotalMinute → numeric minutes (expressions evaluated)\")\n",
    "print(f\"   • Only studies present in BOTH input files are included\")\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(\"Data preparation complete. Ready for meta-analysis.\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
